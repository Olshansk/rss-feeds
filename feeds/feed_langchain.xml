<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>LangChain Blog</title>
    <link>https://blog.langchain.com</link>
    <description>LangChain Blog - product updates, agent engineering, and more</description>
    <atom:link href="https://raw.githubusercontent.com/Olshansk/rss-feeds/main/feeds/feed_langchain.xml" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <image>
      <url>https://blog.langchain.com/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png</url>
      <title>LangChain Blog</title>
      <link>https://blog.langchain.com</link>
    </image>
    <language>en</language>
    <lastBuildDate>Mon, 09 Feb 2026 15:39:01 +0000</lastBuildDate>
    <item>
      <title>January 2026: LangChain Newsletter</title>
      <link>https://blog.langchain.com/january-2026-langchain-newsletter/</link>
      <description>Read about the latest product updates, events, and content from the LangChain team</description>
      <guid isPermaLink="false">https://blog.langchain.com/january-2026-langchain-newsletter/</guid>
      <pubDate>Thu, 29 Jan 2026 18:27:28 -0800</pubDate>
    </item>
    <item>
      <title>Context Management for Deep Agents</title>
      <link>https://blog.langchain.com/context-management-for-deepagents/</link>
      <description>By Chester Curme and Mason Daugherty

As the addressable task length of AI agents continues to grow, effective context management becomes critical to prevent context rot and to manage LLMs’ finite memory constraints.

The Deep Agents SDK is LangChain’s open source, batteries-included agent harness. It provides an easy path to build agents with the ability to plan, spawn subagents, and work with a filesystem to execute complex, long-running tasks. Because these sorts of tasks can generally exceed</description>
      <guid isPermaLink="false">https://blog.langchain.com/context-management-for-deepagents/</guid>
      <pubDate>Wed, 28 Jan 2026 08:11:29 -0800</pubDate>
    </item>
    <item>
      <title>Deploy agents instantly with Agent Builder templates</title>
      <link>https://blog.langchain.com/introducing-agent-builder-template-library/</link>
      <description>Introducing the Agent Builder Template Library: a collection of ready-to-deploy agents for common tasks, equipped with the tools you already use.</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-agent-builder-template-library/</guid>
      <pubDate>Wed, 21 Jan 2026 09:00:00 -0800</pubDate>
    </item>
    <item>
      <title>Building Multi-Agent Applications with Deep Agents</title>
      <link>https://blog.langchain.com/building-multi-agent-applications-with-deep-agents/</link>
      <description>Breaking down complex tasks across specialized agents is one of the most effective approaches to building capable AI systems. In this post, we'll show you how to build multi-agent systems with Deep Agents.</description>
      <guid isPermaLink="false">https://blog.langchain.com/building-multi-agent-applications-with-deep-agents/</guid>
      <pubDate>Wed, 21 Jan 2026 08:30:00 -0800</pubDate>
    </item>
    <item>
      <title>From Traces to Insights: Understanding Agent Behavior at Scale</title>
      <link>https://blog.langchain.com/from-traces-to-insights-understanding-agent-behavior-at-scale/</link>
      <description>Visibility is the easiest piece. The hard part is analyzing and understanding what you’re observing. I’ve spoken to teams recording 100k+ traces every single day. What are they doing with those traces? Literally nothing. Because it’s impossible to read and summarize 100,000 traces at any human scale.

- Dev Shah

Tracing is critical for agent development - it powers evaluation, debugging, and annotation. But when you have agents in production generating thousands of traces daily, manual review d</description>
      <guid isPermaLink="false">https://blog.langchain.com/from-traces-to-insights-understanding-agent-behavior-at-scale/</guid>
      <pubDate>Tue, 20 Jan 2026 09:16:56 -0800</pubDate>
    </item>
    <item>
      <title>How Remote uses LangChain and LangGraph to onboard thousands of customers with AI</title>
      <link>https://blog.langchain.com/customers-remote/</link>
      <description>Guest post written by José Mussa (Staff Software Engineer @ Remote)

Remote is a fast-growing startup helping companies hire, manage, and pay employees globally from a single platform. Remote’s customers operate across many countries and regulatory environments, and they trust Remote as the system of record for their employee, payroll, and compliance data. Every new customer arrives with a unique set of HR and payroll data , with sometimes thousands of spreadsheets or large SQL exports. Migratin</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-remote/</guid>
      <pubDate>Mon, 19 Jan 2026 08:00:07 -0800</pubDate>
    </item>
    <item>
      <title>Choosing the Right Multi-Agent Architecture</title>
      <link>https://blog.langchain.com/choosing-the-right-multi-agent-architecture/</link>
      <description>In this post, we’ll explore when multi-agent architectures become necessary, the four main patterns we’ve observed, and how LangChain empowers you to effectively build multi-agent systems.</description>
      <guid isPermaLink="false">https://blog.langchain.com/choosing-the-right-multi-agent-architecture/</guid>
      <pubDate>Wed, 14 Jan 2026 10:06:14 -0800</pubDate>
    </item>
    <item>
      <title>Now GA: LangSmith Agent Builder</title>
      <link>https://blog.langchain.com/langsmith-agent-builder-generally-available/</link>
      <description>LangSmith Agent Builder is now generally available—enabling anyone to build agents for complex daily tasks, without writing code.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-agent-builder-generally-available/</guid>
      <pubDate>Tue, 13 Jan 2026 08:00:38 -0800</pubDate>
    </item>
    <item>
      <title>In software, the code documents the app. In AI, the traces do.</title>
      <link>https://blog.langchain.com/in-software-the-code-documents-the-app-in-ai-the-traces-do/</link>
      <description>TL;DR

 * In traditional software, you read the code to understand what the app does - the decision logic lives in your codebase
 * In AI agents, the code is just scaffolding - the actual decision-making happens in the model at runtime
 * Because of this, the source of truth for what your app does shifts from code to traces - traces document what your agent actually did and why
 * This changes how we debug, test, optimize, monitor, collaborate, and understand product usage
 * If you're building </description>
      <guid isPermaLink="false">https://blog.langchain.com/in-software-the-code-documents-the-app-in-ai-the-traces-do/</guid>
      <pubDate>Sat, 10 Jan 2026 09:39:27 -0800</pubDate>
    </item>
    <item>
      <title>Fastweb + Vodafone: Transforming Customer Experience with AI Agents using LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/customers-vodafone-italy/</link>
      <description>See how Fastweb + Vodafone revolutionized customer service and call center operations with their agents, Super TOBi and Super Agent.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-vodafone-italy/</guid>
      <pubDate>Tue, 16 Dec 2025 12:50:55 -0800</pubDate>
    </item>
    <item>
      <title>Debugging Deep Agents with LangSmith</title>
      <link>https://blog.langchain.com/debugging-deep-agents-with-langsmith/</link>
      <description>Debugging is the process of finding and fixing errors. This is a critical step in software engineering, and even more critical in agent engineering. One of the key capabilities of LangSmith is tooling to debug LLM applications.

Today we are doubling down on solving that problem for the new wave of “deep agents” we see being developed.

In this blog we:

 * Explain why debugging deep agents is different than debugging simpler LLM applications
 * Introduce Polly (an AI assistant for agent enginee</description>
      <guid isPermaLink="false">https://blog.langchain.com/debugging-deep-agents-with-langsmith/</guid>
      <pubDate>Wed, 10 Dec 2025 09:08:19 -0800</pubDate>
    </item>
    <item>
      <title>Introducing LangSmith Fetch: Debug agents from your terminal</title>
      <link>https://blog.langchain.com/introducing-langsmith-fetch/</link>
      <description>Today, we're launching LangSmith Fetch, a CLI tool that brings the full power of LangSmith tracing directly into your terminal and IDE.

If you're building agents with coding tools like Claude Code or Cursor, or if you simply prefer working in the command line, you've probably hit this friction: your agent runs, something goes wrong, and now you have to context-switch to the LangSmith UI to figure out what happened. You need to find the right trace, click through the interface, and somehow get t</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-langsmith-fetch/</guid>
      <pubDate>Wed, 10 Dec 2025 09:07:57 -0800</pubDate>
    </item>
    <item>
      <title>Introducing Polly: Your AI Agent Engineer</title>
      <link>https://blog.langchain.com/introducing-polly-your-ai-agent-engineer/</link>
      <description>Today, we're launching Polly: an AI-powered assistant built directly into LangSmith that helps you debug, analyze, and improve your agents.

And yes, we see the irony: we're adding an agent to a product for building agents.

We've spent a lot of time working with thousands of developers build production agents on LangSmith. We've seen what agents are genuinely good at (analyzing complex traces, spotting patterns across hundreds of steps) and what they're not (replacing thoughtful engineering dec</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-polly-your-ai-agent-engineer/</guid>
      <pubDate>Wed, 10 Dec 2025 09:07:48 -0800</pubDate>
    </item>
    <item>
      <title>Agent Engineering: A New Discipline</title>
      <link>https://blog.langchain.com/agent-engineering-a-new-discipline/</link>
      <description>If you’ve built an agent, you know that the delta between “it works on my machine” and “it works in production” can be huge. Traditional software assumes you mostly know the inputs and can define the outputs. Agents give you neither: users can say literally anything, and the space of possible behaviors is wide open. That’s why they’re powerful — and why they can also go a little sideways in ways you didn’t see coming.

Over the past 3 years, we’ve watched thousands of teams struggle with this re</description>
      <guid isPermaLink="false">https://blog.langchain.com/agent-engineering-a-new-discipline/</guid>
      <pubDate>Tue, 09 Dec 2025 08:20:35 -0800</pubDate>
    </item>
    <item>
      <title>Evaluating DeepAgents CLI on Terminal Bench 2.0</title>
      <link>https://blog.langchain.com/evaluating-deepagents-cli-on-terminal-bench-2-0/</link>
      <description>By Vivek Trivedy and Eugene Yurtsev

DeepAgents CLI is a coding agent built on top of the Deep Agents SDK, providing an interactive terminal interface with shell execution, filesystem tools, and memory.

How well does DeepAgents CLI actually perform on real-world tasks?

In this post, we show how to evaluate the DeepAgents CLI on Terminal Bench 2.0, a benchmark measuring agent capabilities across 89 tasks in domains like software engineering, biology, security, and gaming.

DeepAgents CLI (power</description>
      <guid isPermaLink="false">https://blog.langchain.com/evaluating-deepagents-cli-on-terminal-bench-2-0/</guid>
      <pubDate>Fri, 05 Dec 2025 09:50:24 -0800</pubDate>
    </item>
    <item>
      <title>Evaluating Deep Agents: Our Learnings</title>
      <link>https://blog.langchain.com/evaluating-deep-agents-our-learnings/</link>
      <description>Over the past month at LangChain, we shipped four applications on top of the Deep Agents harness:

 * DeepAgents CLI: a coding agent
 * LangSmith Assist: an in-app agent to help with various things in LangSmith
 * Personal Email Assistant: an email assistant that learns from interactions with each user
 * Agent Builder: a no-code agent building platform powered by meta deep agents

Building and shipping these agents meant adding evals for each of them, and we learned a lot along the way! In this</description>
      <guid isPermaLink="false">https://blog.langchain.com/evaluating-deep-agents-our-learnings/</guid>
      <pubDate>Wed, 03 Dec 2025 09:44:17 -0800</pubDate>
    </item>
    <item>
      <title>LangSmith Agent Builder now in Public Beta</title>
      <link>https://blog.langchain.com/langsmith-agent-builder-now-in-public-beta/</link>
      <description>Now anyone can create production ready agents without writing code, just chat.
Agent Builder guides you from initial idea to deployed agent, creating detailed prompts, selecting required tools, and even creating subagents.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-agent-builder-now-in-public-beta/</guid>
      <pubDate>Tue, 02 Dec 2025 08:30:39 -0800</pubDate>
    </item>
    <item>
      <title>Using skills with Deep Agents</title>
      <link>https://blog.langchain.com/using-skills-with-deep-agents/</link>
      <description>tl;dr: Anthropic recently introduced the idea of agent skills. Skills are simply folders containing a SKILL.md file along with any associated files (e.g., documents or scripts) that an agent can discover and load dynamically to perform better at specific tasks. We've added skills support to deepagents-CLI.


The Rise of Generalist Agents

General purpose agents like Claude Code and Manus have gained widespread adoption. While we might expect generalist agents to use many tools, a surprising tren</description>
      <guid isPermaLink="false">https://blog.langchain.com/using-skills-with-deep-agents/</guid>
      <pubDate>Tue, 25 Nov 2025 08:45:09 -0800</pubDate>
    </item>
    <item>
      <title>How agents can use filesystems for context engineering</title>
      <link>https://blog.langchain.com/how-agents-can-use-filesystems-for-context-engineering/</link>
      <description>By Nick Huang

A key feature of deep agents is their access to a set of filesystem tools. Deep agents can use these tools to read, write, edit, list, and search for files in their filesystem.

In this post, we’ll walk through why we think filesystems are important for agents. In order to understand how filesystems are helpful, we should start by thinking through where agents can fall short today. They either fail because (a) the model is not good enough, or (b) they don’t have access to the righ</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-agents-can-use-filesystems-for-context-engineering/</guid>
      <pubDate>Fri, 21 Nov 2025 10:45:13 -0800</pubDate>
    </item>
    <item>
      <title>How Jimdo empower solopreneurs with AI-powered business assistance</title>
      <link>https://blog.langchain.com/customers-jimdo/</link>
      <description>See how Jimdo uses LangChain.js, LangGraph.js, and LangSmith to deliver personalized business insights that drive 50% more first customer contacts and 40% more overall customer activity.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-jimdo/</guid>
      <pubDate>Wed, 19 Nov 2025 17:47:31 -0800</pubDate>
    </item>
    <item>
      <title>How ServiceNow uses LangSmith to get visibility into its customer success agents</title>
      <link>https://blog.langchain.com/customers-servicenow/</link>
      <description>Authors: Ganesh Srinivasan (ServiceNow), Linda Ye (LangChain), and Jake Broekhuizen (LangChain)

ServiceNow is a leading digital workflow platform that helps enterprises transform service management across IT, customer service, and other departments. To improve their internal sales and customer success operations, ServiceNow's AI team is using LangSmith and LangGraph to develop an intelligent multi-agent system that orchestrates the entire customer journey— from lead identification through post-</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-servicenow/</guid>
      <pubDate>Mon, 17 Nov 2025 14:42:50 -0800</pubDate>
    </item>
    <item>
      <title>Execute Code with Sandboxes for DeepAgents</title>
      <link>https://blog.langchain.com/execute-code-with-sandboxes-for-deepagents/</link>
      <description>By Vivek Trivedy

Today we're excited to launch Sandboxes for DeepAgents, a new set of integrations that allow you to safely execute arbitrary DeepAgent code in remote sandboxes. We currently support sandboxes from 3 of our partners: Runloop, Daytona, and Modal. Below, we dive into what you can do with sandboxes and how to use them with with the DeepAgents-CLI.


Why Do We Need Sandboxes?

Sandboxes give us a simple, configurable environment to execute code and do work outside of our local machi</description>
      <guid isPermaLink="false">https://blog.langchain.com/execute-code-with-sandboxes-for-deepagents/</guid>
      <pubDate>Thu, 13 Nov 2025 08:22:20 -0800</pubDate>
    </item>
    <item>
      <title>Join LangChain at AWS re:Invent 2025</title>
      <link>https://blog.langchain.com/join-langchain-at-aws-re-invent-2025/</link>
      <description>If you're attending AWS re:Invent in Las Vegas this year and working on agent development, here's what we have planned:


Visit Us at Booth #524

We'll be at Booth #524 in the Venetian Expo Center, next to the Industry Pavilion, December 1-4. Our engineering team will be running demos throughout the week and available for technical conversations. Add to calendar


See What's New

We'll be showing our latest features, such as Insights Agent and Multi-turn Evaluations. Come by and learn how you ca</description>
      <guid isPermaLink="false">https://blog.langchain.com/join-langchain-at-aws-re-invent-2025/</guid>
      <pubDate>Mon, 10 Nov 2025 16:58:44 -0800</pubDate>
    </item>
    <item>
      <title>Why We Rebuilt LangChain’s Chatbot and What We Learned</title>
      <link>https://blog.langchain.com/rebuilding-chat-langchain/</link>
      <description>By Liam Bush


Background

Every successful platform needs reliable support, but we realized our own team was spending hours tracking down answers to technical questions. This friction wasn't just slowing down our engineers—it was a critical bottleneck for our users.

We set out to solve this using the very tools we champion: LangChain, LangGraph and LangSmith. We originally built chat.langchain.com as a prototype, explicitly designed to serve two functions:

 1. Product Q&amp;A: Help users—and our </description>
      <guid isPermaLink="false">https://blog.langchain.com/rebuilding-chat-langchain/</guid>
      <pubDate>Wed, 05 Nov 2025 08:28:53 -0800</pubDate>
    </item>
    <item>
      <title>Introducing DeepAgents CLI</title>
      <link>https://blog.langchain.com/introducing-deepagents-cli/</link>
      <description>By Vivek Trivedy

We're excited to introduce DeepAgents CLI for coding, research, and building agents with persistent memory. Now you can easily create and run custom DeepAgents directly from the terminal. It supports:

 * Read, write, and edit files in your project
 * Execute shell commands with human approval
 * Search the web for current information
 * Make HTTP requests to APIs
 * Learn and remember information across sessions
 * Plan tasks with visual todo lists


Installation

Install Deep</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-deepagents-cli/</guid>
      <pubDate>Thu, 30 Oct 2025 09:55:35 -0700</pubDate>
    </item>
    <item>
      <title>Introducing LangSmith’s No Code Agent Builder</title>
      <link>https://blog.langchain.com/langsmith-agent-builder/</link>
      <description>By Brace Sproul and Sam Crowder

Today, we’re expanding who can build agents beyond developers. While a lot of the highest volume, customer-facing agents will be built by technical teams, nearly every business user has use cases for agentic applications in their daily routines. Our new LangSmith Agent Builder provides a no code agent-building experience — complete with memory and guided prompt creation — that lowers the barrier to building agents.

Try Agent Builder today, and learn more about o</description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-agent-builder/</guid>
      <pubDate>Wed, 29 Oct 2025 07:38:43 -0700</pubDate>
    </item>
    <item>
      <title>Doubling down on DeepAgents</title>
      <link>https://blog.langchain.com/doubling-down-on-deepagents/</link>
      <description>Two months ago we wrote about Deep Agents - a term we coined for agents that are able to do complex, open ended tasks over longer time horizons. We hypothesized that there were four key elements to those agents: a planning tool, access to a filesystem, subagents, and detailed prompts.

We launched deepagents as an Python package that had a base of all these elements, so that you would only have to bring your custom tools and a custom prompt and you could build a Deep Agent easily.

We've seen st</description>
      <guid isPermaLink="false">https://blog.langchain.com/doubling-down-on-deepagents/</guid>
      <pubDate>Tue, 28 Oct 2025 10:02:22 -0700</pubDate>
    </item>
    <item>
      <title>Agent Frameworks, Runtimes, and Harnesses- oh my!</title>
      <link>https://blog.langchain.com/agent-frameworks-runtimes-and-harnesses-oh-my/</link>
      <description>There are few different open source packages we maintain: LangChain and LangGraph being the biggest ones, but DeepAgents being an increasingly popular one. I’ve started using different terms to describe them: LangChain is an agent framework, LangGraph is an agent runtime, DeepAgents is an agent harness. Other folks are using these terms as well - but I don’t think there is a clear definition of framework vs runtime vs harness. This is my attempt to do try to define things. I will readily admit t</description>
      <guid isPermaLink="false">https://blog.langchain.com/agent-frameworks-runtimes-and-harnesses-oh-my/</guid>
      <pubDate>Sat, 25 Oct 2025 09:14:35 -0700</pubDate>
    </item>
    <item>
      <title>Improve agent quality with Insights Agent and Multi-turn Evals, now in LangSmith</title>
      <link>https://blog.langchain.com/insights-agent-multiturn-evals-langsmith/</link>
      <description>LangSmith's new Insights Agent and Multi-turn Evals help you understand what your agents are doing in production and whether they're accomplishing user goals.</description>
      <guid isPermaLink="false">https://blog.langchain.com/insights-agent-multiturn-evals-langsmith/</guid>
      <pubDate>Thu, 23 Oct 2025 07:23:55 -0700</pubDate>
    </item>
    <item>
      <title>LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones</title>
      <link>https://blog.langchain.com/langchain-langgraph-1dot0/</link>
      <description>By Sydney Runkle and the LangChain OSS team

We're releasing LangChain 1.0 and LangGraph 1.0 — our first major versions of our open source frameworks! After years of feedback, we've updated langchain to focus on the core agent loop, provide flexibility with a new concept of middleware, and upgrade model integrations with the latest content types.

These two frameworks serve different purposes:

 * LangChain is the fastest way to build an AI agent — with a standard tool calling architecture, prov</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-langgraph-1dot0/</guid>
      <pubDate>Wed, 22 Oct 2025 07:58:46 -0700</pubDate>
    </item>
    <item>
      <title>LangChain raises $125M to build the platform for agent engineering</title>
      <link>https://blog.langchain.com/series-b/</link>
      <description>We raised $125M at a $1.25B valuation to build the platform for agent engineering.</description>
      <guid isPermaLink="false">https://blog.langchain.com/series-b/</guid>
      <pubDate>Mon, 20 Oct 2025 07:36:50 -0700</pubDate>
    </item>
    <item>
      <title>Reflections on Three Years of Building LangChain</title>
      <link>https://blog.langchain.com/three-years-langchain/</link>
      <description>by Harrison Chase

Almost exactly 3 years ago, I pushed the first lines of code to langchain as an open source package. There was no company at the time, and no grand plan for what the project would become.

A month later, ChatGPT launched, and everything for langchain changed. It quickly gained steam as the default way to build your own LLM-powered apps. Over the past three years the industry has matured past prototyping chatbots toward productionizing agents that do things, and langchain has e</description>
      <guid isPermaLink="false">https://blog.langchain.com/three-years-langchain/</guid>
      <pubDate>Mon, 20 Oct 2025 07:34:32 -0700</pubDate>
    </item>
    <item>
      <title>Securing your agents with authentication and authorization</title>
      <link>https://blog.langchain.com/agent-authorization-explainer/</link>
      <description>Agents can take action which makes proper authentication and authorization critical. Read on for how to implement and evolve agent auth.</description>
      <guid isPermaLink="false">https://blog.langchain.com/agent-authorization-explainer/</guid>
      <pubDate>Mon, 13 Oct 2025 14:12:15 -0700</pubDate>
    </item>
    <item>
      <title>Not Another Workflow Builder</title>
      <link>https://blog.langchain.com/not-another-workflow-builder/</link>
      <description>By Harrison Chase

One of the most common requests we’ve gotten from day zero of LangChain has been a visual workflow builder. We never pursued it and instead let others (LangFlow, Flowise, n8n) build on top of us. With OpenAI launching a workflow builder at Dev Day yesterday, I thought it would be interesting to write about why we haven’t built one to date, and what different (but related) directions we are more interested in.


The problem statement

First of all, it’s worth aligning on the pr</description>
      <guid isPermaLink="false">https://blog.langchain.com/not-another-workflow-builder/</guid>
      <pubDate>Tue, 07 Oct 2025 09:38:16 -0700</pubDate>
    </item>
    <item>
      <title>How to turn Claude Code into a domain specific coding agent</title>
      <link>https://blog.langchain.com/how-to-turn-claude-code-into-a-domain-specific-coding-agent/</link>
      <description>Authored by: Aliyan Ishfaq

Coding agents are great at writing code that uses popular libraries on which LLMs have been heavily trained on. But point them to a custom library, a new version of a library, an internal API, or a niche framework – and they’re not so great. That’s a problem for teams working with domain specific libraries or enterprise code.

As developers of libraries (LangGraph, LangChain) we are really interested in how to get these coding agents to be really good at writing LangG</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-to-turn-claude-code-into-a-domain-specific-coding-agent/</guid>
      <pubDate>Thu, 11 Sep 2025 09:54:37 -0700</pubDate>
    </item>
    <item>
      <title>Monte Carlo: Building Data + AI Observability Agents with LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/customers-monte-carlo/</link>
      <description>See how Monte Carlo built its AI Troubleshooting Agent on LangGraph and debugged with LangSmith to help data teams resolve issues faster</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-monte-carlo/</guid>
      <pubDate>Wed, 10 Sep 2025 21:30:49 -0700</pubDate>
    </item>
    <item>
      <title>Agent Middleware</title>
      <link>https://blog.langchain.com/agent-middleware/</link>
      <description>LangChain has had agent abstractions for nearly three years. There are now probably 100s of agent frameworks with the same core abstraction. They all suffer from the same downsides that the original LangChain agents suffered from: they do not give the developer enough control over context engineering when needed, leading to developers graduating off of the abstraction for any non-trivial use case. In LangChain 1.0 we are introducing a new agent abstraction (Middleware) which we think solves this</description>
      <guid isPermaLink="false">https://blog.langchain.com/agent-middleware/</guid>
      <pubDate>Mon, 08 Sep 2025 14:11:12 -0700</pubDate>
    </item>
    <item>
      <title>Building LangGraph: Designing an Agent Runtime from first principles</title>
      <link>https://blog.langchain.com/building-langgraph/</link>
      <description>In this blog piece, you’ll learn why and how we built LangGraph for production agents—focusing on control, durability, and the core features needed to scale.</description>
      <guid isPermaLink="false">https://blog.langchain.com/building-langgraph/</guid>
      <pubDate>Thu, 04 Sep 2025 09:26:16 -0700</pubDate>
    </item>
    <item>
      <title>Standard message content</title>
      <link>https://blog.langchain.com/standard-message-content/</link>
      <description>TLDR: We’ve introduced a new view of message content that standardizes reasoning, citations, server-side tool calls, and other modern LLM features across providers. This makes it easier to build applications that are agnostic of the inference provider, while taking advantage of the latest features of each. This feature is fully backward-compatible as it can be computed lazily from existing message content.


Motivation

One of LangChain's core strengths is providing a "write once, run anywhere" </description>
      <guid isPermaLink="false">https://blog.langchain.com/standard-message-content/</guid>
      <pubDate>Wed, 03 Sep 2025 09:10:02 -0700</pubDate>
    </item>
    <item>
      <title>LangChain &amp; LangGraph 1.0 alpha releases</title>
      <link>https://blog.langchain.com/langchain-langchain-1-0-alpha-releases/</link>
      <description>Today we are announcing alpha releases of v1.0 for langgraph and langchain, in both Python and JS. LangGraph is a low-level agent orchestration framework, giving developers durable execution and fine-grained control to run complex agentic systems in production. LangChain helps developers ship AI features fast with standardized model abstractions and prebuilt agent patterns, making it easy to build complex applications without vendor lock-in. We are working towards an official 1.0 release in late</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-langchain-1-0-alpha-releases/</guid>
      <pubDate>Tue, 02 Sep 2025 10:02:02 -0700</pubDate>
    </item>
    <item>
      <title>Introducing Open SWE: An Open-Source Asynchronous Coding Agent</title>
      <link>https://blog.langchain.com/introducing-open-swe-an-open-source-asynchronous-coding-agent/</link>
      <description>The use of AI in software engineering has evolved over the past two years. It started as autocomplete, then went to a copilot in an IDE, and in the fast few months has evolved to be a long running, more end-to-end agent that run asynchronously in the cloud.

We believe that all agents will long more like this in the future - long running, asynchronous, more autonomous. Specifically, we think that they will:

 * Run asynchronously in the cloud
 * Integrate directly with your tooling
 * Have enoug</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-open-swe-an-open-source-asynchronous-coding-agent/</guid>
      <pubDate>Wed, 06 Aug 2025 09:53:45 -0700</pubDate>
    </item>
    <item>
      <title>Deep Agents</title>
      <link>https://blog.langchain.com/deep-agents/</link>
      <description>Using an LLM to call tools in a loop is the simplest form of an agent. This architecture, however, can yield agents that are “shallow” and fail to plan and act over longer, more complex tasks. Applications like “Deep Research”, “Manus”, and “Claude Code” have gotten around this limitation by implementing a combination of four things: a planning tool, sub agents, access to a file system, and a detailed prompt.

Acknowledgements: this exploration was primarily inspired by Claude Code and reports o</description>
      <guid isPermaLink="false">https://blog.langchain.com/deep-agents/</guid>
      <pubDate>Wed, 30 Jul 2025 08:53:38 -0700</pubDate>
    </item>
    <item>
      <title>Introducing Align Evals: Streamlining LLM Application Evaluation</title>
      <link>https://blog.langchain.com/introducing-align-evals/</link>
      <description>Align Evals is a new feature in LangSmith that helps you calibrate your evaluators to better match human preferences. </description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-align-evals/</guid>
      <pubDate>Tue, 29 Jul 2025 13:12:52 -0700</pubDate>
    </item>
    <item>
      <title>How Bertelsmann Built a Multi-Agent System to Empower Creatives</title>
      <link>https://blog.langchain.com/customer-bertelsmann/</link>
      <description>See how one of the world’s biggest media companies leveraged LangGraph from its earliest days to build and deploy a multi-agent system to production that empowers creativity. 
</description>
      <guid isPermaLink="false">https://blog.langchain.com/customer-bertelsmann/</guid>
      <pubDate>Tue, 29 Jul 2025 07:30:45 -0700</pubDate>
    </item>
    <item>
      <title>Why agent infrastructure matters</title>
      <link>https://blog.langchain.com/why-agent-infrastructure/</link>
      <description>Learn why agent infrastructure is essential to handling stateful, long-running tasks — and how LangGraph Platform provides the runtime support needed to build and scale reliable agents.</description>
      <guid isPermaLink="false">https://blog.langchain.com/why-agent-infrastructure/</guid>
      <pubDate>Sun, 27 Jul 2025 22:21:48 -0700</pubDate>
    </item>
    <item>
      <title>LangSmith and LangGraph Platform are now available in AWS Marketplace</title>
      <link>https://blog.langchain.com/aws-marketplace-july-2025-announce/</link>
      <description>LangSmith and LangGraph Platform (self-hosted deployments) are now available in AWS Marketplace.</description>
      <guid isPermaLink="false">https://blog.langchain.com/aws-marketplace-july-2025-announce/</guid>
      <pubDate>Wed, 16 Jul 2025 10:30:41 -0700</pubDate>
    </item>
    <item>
      <title>Open Deep Research</title>
      <link>https://blog.langchain.com/open-deep-research/</link>
      <description>TL;DR

Deep research has broken out as one of the most popular agent applications. OpenAI, Anthropic, Perplexity, and Google all have deep research products that produce comprehensive reports using various sources of context. There are also many open source implementations.

We've built an open deep researcher that is simple and configurable, allowing users to bring their own models, search tools, and MCP servers.

 * Open deep research is built on LangGraph. See the code here!
 * Try it out on </description>
      <guid isPermaLink="false">https://blog.langchain.com/open-deep-research/</guid>
      <pubDate>Wed, 16 Jul 2025 08:43:23 -0700</pubDate>
    </item>
    <item>
      <title>How to Build an Agent</title>
      <link>https://blog.langchain.com/how-to-build-an-agent/</link>
      <description>Learn how to build an agent -- from choosing realistic task examples, to building the MVP to testing quality and safety, to deploying in production.</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-to-build-an-agent/</guid>
      <pubDate>Wed, 09 Jul 2025 17:01:04 -0700</pubDate>
    </item>
    <item>
      <title>Context Engineering</title>
      <link>https://blog.langchain.com/context-engineering-for-agents/</link>
      <description>TL;DR

Agents need context to perform tasks. Context engineering is the art and science of filling the context window with just the right information at each step of an agent’s trajectory. In this post, we break down some common strategies — write, select, compress, and isolate — for context engineering by reviewing various popular agents and papers. We then explain how LangGraph is designed to support them!

Also, see our video on context engineering here.


Context Engineering

As Andrej Karpa</description>
      <guid isPermaLink="false">https://blog.langchain.com/context-engineering-for-agents/</guid>
      <pubDate>Wed, 02 Jul 2025 08:52:42 -0700</pubDate>
    </item>
    <item>
      <title>How Exa built a Web Research Multi-Agent System with LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/exa/</link>
      <description>See how Exa used LangGraph and LangSmith to build a multi-agent web research system to process research queries</description>
      <guid isPermaLink="false">https://blog.langchain.com/exa/</guid>
      <pubDate>Mon, 30 Jun 2025 21:29:33 -0700</pubDate>
    </item>
    <item>
      <title>How Captide agents running on LangGraph Platform compress investment research from days to seconds</title>
      <link>https://blog.langchain.com/captide/</link>
      <description>See how Captide is using LangGraph Platform and LangSmith for their investment research and equity modeling agents. </description>
      <guid isPermaLink="false">https://blog.langchain.com/captide/</guid>
      <pubDate>Tue, 24 Jun 2025 13:54:47 -0700</pubDate>
    </item>
    <item>
      <title>The rise of "context engineering"</title>
      <link>https://blog.langchain.com/the-rise-of-context-engineering/</link>
      <description>Header image from Dex Horthy on Twitter.

Context engineering is building dynamic systems to provide the right information and tools in the right format such that the LLM can plausibly accomplish the task.

Most of the time when an agent is not performing reliably the underlying cause is that the appropriate context, instructions and tools have not been communicated to the model.

LLM applications are evolving from single prompts to more complex, dynamic agentic systems. As such, context enginee</description>
      <guid isPermaLink="false">https://blog.langchain.com/the-rise-of-context-engineering/</guid>
      <pubDate>Mon, 23 Jun 2025 09:56:00 -0700</pubDate>
    </item>
    <item>
      <title>How and when to build multi-agent systems</title>
      <link>https://blog.langchain.com/how-and-when-to-build-multi-agent-systems/</link>
      <description>Late last week two great blog posts were released with seemingly opposite titles. “Don’t Build Multi-Agents” by the Cognition team, and “How we built our multi-agent research system” by the Anthropic team.

Despite their opposing titles, I would argue they actually have a lot in common and contain some insights as to how and when to build multi-agent systems:

 1. Context engineering is crucial
 2. Multi-agent systems that primarily “read” are easier than those that “write”


Context engineering</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-and-when-to-build-multi-agent-systems/</guid>
      <pubDate>Mon, 16 Jun 2025 07:52:10 -0700</pubDate>
    </item>
    <item>
      <title>The Hidden Metric That Determines AI Product Success</title>
      <link>https://blog.langchain.com/the-hidden-metric-that-determines-ai-product-success/</link>
      <description>Co-authored by Assaf Elovic and Harrison Chase. You can also find a version of this post published on Assaf's Medium.

Why do some AI products explode in adoption while others struggle to gain traction? After a decade of building AI products and watching hundreds of launches across the industry, we’ve noticed a pattern that has almost nothing to do with model accuracy or technical sophistication.

The difference comes down to what we call “CAIR” — Confidence in AI Results. This psychological fac</description>
      <guid isPermaLink="false">https://blog.langchain.com/the-hidden-metric-that-determines-ai-product-success/</guid>
      <pubDate>Thu, 12 Jun 2025 08:24:39 -0700</pubDate>
    </item>
    <item>
      <title>Benchmarking Multi-Agent Architectures</title>
      <link>https://blog.langchain.com/benchmarking-multi-agent-architectures/</link>
      <description>By Will Fu-Hinthorn

In this blog, we explore a few common multi-agent architectures. We discuss both the motivations and constraints of different architectures. We benchmark their performance on a variant of the Tau-bench dataset. Finally, we discuss improvements we made to our “supervisor” implementation that yielded a nearly 50% increase in performance on this benchmark.


Motivators for multi-agent systems

A few months ago, we benchmarked how well a single agent architecture scaled with inc</description>
      <guid isPermaLink="false">https://blog.langchain.com/benchmarking-multi-agent-architectures/</guid>
      <pubDate>Tue, 10 Jun 2025 18:40:14 -0700</pubDate>
    </item>
    <item>
      <title>LangGraph Release Week Recap</title>
      <link>https://blog.langchain.com/langgraph-release-week-recap/</link>
      <description>See what we released for LangGraph.js and Python over the past few weeks to speed up development workflows and gain more control at every level of your graph.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-release-week-recap/</guid>
      <pubDate>Mon, 09 Jun 2025 12:17:29 -0700</pubDate>
    </item>
    <item>
      <title>Why do I need LangGraph Platform for agent deployment?</title>
      <link>https://blog.langchain.com/why-langgraph-platform/</link>
      <description>This blog dives into technical details for why agent deployment is difficult, and how we built a platform to solve those challenges (LangGraph Platform).</description>
      <guid isPermaLink="false">https://blog.langchain.com/why-langgraph-platform/</guid>
      <pubDate>Thu, 22 May 2025 08:33:45 -0700</pubDate>
    </item>
    <item>
      <title>How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</title>
      <link>https://blog.langchain.com/customers-webtoon/</link>
      <description>See how Webtoon is transforming storytelling with agent workflows built on LangGraph for content discovery to help marketing, transation, and recommendation teams.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-webtoon/</guid>
      <pubDate>Mon, 19 May 2025 12:00:00 -0700</pubDate>
    </item>
    <item>
      <title>Recap of Interrupt 2025: The AI Agent Conference by LangChain</title>
      <link>https://blog.langchain.com/interrupt-2025-recap/</link>
      <description>Hear more about the product launches, keynote themes, and exciting news from our first-ever conference.</description>
      <guid isPermaLink="false">https://blog.langchain.com/interrupt-2025-recap/</guid>
      <pubDate>Wed, 14 May 2025 22:47:50 -0700</pubDate>
    </item>
    <item>
      <title>LangGraph Platform is now Generally Available: Deploy &amp; manage long-running, stateful Agents</title>
      <link>https://blog.langchain.com/langgraph-platform-ga/</link>
      <description>LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-platform-ga/</guid>
      <pubDate>Wed, 14 May 2025 06:55:34 -0700</pubDate>
    </item>
    <item>
      <title>LangSmith Incident on May 1, 2025</title>
      <link>https://blog.langchain.com/langsmith-incident-on-may-1-2025/</link>
      <description>Requests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025 (starting at 14:35 UTC and ending at 15:03 UTC). During the incident window, approximately 55% of all API requests failed with a connection error. This impacted all endpoints accessible through the API, including endpoints for run ingestion and data fetching.

A conflicting DNS record was accidentally left over during a migration between certificate renewal aut</description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-incident-on-may-1-2025/</guid>
      <pubDate>Wed, 07 May 2025 11:48:28 -0700</pubDate>
    </item>
    <item>
      <title>How Outshift by Cisco achieved a 10x productivity boost with their Agentic AI Platform Engineer</title>
      <link>https://blog.langchain.com/cisco-outshift/</link>
      <description>See how Cisco Outshift built an AI Platform Engineer to boost productivity 10x, taking tasks like setting up CI/CD pipelines from a week to under an hour. </description>
      <guid isPermaLink="false">https://blog.langchain.com/cisco-outshift/</guid>
      <pubDate>Sun, 04 May 2025 14:00:12 -0700</pubDate>
    </item>
    <item>
      <title>How DocentPro Built a Multi-Agent Travel Companion with LangGraph</title>
      <link>https://blog.langchain.com/customers-docentpro/</link>
      <description>See how DocentPro built a multi-agent system in LangGraph and traces and monitors interactions with LangSmith for their AI search itinerary agent</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-docentpro/</guid>
      <pubDate>Tue, 29 Apr 2025 13:35:39 -0700</pubDate>
    </item>
    <item>
      <title>Catch production failures early with LangSmith Alerts</title>
      <link>https://blog.langchain.com/langsmith-alerts/</link>
      <description>Set up real‑time notifications on error rates, run latency &amp; feedback scores to spot failures before your customers do. </description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-alerts/</guid>
      <pubDate>Tue, 22 Apr 2025 08:58:23 -0700</pubDate>
    </item>
    <item>
      <title>How Trellix cut log parsing time from days to minutes with LangGraph Studio and LangSmith</title>
      <link>https://blog.langchain.com/customers-trellix/</link>
      <description>See how cybersecurity company Trellix used LangGraph Studio to visualize and debug agent interactions, plus LangSmith for agent evaluations</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-trellix/</guid>
      <pubDate>Mon, 21 Apr 2025 20:00:19 -0700</pubDate>
    </item>
    <item>
      <title>How to think about agent frameworks</title>
      <link>https://blog.langchain.com/how-to-think-about-agent-frameworks/</link>
      <description>TL;DR:

 * The hard part of building reliable agentic systems is making sure the LLM has the appropriate context at each step. This includes both controlling the exact content that goes into the LLM, as well as running the appropriate steps to generate relevant content.
 * Agentic systems consist of both workflows and agents (and everything in between).
 * Most agentic frameworks are neither declarative or imperative orchestration frameworks, but rather just a set of agent abstractions.
 * Agent</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-to-think-about-agent-frameworks/</guid>
      <pubDate>Sun, 20 Apr 2025 10:32:47 -0700</pubDate>
    </item>
    <item>
      <title>TAMM AI Assistant: Transforming Government Services in Abu Dhabi with LangChain and LangGraph"</title>
      <link>https://blog.langchain.com/customers-abu-dhabi-government/</link>
      <description>See how the Abu Dhabi Government powers their government services platform with LangGraph and LangChain to achieve efficiency and precision.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-abu-dhabi-government/</guid>
      <pubDate>Tue, 15 Apr 2025 08:00:26 -0700</pubDate>
    </item>
    <item>
      <title>How Harmonic built an investment agent with LangGraph and LangSmith— so VCs can focus on founders</title>
      <link>https://blog.langchain.com/customers-harmonic/</link>
      <description>See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-harmonic/</guid>
      <pubDate>Sun, 13 Apr 2025 16:14:30 -0700</pubDate>
    </item>
    <item>
      <title>Why Definely chose LangGraph for building their multi-agent AI system</title>
      <link>https://blog.langchain.com/customers-definely/</link>
      <description>See how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-definely/</guid>
      <pubDate>Mon, 07 Apr 2025 12:53:40 -0700</pubDate>
    </item>
    <item>
      <title>Introducing End-to-End OpenTelemetry Support in LangSmith</title>
      <link>https://blog.langchain.com/end-to-end-opentelemetry-langsmith/</link>
      <description>LangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.</description>
      <guid isPermaLink="false">https://blog.langchain.com/end-to-end-opentelemetry-langsmith/</guid>
      <pubDate>Wed, 26 Mar 2025 23:55:36 -0700</pubDate>
    </item>
    <item>
      <title>How Lovable uses LangSmith to debug &amp; monitor agents in production</title>
      <link>https://blog.langchain.com/customers-lovable/</link>
      <description>Discover how Lovable leveraged LangSmith to gain visibility into its agent’s interactions, rapidly scaling its AI software engineer agent to $25M ARR in just 4 months. </description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-lovable/</guid>
      <pubDate>Tue, 25 Mar 2025 12:35:40 -0700</pubDate>
    </item>
    <item>
      <title>Vodafone transforms data operations with AI using LangChain and LangGraph</title>
      <link>https://blog.langchain.com/customers-vodafone/</link>
      <description>See how Vodafone, a leading telecom company serving 340M+ customers, used LangChain and LangGraph for its performance metrics monitoring and information retrieval chatbots.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-vodafone/</guid>
      <pubDate>Sun, 23 Mar 2025 21:00:28 -0700</pubDate>
    </item>
    <item>
      <title>How Inconvo is improving customer-facing analytics with conversational AI built on LangGraph</title>
      <link>https://blog.langchain.com/customers-inconvo/</link>
      <description>See how Inconvo leverages LangGraph to empower non-technical users to conduct data analysis seamlessly through natural language queries.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-inconvo/</guid>
      <pubDate>Wed, 19 Mar 2025 11:41:17 -0700</pubDate>
    </item>
    <item>
      <title>AI Agent Latency 101: How do I speed up my AI agent?</title>
      <link>https://blog.langchain.com/how-do-i-speed-up-my-agent/</link>
      <description>I get this question a bunch. Developers generally first spend time getting the agent to work, but then they turn their attention to speed and cost. There are few things we see developers doing:

 * Identifying where the latency is coming from
 * Changing the UX to reduce the “perceived” latency
 * Making fewer LLM calls
 * Speeding up LLM calls
 * Making LLM calls in parallel


Identifying where the latency is coming from

This may sound basic, but how you approach reducing latency will depend e</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-do-i-speed-up-my-agent/</guid>
      <pubDate>Sat, 15 Mar 2025 11:34:47 -0700</pubDate>
    </item>
    <item>
      <title>How C.H. Robinson is transforming the logistics industry with LangChain</title>
      <link>https://blog.langchain.com/customers-chrobinson/</link>
      <description>Global logistics provider saves 600+ hours a day with tech they built using LangGraph, LangGraph Studio, and LangSmith developer tools.

</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-chrobinson/</guid>
      <pubDate>Mon, 10 Mar 2025 14:55:16 -0700</pubDate>
    </item>
    <item>
      <title>MCP: Flash in the Pan or Future Standard?</title>
      <link>https://blog.langchain.com/mcp-fad-or-fixture/</link>
      <description>Model Context Protocol (MCP) is creating quite the stir on Twitter – but is it actually useful, or just noise? In this back and forth, Harrison Chase (LangChain CEO) and Nuno Campos (LangGraph Lead) debate whether MCP lives up to the hype.

Harrison: I’ll take the position that MCP is actually useful. I was skeptical on it at first, but I’ve begun to see its value. Essentially: MCP is useful when you want to bring tools to an agent you don’t control.

Let me give an example. For Claude Desktop, </description>
      <guid isPermaLink="false">https://blog.langchain.com/mcp-fad-or-fixture/</guid>
      <pubDate>Sat, 08 Mar 2025 08:25:03 -0800</pubDate>
    </item>
    <item>
      <title>How Build.inc used LangGraph to launch a Multi-Agent Architecture for automating critical CRE workflows for Data Center Development.</title>
      <link>https://blog.langchain.com/how-build-inc-used-langgraph-to-launch-a-multi-agent-architecture-for-automating-critical-cre-workflows-for-data-center-development/</link>
      <description>Editor's note: This is a guest blog post from our friends at Build.inc. They built one of the more complex multi-agent workflows we've seen - with over 25 sub agents. Check out the screenshot of their graph for an idea of the complexity. They also share practical lessons learned from building agent that we think will be helpful for other agent builders.

Build.inc is pushing the boundaries of agentic systems to automate manual and labour intensive workflows in the built world. Our first “worker”</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-build-inc-used-langgraph-to-launch-a-multi-agent-architecture-for-automating-critical-cre-workflows-for-data-center-development/</guid>
      <pubDate>Wed, 05 Mar 2025 07:00:21 -0800</pubDate>
    </item>
    <item>
      <title>LangGraph 0.3 Release: Prebuilt Agents</title>
      <link>https://blog.langchain.com/langgraph-0-3-release-prebuilt-agents/</link>
      <description>By Nuno Campos and Vadym Barda

Over the past year, we’ve invested heavily in making LangGraph the go-to framework for building AI agents. With companies like Replit, Klarna, LinkedIn and Uber choosing to build on top of LangGraph, we have more conviction than ever that we are on the right path.

A core principle of LangGraph is to be as low level as possible. There are no hidden prompts or no enforced “cognitive architectures” in LangGraph. This has served to make it production ready and also d</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-0-3-release-prebuilt-agents/</guid>
      <pubDate>Thu, 27 Feb 2025 07:09:15 -0800</pubDate>
    </item>
    <item>
      <title>How MUFG Bank increased sales efficiency by 10x with LangChain</title>
      <link>https://blog.langchain.com/customers-mufgbank/</link>
      <description>See how MUFG Bank used LangChain to streamline corporate sales research, cutting data analysis time from hours to minutes and boosting efficiency 10x.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-mufgbank/</guid>
      <pubDate>Wed, 26 Feb 2025 23:29:48 -0800</pubDate>
    </item>
    <item>
      <title>Quickly Start Evaluating LLMs With OpenEvals</title>
      <link>https://blog.langchain.com/evaluating-llms-with-openevals/</link>
      <description>Evaluations (evals) are important for bringing reliable LLM powered applications or agents to production, but it can be hard to know where to start when building evaluations from scratch. Our new packages—openevals and agentevals—provide a set of evaluators and a common framework that you can easily get started with.


What are evals?

Evals provide systematic ways to judge LLM output quality based on criteria that's important for your application. There are two components of evals: the data tha</description>
      <guid isPermaLink="false">https://blog.langchain.com/evaluating-llms-with-openevals/</guid>
      <pubDate>Wed, 26 Feb 2025 10:35:25 -0800</pubDate>
    </item>
    <item>
      <title>Beyond RAG: Implementing Agent Search with LangGraph for Smarter Knowledge Retrieval</title>
      <link>https://blog.langchain.com/beyond-rag-implementing-agent-search-with-langgraph-for-smarter-knowledge-retrieval/</link>
      <description>Editor's note: this is a guest post from our friends at Onyx. As LangGraph has matured, we've seen more and more companies (Klarna, Replit, AppFolio, etc) start to use it as their agent framework of choice. We thought this was a great blog describing in detail how that evaluation is done. You can read a version of this post on their blog as well.

By Evan Lohn, Joachim Rahmfeld

At Onyx, we are dedicated to expanding the knowledge and insights users can gain from their enterprise data, thereby e</description>
      <guid isPermaLink="false">https://blog.langchain.com/beyond-rag-implementing-agent-search-with-langgraph-for-smarter-knowledge-retrieval/</guid>
      <pubDate>Sat, 22 Feb 2025 15:23:08 -0800</pubDate>
    </item>
    <item>
      <title>LangMem SDK for agent long-term memory</title>
      <link>https://blog.langchain.com/langmem-sdk-launch/</link>
      <description>Today we're releasing the LangMem SDK, a library that helps your agents learn and improve through long-term memory.

It provides tooling to extract information from conversations, optimize agent behavior through prompt updates, and maintain long-term memory about behaviors, facts, and events.

You can use its core API with any storage system and within any Agent framework, and it integrates natively with LangGraph's long-term memory layer. We are also launching a managed service that provides ad</description>
      <guid isPermaLink="false">https://blog.langchain.com/langmem-sdk-launch/</guid>
      <pubDate>Tue, 18 Feb 2025 07:50:31 -0800</pubDate>
    </item>
    <item>
      <title>How Klarna's AI assistant redefined customer support at scale for 85 million active users</title>
      <link>https://blog.langchain.com/customers-klarna/</link>
      <description>Klarna's AI assistant is revolutionizing the personal shopping experience, including customer service and productivity. See how they used LangGraph and LangSmith to achieve 80% faster customer resolution times.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-klarna/</guid>
      <pubDate>Wed, 12 Feb 2025 07:00:55 -0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Single Agent Performance</title>
      <link>https://blog.langchain.com/react-agent-benchmarking/</link>
      <description>We explore how increasing the number of instructions and tools available to a single ReAct agent affects its performance, benchmarking models like claude-3.5-sonnet, gpt-4o, o1, and o3-mini across two domains of tasks.</description>
      <guid isPermaLink="false">https://blog.langchain.com/react-agent-benchmarking/</guid>
      <pubDate>Mon, 10 Feb 2025 09:13:25 -0800</pubDate>
    </item>
    <item>
      <title>How Vizient empowers healthcare providers with reliable GenAI insights using LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/customers-vizient/</link>
      <description>Vizient's GenAI platform helps users manage data to query for information ranging from patient outcomes to clinical benchmarking. See how they used LangGraph and LangSmith for multi-agent system reliability and prompt management.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-vizient/</guid>
      <pubDate>Mon, 10 Feb 2025 08:41:48 -0800</pubDate>
    </item>
    <item>
      <title>How Infor is Transforming Enterprise AI using LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/customers-infor/</link>
      <description>See how Infor is using the full LangChain product suite — including LangChain, LangGraph, and LangSmith — to drive enterprise automation for the cloud.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-infor/</guid>
      <pubDate>Wed, 05 Feb 2025 23:18:26 -0800</pubDate>
    </item>
    <item>
      <title>Is LangGraph Used In Production?</title>
      <link>https://blog.langchain.com/is-langgraph-used-in-production/</link>
      <description>LinkedIn, Uber, Replit, and Elastic are just a few of the companies using LangGraph for real use cases in production. Learn how they did it below!</description>
      <guid isPermaLink="false">https://blog.langchain.com/is-langgraph-used-in-production/</guid>
      <pubDate>Tue, 04 Feb 2025 23:47:42 -0800</pubDate>
    </item>
    <item>
      <title>Introducing Interrupt: The AI Agent Conference by LangChain</title>
      <link>https://blog.langchain.com/introducing-interrupt-langchain-conference/</link>
      <description>Join us this May at Interrupt, LangChain’s inaugural conference where the future of AI agents takes center stage.</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-interrupt-langchain-conference/</guid>
      <pubDate>Mon, 03 Feb 2025 08:29:57 -0800</pubDate>
    </item>
    <item>
      <title>Introducing the LangGraph Functional API</title>
      <link>https://blog.langchain.com/introducing-the-langgraph-functional-api/</link>
      <description>Have you ever wanted to take advantage of LangGraph's core features like human-in-the-loop, persistence/memory, and streaming without having to explicitly define a graph?

We're excited to announce the release of the Functional API for LangGraph, available in Python and JavaScript.

The functional API allows you to leverage LangGraph features using a more traditional programming paradigm, making it easier to build AI workflows that incorporate human-in-the-loop interactions, short-term and long-</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-the-langgraph-functional-api/</guid>
      <pubDate>Wed, 29 Jan 2025 08:20:22 -0800</pubDate>
    </item>
    <item>
      <title>Exploring Prompt Optimization</title>
      <link>https://blog.langchain.com/exploring-prompt-optimization/</link>
      <description>By Krish Maniar and William Fu-Hinthorn

If you are interested in beta-testing more prompt optimization techniques, fill out interest form here.

When we write prompts, we attempt to communicate our intent for LLMs to apply on messy data, but it's hard to effectively communicate every nuance in one go. Prompting is typically done through manual trial and error, testing and tweaking until things work better; on the other hand, tools like DSPy and promptim have shown the usefulness of prompt "prog</description>
      <guid isPermaLink="false">https://blog.langchain.com/exploring-prompt-optimization/</guid>
      <pubDate>Tue, 28 Jan 2025 08:29:38 -0800</pubDate>
    </item>
    <item>
      <title>Introducing Pytest and Vitest integrations for LangSmith Evaluations</title>
      <link>https://blog.langchain.com/pytest-and-vitest-for-langsmith-evals/</link>
      <description>Introducing a new way to run evals using LangSmith’s Pytest and Vitest/Jest integrations.</description>
      <guid isPermaLink="false">https://blog.langchain.com/pytest-and-vitest-for-langsmith-evals/</guid>
      <pubDate>Wed, 22 Jan 2025 09:54:26 -0800</pubDate>
    </item>
    <item>
      <title>How Captide is redefining equity research with agentic workflows running on LangGraph Platform</title>
      <link>https://blog.langchain.com/how-captide-is-redefining-equity-research-with-agentic-workflows-built-on-langgraph-and-langsmith/</link>
      <description>Captide’s platform transforms how investment research teams work with financial data. By automating the extraction of insights and metrics from regulatory filings and investor relations documents, analysts can create customized datasets and analyses with extreme efficiency. At the heart of this innovation is their commitment to NLP workflows and its strategic integration of LangGraph and LangSmith, hosted on LangGraph Platform.


Redefining Financial Analysis with NLP Workflows

By allowing user</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-captide-is-redefining-equity-research-with-agentic-workflows-built-on-langgraph-and-langsmith/</guid>
      <pubDate>Mon, 20 Jan 2025 08:58:57 -0800</pubDate>
    </item>
    <item>
      <title>How Minimal built a multi-agent customer support system with LangGraph &amp; LangSmith</title>
      <link>https://blog.langchain.com/how-minimal-built-a-multi-agent-customer-support-system-with-langgraph-langsmith/</link>
      <description>In the thriving world of e-commerce, where customer satisfaction can make or break a brand, Minimal is leveraging the LangChain ecosystem to transform how support issues are handled. Minimal AI agents are delivering 80%+ efficiency gains over a broad variety of E-commerce stores while improving customer satisfaction. This year, Minimal expects that 90% of their customers' support tickets will be handled autonomously by their AI, escalating only 10% to human agents. Below, you’ll see how this new</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-minimal-built-a-multi-agent-customer-support-system-with-langgraph-langsmith/</guid>
      <pubDate>Mon, 20 Jan 2025 08:52:14 -0800</pubDate>
    </item>
    <item>
      <title>Introducing ambient agents</title>
      <link>https://blog.langchain.com/introducing-ambient-agents/</link>
      <description>Most AI apps today follow a familiar chat pattern ("chat" UX). Though easy to implement, they create unnecessary interaction overhead, limit the ability of us humans to scale ourselves, and fail to use the full potential of LLMs.

Over the past six months, we've been exploring a different approach at LangChain: agents that respond to ambient signals and demand user input only when they detect important opportunities or require feedback. Rather than forcing users into new chat windows, these agen</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-ambient-agents/</guid>
      <pubDate>Tue, 14 Jan 2025 09:07:02 -0800</pubDate>
    </item>
    <item>
      <title>Acxiom's use of LangSmith for enhanced audience segmentation</title>
      <link>https://blog.langchain.com/customers-acxiom/</link>
      <description>See how Acxiom debugged their agent application with LangSmith and built a scalable solution for their user base, complete with long-term memory, dynamic updates, and attribute-specific search.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-acxiom/</guid>
      <pubDate>Sun, 12 Jan 2025 23:47:34 -0800</pubDate>
    </item>
    <item>
      <title>Structured Report Generation Blueprint with NVIDIA AI</title>
      <link>https://blog.langchain.com/structured-report-generation-blueprint/</link>
      <description>LLMs are reaching a point of maturity where they are sufficiently capable of powering sophisticated AI agents. The agents they power are not free-range, pseudo-AGI-like agents, but rather vertical-specific agents addressing a specific use case, with a specific focus. Examples of these AI agents launched in the past year include Replit's coding agent, Elastic's security assistant, and Uber's developer productivity platform.

A significant portion of these agents rely on large, closed-source model</description>
      <guid isPermaLink="false">https://blog.langchain.com/structured-report-generation-blueprint/</guid>
      <pubDate>Mon, 06 Jan 2025 10:30:00 -0800</pubDate>
    </item>
    <item>
      <title>Top 5 LangGraph Agents in Production 2024</title>
      <link>https://blog.langchain.com/top-5-langgraph-agents-in-production-2024/</link>
      <description>2024 was the year that agents started to work in production. Not the wide-ranging, fully autonomous agents that people imagined with AutoGPT. But more vertical, narrowly scoped, highly controllable agents with custom cognitive architectures. It's still not easy to build these agents - but it's entirely possible.

We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework</description>
      <guid isPermaLink="false">https://blog.langchain.com/top-5-langgraph-agents-in-production-2024/</guid>
      <pubDate>Tue, 31 Dec 2024 10:03:10 -0800</pubDate>
    </item>
    <item>
      <title>LangChain State of AI 2024 Report</title>
      <link>https://blog.langchain.com/langchain-state-of-ai-2024/</link>
      <description>Dive into LangSmith product usage patterns that show how the AI ecosystem and the way people are building LLM apps is evolving. </description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-state-of-ai-2024/</guid>
      <pubDate>Thu, 19 Dec 2024 09:30:11 -0800</pubDate>
    </item>
    <item>
      <title>Custom Authentication and Access Control for LangGraph Platform</title>
      <link>https://blog.langchain.com/custom-authentication-and-access-control-in-langgraph/</link>
      <description>Note: As of October 2025, LangGraph Platform has been re-named to "LangSmith Deployment".

Today we're introducing custom authentication and resource-level access control for Python deployments in LangGraph Cloud and self-hosted environments. This feature lets you integrate your own auth providers and implement granular access patterns directly in your LangGraph applications.


Quick Links

 * Video Tutorial: Adding Custom Authentication to LangGraph
 * Authentication tutorial series:
   1. Basi</description>
      <guid isPermaLink="false">https://blog.langchain.com/custom-authentication-and-access-control-in-langgraph/</guid>
      <pubDate>Thu, 19 Dec 2024 08:40:26 -0800</pubDate>
    </item>
    <item>
      <title>How AppFolio transformed property management workflows with Realm-X, built using LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/customers-appfolio/</link>
      <description>See how AppFolio's AI-powered copilot Realm-X has saved property managers over 10 hours per week. Learn how they improved Realm-X's performance 2x using LangSmith and built an agent architecture with LangGraph.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-appfolio/</guid>
      <pubDate>Mon, 16 Dec 2024 09:30:11 -0800</pubDate>
    </item>
    <item>
      <title>Making it easier to build human-in-the-loop agents with interrupt</title>
      <link>https://blog.langchain.com/making-it-easier-to-build-human-in-the-loop-agents-with-interrupt/</link>
      <description>While agents can be powerful, they are not perfect. This often makes it important to keep the human “in the loop” when building agents. For example, in our fireside chat we did with Michele Catasta (President of Replit) on their Replit Agent, he speaks several times about the human-in-the-loop component being crucial to their agent design.

From the start, we designed LangGraph with this in mind, and it’s one of the key reasons many companies choose to build on LangGraph. Today, we’re excited to</description>
      <guid isPermaLink="false">https://blog.langchain.com/making-it-easier-to-build-human-in-the-loop-agents-with-interrupt/</guid>
      <pubDate>Sat, 14 Dec 2024 08:37:58 -0800</pubDate>
    </item>
    <item>
      <title>Command: A new tool for building multi-agent architectures in LangGraph</title>
      <link>https://blog.langchain.com/command-a-new-tool-for-multi-agent-architectures-in-langgraph/</link>
      <description>Learn about Command, a new tool in LangGraph that helps facilitate multi-agent communication.</description>
      <guid isPermaLink="false">https://blog.langchain.com/command-a-new-tool-for-multi-agent-architectures-in-langgraph/</guid>
      <pubDate>Tue, 10 Dec 2024 09:13:42 -0800</pubDate>
    </item>
    <item>
      <title>Introducing OpenTelemetry support for LangSmith</title>
      <link>https://blog.langchain.com/opentelemetry-langsmith/</link>
      <description>LangSmith now supports OpenTelemetry for distributed tracing and observability.</description>
      <guid isPermaLink="false">https://blog.langchain.com/opentelemetry-langsmith/</guid>
      <pubDate>Mon, 09 Dec 2024 08:44:18 -0800</pubDate>
    </item>
    <item>
      <title>Easier evaluations with LangSmith SDK v0.2</title>
      <link>https://blog.langchain.com/easier-evaluations-with-langsmith-sdk-v0-2/</link>
      <description>We've released a v0.2 of the LangSmith SDKs with various evaluations and performance improvements. </description>
      <guid isPermaLink="false">https://blog.langchain.com/easier-evaluations-with-langsmith-sdk-v0-2/</guid>
      <pubDate>Thu, 05 Dec 2024 10:51:25 -0800</pubDate>
    </item>
    <item>
      <title>Semantic Search for LangGraph Memory</title>
      <link>https://blog.langchain.com/semantic-search-for-langgraph-memory/</link>
      <description>Following our launch of long-term memory support, we're adding semantic search to LangGraph's BaseStore. Available today in the open source PostgresStore and InMemoryStore's, in LangGraph studio, as well as in production in all LangGraph Platform deployments.

Quick Links:

 * Video tutorial on adding semantic search to the memory agent template
 * How to guide on adding semantic search in LangGraph
 * How to guide on adding semantic search in your LangGraph Platform deployment


Why semantic se</description>
      <guid isPermaLink="false">https://blog.langchain.com/semantic-search-for-langgraph-memory/</guid>
      <pubDate>Thu, 05 Dec 2024 06:08:36 -0800</pubDate>
    </item>
    <item>
      <title>How Cleric’s AI SRE leveled up with continuous learning through LangSmith</title>
      <link>https://blog.langchain.com/customers-cleric/</link>
      <description>Cleric is an AI SRE teammate that identifies issues using existing observability tools and infrastructure. See how they used LangSmith to investigate their production issues effectively.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-cleric/</guid>
      <pubDate>Mon, 02 Dec 2024 21:39:41 -0800</pubDate>
    </item>
    <item>
      <title>How Airtop built web-automation for AI agents powered by the LangChain ecosystem</title>
      <link>https://blog.langchain.com/customers-airtop/</link>
      <description>See how Airtop, which provides browser automation for AI agents, built a flexible agent architecture with LangGraph and debugged and refined prompts in LangSmith.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-airtop/</guid>
      <pubDate>Tue, 26 Nov 2024 06:00:45 -0800</pubDate>
    </item>
    <item>
      <title>Agent Protocol: Interoperability for LLM agents</title>
      <link>https://blog.langchain.com/agent-protocol-interoperability-for-llm-agents/</link>
      <description>LangGraph is a multi-agent framework. This means not only interacting with other LangGraph agents, but all other types of agents as well, regardless of how they are built. Today we are taking a few steps to build towards this vision. We are announcing:

 * Agent Protocol: a common interface for agent communication. This standardizes how agents (LangGraph or otherwise) can interact.
 * A guide and video showing how to connect LangGraph Studio to a locally running agent. This exposes a locally run</description>
      <guid isPermaLink="false">https://blog.langchain.com/agent-protocol-interoperability-for-llm-agents/</guid>
      <pubDate>Tue, 19 Nov 2024 09:00:02 -0800</pubDate>
    </item>
    <item>
      <title>LangSmith: Redesigned product homepage and Resource Tags for better organization</title>
      <link>https://blog.langchain.com/langsmith-homepage-redesign-and-resource-tags/</link>
      <description>LangSmith's homepage is now organized into Observability, Evaluation, and Prompt Engineering. Learn why we organized the homepage like this. Plus, see our latest Resource Tags updates.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-homepage-redesign-and-resource-tags/</guid>
      <pubDate>Tue, 19 Nov 2024 07:59:58 -0800</pubDate>
    </item>
    <item>
      <title>How Dun &amp; Bradstreet’s ChatD&amp;B™ uses LangChain and LangSmith to deliver trusted, data-driven AI insights</title>
      <link>https://blog.langchain.com/customers-dun-bradstreet/</link>
      <description>Learn how Dun &amp; Bradstreet, a leading financial data analytics company, empowers global clients with business data — from credit risk to ownership structures — to make better decisions using their AI assistant, Chat D&amp;B. See how LangChain and LangSmith have helped Dun &amp; Bradstreet on their journey.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-dun-bradstreet/</guid>
      <pubDate>Mon, 18 Nov 2024 07:30:21 -0800</pubDate>
    </item>
    <item>
      <title>Promptim: an experimental library for prompt optimization</title>
      <link>https://blog.langchain.com/promptim/</link>
      <description>Promptim is an experimental prompt optimization library to help you systematically improve your AI systems.

Promptim automates the process of improving prompts on specific tasks. You provide initial prompt, a dataset, and custom evaluators (and optional human feedback), and promptim runs an optimization loop to produce a refined prompt that aims to outperform the original.


From evaluation-driven development to prompt optimization

A core responsibility of AI engineers is prompt engineering. T</description>
      <guid isPermaLink="false">https://blog.langchain.com/promptim/</guid>
      <pubDate>Wed, 13 Nov 2024 10:09:41 -0800</pubDate>
    </item>
    <item>
      <title>Introducing Prompt Canvas: a Novel UX for Developing Prompts</title>
      <link>https://blog.langchain.com/introducing-prompt-canvas/</link>
      <description>Use Prompt Canvas in LangSmith to collaborate with an AI agent to build and optimize your prompts.</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-prompt-canvas/</guid>
      <pubDate>Tue, 12 Nov 2024 08:59:11 -0800</pubDate>
    </item>
    <item>
      <title>Composio’s SWE agent advances open-source on SweBench with a 48.6% score using LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/composio-swekit/</link>
      <description>We are excited to launch SWE-Kit, an open-source headless IDE with AI-native coding toolkits for AI agents, as part of Composio's agent tooling ecosystem. SWE-kit offers a headless IDE featuring Language Server Protocol (LSP) for code intelligence and a development container for secure code execution. It also features comprehensive coding tools like CodeAnalysis, Shell tools, File management and Git tools.

To demonstrate SWE-Kit’s efficiency, we built a complete SWE agent using LangGraph and te</description>
      <guid isPermaLink="false">https://blog.langchain.com/composio-swekit/</guid>
      <pubDate>Mon, 11 Nov 2024 09:16:31 -0800</pubDate>
    </item>
    <item>
      <title>SCIPE - Systematic Chain Improvement and Problem Evaluation</title>
      <link>https://blog.langchain.com/scipe-systematic-chain-improvement-and-problem-evaluation/</link>
      <description>Editor's Note: we're EXTREMELY excited to highlight this research from Ankush Garg and Shreya Shankar from Berkeley. At LangChain, two of the biggest problems we think about are evals and agents, and this research sits right at the intersection. You can try it out today in their Python package.

TLDR: It helps you find underperforming nodes in LLM chains.


The problem it solves

Building LLM-powered applications is challenging, and the complexity multiplies with LLM chains that can have multipl</description>
      <guid isPermaLink="false">https://blog.langchain.com/scipe-systematic-chain-improvement-and-problem-evaluation/</guid>
      <pubDate>Thu, 07 Nov 2024 09:27:18 -0800</pubDate>
    </item>
    <item>
      <title>How Chaos Labs built a multi-agent system for resolution in prediction markets</title>
      <link>https://blog.langchain.com/how-chaos-labs-built-a-multi-agent-system-for-resolution-in-prediction-markets/</link>
      <description>Editor's Note: one of the most common use cases we've seen for LangGraph is complex research agents. This guest blog post by Chaos Labs highlights a great example of that. It utilizes multiple sources and complex architecture to do research that would power resolution in prediction markets. For those unfamiliar with prediction markets: prediction markets are resolved via an "oracle" that determines outcomes and resolves bets. Edge AI Oracle is an LLM based system that does just that.

Today, we’</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-chaos-labs-built-a-multi-agent-system-for-resolution-in-prediction-markets/</guid>
      <pubDate>Wed, 06 Nov 2024 09:07:30 -0800</pubDate>
    </item>
    <item>
      <title>LangGraph Platform in beta: New deployment options for scalable agent infrastructure</title>
      <link>https://blog.langchain.com/langgraph-platform-announce/</link>
      <description>We've rebranded our service for deploying and scaling LangGraph apps as LangGraph Platform. Learn about the multiple deployment options and what LangGraph Platform entails.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-platform-announce/</guid>
      <pubDate>Thu, 31 Oct 2024 08:23:29 -0700</pubDate>
    </item>
    <item>
      <title>Communication is all you need</title>
      <link>https://blog.langchain.com/communication-is-all-you-need/</link>
      <description>“What we’ve got here is failure to communicate” - Cool Hand Luke (1967)

Communication is the hardest part of life. It’s also the hardest part of building LLM applications.

New hires always requires a lot of communication when first joining a company, no matter how smart they may be. This might include getting a guidebook of key procedures and best practices, having a manager step in to help the new hire get up to speed, and gaining access to specific software to do the job properly. While ramp</description>
      <guid isPermaLink="false">https://blog.langchain.com/communication-is-all-you-need/</guid>
      <pubDate>Sat, 26 Oct 2024 09:28:29 -0700</pubDate>
    </item>
    <item>
      <title>LangChain's Second Birthday</title>
      <link>https://blog.langchain.com/langchain-second-birthday/</link>
      <description>Reflections on how LangChain has evolved — including our products, ecosystem, and community — over the past two years, and where we're headed next. </description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-second-birthday/</guid>
      <pubDate>Thu, 24 Oct 2024 07:43:53 -0700</pubDate>
    </item>
    <item>
      <title>Memory for agents</title>
      <link>https://blog.langchain.com/memory-for-agents/</link>
      <description>At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. Check out that talk here. In this post I will dive more into memory. See the previous post on planning here, and the previous posts on UX here, here, and here.

If agents are the biggest buzzword of LLM application development in 2024, memory might be the second biggest. But what even is memory?

At a high level, memory is just a system that remembers something about previous intera</description>
      <guid isPermaLink="false">https://blog.langchain.com/memory-for-agents/</guid>
      <pubDate>Sat, 19 Oct 2024 10:00:23 -0700</pubDate>
    </item>
    <item>
      <title>How Rexera’s AI agents drive quality control with LangGraph</title>
      <link>https://blog.langchain.com/customers-rexera/</link>
      <description>See how Rexera migrated to LangGraph to create a robust quality control agent for real estate workflows, significantly improving their LLM response accuracy.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-rexera/</guid>
      <pubDate>Wed, 09 Oct 2024 13:14:27 -0700</pubDate>
    </item>
    <item>
      <title>Unify Launches Agents for Account Qualification using LangGraph and LangSmith</title>
      <link>https://blog.langchain.com/unify-launches-agents-for-account-qualification-using-langgraph-and-langsmith/</link>
      <description>This is a guest blog post written by Sam and Connor at Unify. Unify is reinventing how go-to-market teams work using generative AI. As part of this transformation, they are launching a new agents feature today (powered by LangGraph and LangSmith). We had the pleasure of learning more about the engineering journey taken to launch this feature, and thought it would be a great story to share.

Agents are a new feature we’re launching alongside a broader automation suite we call Plays. Agents are ef</description>
      <guid isPermaLink="false">https://blog.langchain.com/unify-launches-agents-for-account-qualification-using-langgraph-and-langsmith/</guid>
      <pubDate>Tue, 08 Oct 2024 10:23:51 -0700</pubDate>
    </item>
    <item>
      <title>Launching Long-Term Memory Support in LangGraph</title>
      <link>https://blog.langchain.com/launching-long-term-memory-support-in-langgraph/</link>
      <description>Today, we are excited to announce the first steps towards long-term memory support in LangGraph, available both in Python and JavaScript. Long-term memory lets you store and recall information between conversations so your agent can learn from feedback and adapt to user preferences. This feature is part of the OSS library, and it is enabled by default for all LangGraph Cloud &amp; Studio users.


On Memory

Most AI applications today are goldfish; they forget everything between conversations. This i</description>
      <guid isPermaLink="false">https://blog.langchain.com/launching-long-term-memory-support-in-langgraph/</guid>
      <pubDate>Tue, 08 Oct 2024 08:02:03 -0700</pubDate>
    </item>
    <item>
      <title>OpenRecovery: Transforming addiction recovery with LangGraph Platform</title>
      <link>https://blog.langchain.com/customers-openrecovery/</link>
      <description>See how OpenRecovery built an AI assistant with LangGraph Cloud, LangGraph, and LangSmith to support users on their journey to addiction recovery.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-openrecovery/</guid>
      <pubDate>Thu, 03 Oct 2024 09:02:44 -0700</pubDate>
    </item>
    <item>
      <title>Pushing LangSmith to new limits with Replit Agent's complex workflows</title>
      <link>https://blog.langchain.com/customers-replit/</link>
      <description>See how Replit built their agents atop LangGraph and integrated LangSmith to pinpoint issues, improve the performance of their agents, and enable human-in-the-loop workflows.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-replit/</guid>
      <pubDate>Thu, 26 Sep 2024 11:22:15 -0700</pubDate>
    </item>
    <item>
      <title>Introducing Assistant Editor for configuring agents in LangGraph Studio</title>
      <link>https://blog.langchain.com/asssistant-editor/</link>
      <description>We're excited to announce the launch of the Assistant Editor, a powerful new feature in LangGraph Studio that makes it easier than ever to configure and customize your LLM-powered agents. This visual editing tool empowers both developers and non-technical users to fine-tune agent behavior without diving into code.


What are Assistants?

Before we dive into the new Assistant Editor, let's quickly recap what assistants are in the context of LangGraph.

Assistants are instances of a graph with spe</description>
      <guid isPermaLink="false">https://blog.langchain.com/asssistant-editor/</guid>
      <pubDate>Wed, 25 Sep 2024 10:14:19 -0700</pubDate>
    </item>
    <item>
      <title>How Tradestack launched their MVP in 6 weeks using LangGraph Cloud</title>
      <link>https://blog.langchain.com/customers-tradestack/</link>
      <description>See how Tradestack built and launched their MVP with LangGraph Cloud, adding reliability and improved performance to their agentic workflows.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-tradestack/</guid>
      <pubDate>Wed, 25 Sep 2024 07:00:52 -0700</pubDate>
    </item>
    <item>
      <title>Launching LangGraph Templates</title>
      <link>https://blog.langchain.com/launching-langgraph-templates/</link>
      <description>Today we are excited to announce LangGraph templates, available in both Python and JS. These template repositories address common use cases and are designed for easy configuration and deployment to LangGraph Cloud. The best way to use these is to download the newest version of LangGraph Studio, but you can also use them as standalone GitHub repos.
























0:00

/0:12


1×

















Over the past year, we've repeatedly seen that real-world "agentic" applications require car</description>
      <guid isPermaLink="false">https://blog.langchain.com/launching-langgraph-templates/</guid>
      <pubDate>Thu, 19 Sep 2024 08:27:28 -0700</pubDate>
    </item>
    <item>
      <title>Announcing LangChain v0.3</title>
      <link>https://blog.langchain.com/announcing-langchain-v0-3/</link>
      <description>Today, we’re excited to announce the release of LangChain v0.3 for both Python and JavaScript ecosystems.


What's changed


Python

 * All packages have been upgraded from Pydantic 1 to Pydantic 2 internally. Use of Pydantic 2 in user code is fully supported with all packages without the need for bridges like langchain_core.pydantic_v1 or pydantic.v1.
 * Pydantic 1 will no longer be supported as it reached its end-of-life in June 2024.
 * Python 3.8 will no longer be supported as its end-of-lif</description>
      <guid isPermaLink="false">https://blog.langchain.com/announcing-langchain-v0-3/</guid>
      <pubDate>Mon, 16 Sep 2024 09:40:01 -0700</pubDate>
    </item>
    <item>
      <title>Building a Data Visualization Agent with LangGraph Cloud</title>
      <link>https://blog.langchain.com/data-viz-agent/</link>
      <description>Editor's Note: This is a guest blog post by Dhruv Ateja. It covers building a full stack application that uses an agent to both query data as well as choose how to display that data. It leverages LangGraph and LangGraph Cloud.

Key Links:

 * YouTube Video
 * GitHub Repo
 * Hosted Application

Let's explore an exciting project that leverages LangGraph Cloud's streaming API to create a data visualization agent. You can upload an SQLite database or CSV file, ask questions about your data, and the </description>
      <guid isPermaLink="false">https://blog.langchain.com/data-viz-agent/</guid>
      <pubDate>Thu, 12 Sep 2024 09:17:24 -0700</pubDate>
    </item>
    <item>
      <title>Build stateful conversational AI agents with LangGraph and assistant-ui</title>
      <link>https://blog.langchain.com/assistant-ui/</link>
      <description>TL;DR: assistant-ui is an embeddable AI chat frontend for React applications. It supports streaming, generative UI, human-in-the-loop, and other UX paradigms crucial for agentic applications. We’ve worked with Simon (the maintainer) to add a tight integration with LangGraph Cloud. This allows you to easily deploy LangGraph agents as standalone web apps or integrate them as assistants into existing applications. This post was written in collaboration with Simon.


Relevant Links

 * Getting Start</description>
      <guid isPermaLink="false">https://blog.langchain.com/assistant-ui/</guid>
      <pubDate>Wed, 11 Sep 2024 08:44:40 -0700</pubDate>
    </item>
    <item>
      <title>How Paradigm runs and monitors thousands of agents in parallel with LangChain and LangSmith</title>
      <link>https://blog.langchain.com/customers-paradigm/</link>
      <description>See how Paradigm used LangSmith and LangChain to build, iterate, and monitor their AI agents.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-paradigm/</guid>
      <pubDate>Wed, 04 Sep 2024 08:34:34 -0700</pubDate>
    </item>
    <item>
      <title>Build reliable agents in JavaScript with LangGraph.js v0.2: Now supporting Cloud and Studio</title>
      <link>https://blog.langchain.com/javascript-langgraph-v02-cloud-studio/</link>
      <description>For JavaScript developers - LangGraph v0.2, LangGraph Cloud, and LangGraph Studio are all available. </description>
      <guid isPermaLink="false">https://blog.langchain.com/javascript-langgraph-v02-cloud-studio/</guid>
      <pubDate>Tue, 03 Sep 2024 07:52:36 -0700</pubDate>
    </item>
    <item>
      <title>How Podium optimized agent behavior and reduced engineering intervention by 90% with LangSmith</title>
      <link>https://blog.langchain.com/customers-podium/</link>
      <description>See how Podium tests across the lifecycle development of their AI employee agent, using LangSmith for dataset curation and finetuning. They improved agent F1 response quality to 98% and reduced the need for engineering intervention by 90%.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-podium/</guid>
      <pubDate>Thu, 15 Aug 2024 07:00:04 -0700</pubDate>
    </item>
    <item>
      <title>LangChain Integration Docs: Find information faster with revamped pages &amp; API references</title>
      <link>https://blog.langchain.com/langchain-integration-docs-revamped/</link>
      <description>See the latest updates to the LangChain integration docs, including a new standardized format and improved API references that can help you find relevant information faster.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-integration-docs-revamped/</guid>
      <pubDate>Wed, 14 Aug 2024 08:36:14 -0700</pubDate>
    </item>
    <item>
      <title>UX for Agents, Part 3: Spreadsheet, Generative, and Collaborative UI/UX</title>
      <link>https://blog.langchain.com/ux-for-agents-part-3/</link>
      <description>Learn about spreadsheet UX for batch agent workloads, Generative UI, and collaborative UX with agents.</description>
      <guid isPermaLink="false">https://blog.langchain.com/ux-for-agents-part-3/</guid>
      <pubDate>Sat, 10 Aug 2024 07:00:36 -0700</pubDate>
    </item>
    <item>
      <title>LangGraph v0.2: Increased customization with new checkpointer libraries</title>
      <link>https://blog.langchain.com/langgraph-v0-2/</link>
      <description>LangGraph v0.2 includes new checkpointer libraries for increased customization — including a SQLite checkpointer for local workflows and an optimized Postgres checkpointer to take your app to production. Plus, learn about LangGraph Cloud in open beta. </description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-v0-2/</guid>
      <pubDate>Wed, 07 Aug 2024 09:16:24 -0700</pubDate>
    </item>
    <item>
      <title>Dynamic few-shot examples with LangSmith datasets</title>
      <link>https://blog.langchain.com/dynamic-few-shot-examples-langsmith-datasets/</link>
      <description>With dynamic few-shot examples in LangSmith, you can Index examples in your datasets in one click and dynamically select the most relevant few-shot examples based on user input. This lets you rapidly iterate and improve LLM app performance.
</description>
      <guid isPermaLink="false">https://blog.langchain.com/dynamic-few-shot-examples-langsmith-datasets/</guid>
      <pubDate>Tue, 06 Aug 2024 09:00:10 -0700</pubDate>
    </item>
    <item>
      <title>UX for Agents, Part 2: Ambient</title>
      <link>https://blog.langchain.com/ux-for-agents-part-2-ambient/</link>
      <description>This is our second post focused on UX for agents. We discuss ambient background agents, which can handle multiple tasks at the same time, and how they can be used in your workflow.</description>
      <guid isPermaLink="false">https://blog.langchain.com/ux-for-agents-part-2-ambient/</guid>
      <pubDate>Fri, 02 Aug 2024 17:53:41 -0700</pubDate>
    </item>
    <item>
      <title>LangGraph Studio: The first agent IDE</title>
      <link>https://blog.langchain.com/langgraph-studio-the-first-agent-ide/</link>
      <description>LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-studio-the-first-agent-ide/</guid>
      <pubDate>Thu, 01 Aug 2024 09:38:17 -0700</pubDate>
    </item>
    <item>
      <title>Dataset schemas for fast and iterative data curation in LangSmith</title>
      <link>https://blog.langchain.com/dataset-schemas/</link>
      <description>Define and flexibly manage dataset schemas in LangSmith. Validate examples against a defined schema, and update the schema easily in the LangSmith UI. </description>
      <guid isPermaLink="false">https://blog.langchain.com/dataset-schemas/</guid>
      <pubDate>Wed, 31 Jul 2024 05:17:07 -0700</pubDate>
    </item>
    <item>
      <title>UX for Agents, Part 1: Chat</title>
      <link>https://blog.langchain.com/ux-for-agents-part-1-chat-2/</link>
      <description>At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. Check out that talk here. In this post I will dive deeper into UX for agents. Thanks to Nuno Campos, LangChain founding engineer for many of the original thoughts and analogies here.

Because there are so many different aspects of UX for agents, this topic will be split into three separate blogs. This is first in the series.

Human-Computer Interaction has been a well-studied area f</description>
      <guid isPermaLink="false">https://blog.langchain.com/ux-for-agents-part-1-chat-2/</guid>
      <pubDate>Fri, 26 Jul 2024 18:14:17 -0700</pubDate>
    </item>
    <item>
      <title>Few-shot prompting to improve tool-calling performance</title>
      <link>https://blog.langchain.com/few-shot-prompting-to-improve-tool-calling-performance/</link>
      <description>We ran a few experiments, which show how few-shot prompting can significantly enhance model accuracy - especially for complex tasks. Read on for how we did it (and the results).</description>
      <guid isPermaLink="false">https://blog.langchain.com/few-shot-prompting-to-improve-tool-calling-performance/</guid>
      <pubDate>Wed, 24 Jul 2024 07:00:04 -0700</pubDate>
    </item>
    <item>
      <title>How Athena Intelligence optimized research reports with LangSmith, LangChain, and LangGraph</title>
      <link>https://blog.langchain.com/customers-athena-intelligence/</link>
      <description>See how an AI-powered employee for enterprise analytics used the LangSmith playground and debugging features to quickly identify LLM issues and to generate complex research reports.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-athena-intelligence/</guid>
      <pubDate>Sun, 21 Jul 2024 19:02:31 -0700</pubDate>
    </item>
    <item>
      <title>Planning for Agents</title>
      <link>https://blog.langchain.com/planning-for-agents/</link>
      <description>The fourth installment in our "In the Loop Series," in which we talk about what planning means for an agent and how to improve it.</description>
      <guid isPermaLink="false">https://blog.langchain.com/planning-for-agents/</guid>
      <pubDate>Sat, 20 Jul 2024 08:02:23 -0700</pubDate>
    </item>
    <item>
      <title>Improving core tool interfaces and docs in LangChain</title>
      <link>https://blog.langchain.com/improving-core-tool-interfaces-and-docs-in-langchain/</link>
      <description>See our latest improvements to our core tool interfaces that make it turn any code into a tool, handle diverse inputs, enrich tool outputs, and handle tool errors effectively.</description>
      <guid isPermaLink="false">https://blog.langchain.com/improving-core-tool-interfaces-and-docs-in-langchain/</guid>
      <pubDate>Thu, 18 Jul 2024 09:55:18 -0700</pubDate>
    </item>
    <item>
      <title>How We Deployed our Multi-Agent Flow to LangGraph Cloud</title>
      <link>https://blog.langchain.com/how-we-deployed-our-multi-agent-flow-to-langgraph-cloud-2/</link>
      <description>Read this guest blog post on how to create a LangGraph multi-agent flow via React &amp; LangGraph Cloud.</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-we-deployed-our-multi-agent-flow-to-langgraph-cloud-2/</guid>
      <pubDate>Mon, 15 Jul 2024 08:51:05 -0700</pubDate>
    </item>
    <item>
      <title>Why you should outsource your agentic infrastructure, but own your cognitive architecture</title>
      <link>https://blog.langchain.com/why-you-should-outsource-your-agentic-infrastructure-but-own-your-cognitive-architecture/</link>
      <description>In this third installment in our "In The Loop" series, learn why you should tailor your cognitive architecture to be application-specific, alongside running better infrastructure for your agentic apps.</description>
      <guid isPermaLink="false">https://blog.langchain.com/why-you-should-outsource-your-agentic-infrastructure-but-own-your-cognitive-architecture/</guid>
      <pubDate>Sat, 13 Jul 2024 06:25:35 -0700</pubDate>
    </item>
    <item>
      <title>[Week of 7/8] LangChain Release Notes</title>
      <link>https://blog.langchain.com/week-of-7-8-langchain-release-notes/</link>
      <description>See new use cases for building &amp; deploying with LangGraph Cloud, revamped LangGraph docs, and more on self-improving evaluators in LangSmith. Plus, hear the latest agents trends — and learn more about our upcoming agents-themed hackathon.</description>
      <guid isPermaLink="false">https://blog.langchain.com/week-of-7-8-langchain-release-notes/</guid>
      <pubDate>Fri, 12 Jul 2024 08:15:28 -0700</pubDate>
    </item>
    <item>
      <title>LangSmith for the full product lifecycle: How Wordsmith quickly builds, debugs, and evaluates LLM performance in production</title>
      <link>https://blog.langchain.com/customers-wordsmith/</link>
      <description>Learn how WordSmith, an AI assistant for legal teams, uses LangSmith across its entire product lifecycle — from prototyping, to evaluation, to debugging, to experimentation.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-wordsmith/</guid>
      <pubDate>Mon, 08 Jul 2024 21:56:13 -0700</pubDate>
    </item>
    <item>
      <title>What is a "cognitive architecture"?</title>
      <link>https://blog.langchain.com/what-is-a-cognitive-architecture/</link>
      <description>The second installment in our "In the Loop" series, focusing on what cognitive architecture means.</description>
      <guid isPermaLink="false">https://blog.langchain.com/what-is-a-cognitive-architecture/</guid>
      <pubDate>Fri, 05 Jul 2024 22:52:03 -0700</pubDate>
    </item>
    <item>
      <title>Jockey: A Conversational Video Agent Powered by Twelve Labs APIs and LangGraph</title>
      <link>https://blog.langchain.com/jockey-twelvelabs-langgraph/</link>
      <description>Guest blog post on how Jockey, a conversational video agent, uses LangGraph and Twelve Labs API for more intelligent video processing.</description>
      <guid isPermaLink="false">https://blog.langchain.com/jockey-twelvelabs-langgraph/</guid>
      <pubDate>Wed, 03 Jul 2024 11:06:58 -0700</pubDate>
    </item>
    <item>
      <title>Improving Memory Retrieval: How New Computer achieved 50% higher recall with LangSmith</title>
      <link>https://blog.langchain.com/customers-new-computer/</link>
      <description>New Computer used LangSmith to improve their memory retrieval system, achieving 50% higher recall by tracking regressions in comparison view and adjusting conversation prompts accordingly.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-new-computer/</guid>
      <pubDate>Tue, 02 Jul 2024 07:59:14 -0700</pubDate>
    </item>
    <item>
      <title>What is an AI agent?</title>
      <link>https://blog.langchain.com/what-is-an-agent/</link>
      <description>Introducing a new series of musings on AI agents, called "In the Loop".</description>
      <guid isPermaLink="false">https://blog.langchain.com/what-is-an-agent/</guid>
      <pubDate>Fri, 28 Jun 2024 18:01:01 -0700</pubDate>
    </item>
    <item>
      <title>Announcing LangGraph v0.1 &amp; LangGraph Cloud: Running agents at scale, reliably</title>
      <link>https://blog.langchain.com/langgraph-cloud/</link>
      <description>Our new infrastructure for running agents at scale, LangGraph Cloud, is available in beta. We also have a new stable release of LangGraph.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-cloud/</guid>
      <pubDate>Thu, 27 Jun 2024 08:13:05 -0700</pubDate>
    </item>
    <item>
      <title>Aligning LLM-as-a-Judge with Human Preferences</title>
      <link>https://blog.langchain.com/aligning-llm-as-a-judge-with-human-preferences/</link>
      <description>Deep dive into self-improving evaluators in LangSmith, motivated by the rise of LLM-as-a-Judge evaluators plus research on few-shot learning and aligning human preferences.</description>
      <guid isPermaLink="false">https://blog.langchain.com/aligning-llm-as-a-judge-with-human-preferences/</guid>
      <pubDate>Wed, 26 Jun 2024 09:59:06 -0700</pubDate>
    </item>
    <item>
      <title>How Factory used LangSmith to automate their feedback loop and improve iteration speed by 2x</title>
      <link>https://blog.langchain.com/customers-factory/</link>
      <description>How Factory AI uses LangSmith to debug issues and close the product feedback loop, resulting in a 2x improvement in iteration speed.</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-factory/</guid>
      <pubDate>Wed, 19 Jun 2024 08:16:54 -0700</pubDate>
    </item>
    <item>
      <title>Workspaces in LangSmith for improved collaboration and organization</title>
      <link>https://blog.langchain.com/workspaces-in-langsmith/</link>
      <description>LangSmith activities and workflows now happen in workspaces that separate resources between teams, business units, or deployment environments.</description>
      <guid isPermaLink="false">https://blog.langchain.com/workspaces-in-langsmith/</guid>
      <pubDate>Thu, 13 Jun 2024 07:45:00 -0700</pubDate>
    </item>
    <item>
      <title>Documentation Refresh for LangChain v0.2</title>
      <link>https://blog.langchain.com/documentation-refresh-for-langchain-v0-2/</link>
      <description>Learn about the docs refresh for LangChain v0.2. There's now versioned docs and a clearer structure — with tutorials, how-to guides, conceptual guides, and API docs</description>
      <guid isPermaLink="false">https://blog.langchain.com/documentation-refresh-for-langchain-v0-2/</guid>
      <pubDate>Mon, 20 May 2024 09:19:15 -0700</pubDate>
    </item>
    <item>
      <title>Integrating LangChain with Azure Container Apps dynamic sessions</title>
      <link>https://blog.langchain.com/integrating-langchain-with-azure-container-apps-dynamic-sessions/</link>
      <description>Azure Container Apps dynamic sessions provide a secure, low-latency, reliable Python REPL API. With the new dynamic sessions LangChain integration, you can safely give your LangChain chains and agents the ability to write and execute Python code.


Relevant Links

 * LangChain: docs
 * Azure Container Apps: docs and tutorial
 * LangGraph data analyst: video and code


The value of code execution

LLMs excel at solving complex problems but, just like human brains, struggle with certain computatio</description>
      <guid isPermaLink="false">https://blog.langchain.com/integrating-langchain-with-azure-container-apps-dynamic-sessions/</guid>
      <pubDate>Thu, 16 May 2024 10:57:28 -0700</pubDate>
    </item>
    <item>
      <title>Pairwise Evaluations with LangSmith</title>
      <link>https://blog.langchain.com/pairwise-evaluations-with-langsmith/</link>
      <description>What is pairwise evaluation? Learn why you might need it for your LLM app development, and see a walk-through example of how to use pairwise evaluators in LangSmith.</description>
      <guid isPermaLink="false">https://blog.langchain.com/pairwise-evaluations-with-langsmith/</guid>
      <pubDate>Wed, 15 May 2024 08:00:44 -0700</pubDate>
    </item>
    <item>
      <title>LangChain v0.2: A Leap Towards Stability</title>
      <link>https://blog.langchain.com/langchain-v02-leap-to-stability/</link>
      <description>Today, we're announcing the pre-release of LangChain v0.2, which improves the stability and security of LangChain.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-v02-leap-to-stability/</guid>
      <pubDate>Fri, 10 May 2024 09:16:38 -0700</pubDate>
    </item>
    <item>
      <title>How to Build the Ultimate AI Automation with Multi-Agent Collaboration</title>
      <link>https://blog.langchain.com/how-to-build-the-ultimate-ai-automation-with-multi-agent-collaboration/</link>
      <description>Assaf Elovic, Head of R&amp;D at Wix, walks through how to build an autonomous research assistant using LangGraph with a team of specialized agents.</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-to-build-the-ultimate-ai-automation-with-multi-agent-collaboration/</guid>
      <pubDate>Thu, 09 May 2024 11:55:22 -0700</pubDate>
    </item>
    <item>
      <title>Access Control Updates for LangSmith</title>
      <link>https://blog.langchain.com/access-control-updates-for-langsmith/</link>
      <description>Access management can be a pain for large engineering teams as they build LLM applications. To avoid playing a game of whodunit or over/under-provisioning permissions, you need to systematically determine who can access your resources and to what capacity.

LangSmith now has new Access Control features to help enterprises manage access to their resources. This includes Role Based Access Control (RBAC), which lets you specify custom roles and can better support users with limited permissions via </description>
      <guid isPermaLink="false">https://blog.langchain.com/access-control-updates-for-langsmith/</guid>
      <pubDate>Wed, 08 May 2024 08:30:00 -0700</pubDate>
    </item>
    <item>
      <title>How Dosu Used LangSmith to Achieve a 30% Accuracy Improvement with No Prompt Engineering</title>
      <link>https://blog.langchain.com/dosu-langsmith-no-prompt-eng/</link>
      <description>Editor's Note: the following is authored by Devin Stein, CEO of Dosu. In this blog we walk through how Dosu uses LangSmith to improve the performance of their application - with NO prompt engineering. Rather, they collected feedback from their users, transformed that into few shot examples, and then fed that back into their application.

This is a relatively simple and general technique that can lead to automatic performance improvements. We've written up a LangSmith cookbook to let anyone get s</description>
      <guid isPermaLink="false">https://blog.langchain.com/dosu-langsmith-no-prompt-eng/</guid>
      <pubDate>Thu, 02 May 2024 08:16:51 -0700</pubDate>
    </item>
    <item>
      <title>Regression Testing with LangSmith</title>
      <link>https://blog.langchain.com/regression-testing/</link>
      <description>This blog post walks through our improved regression testing experience in LangSmith. If video form is more your style, you can check out our YouTube walkthrough here. Sign up for LangSmith here for free to try it out for yourself!

 * YouTube Walkthrough
 * LangSmith

The ability to quickly and reliably evaluate your LLM application allows AI engineers to iterate with confidence. Many of the fastest moving and most successful teams we see have efficient testing and experimentation processes. Th</description>
      <guid isPermaLink="false">https://blog.langchain.com/regression-testing/</guid>
      <pubDate>Wed, 01 May 2024 09:23:06 -0700</pubDate>
    </item>
    <item>
      <title>Graph-based metadata filtering for improving vector search in RAG applications</title>
      <link>https://blog.langchain.com/graph-based-metadata-filtering-for-improving-vector-search-in-rag-applications/</link>
      <description>Optimizing vector retrieval with advanced graph-based metadata techniques using LangChain and Neo4j

Editor's Note: the following is a guest blog post from Tomaz Bratanic, who focuses on Graph ML and GenAI research at Neo4j. Neo4j is a graph database and analytics company which helps organizations find hidden relationships and patterns across billions of data connections deeply, easily, and quickly.

Text embeddings and vector similarity search help us find documents by understanding their meani</description>
      <guid isPermaLink="false">https://blog.langchain.com/graph-based-metadata-filtering-for-improving-vector-search-in-rag-applications/</guid>
      <pubDate>Thu, 25 Apr 2024 08:30:52 -0700</pubDate>
    </item>
    <item>
      <title>Announcing LangSmith is now a transactable offering in the Azure Marketplace</title>
      <link>https://blog.langchain.com/announcing-langsmith-is-now-a-transactable-offering-in-the-azure-marketplace/</link>
      <description>Today, we’re thrilled to announce that enterprises can purchase LangSmith in the Azure Marketplace as an Azure Kubernetes Application. LangSmith is a unified DevOps platform for developing, collaborating, testing, and monitoring LLM applications, whether you’re building with LangChain or not. LangSmith has quickly become the platform of choice to help enterprises get their LLM-apps from prototype to production, and LangSmith customers such as Moody’s, Elastic, Rakuten, and BCG rely on the platfo</description>
      <guid isPermaLink="false">https://blog.langchain.com/announcing-langsmith-is-now-a-transactable-offering-in-the-azure-marketplace/</guid>
      <pubDate>Wed, 24 Apr 2024 08:03:59 -0700</pubDate>
    </item>
    <item>
      <title>Empowering Development with FlowTestAI: Bridging APIs and LLMs for Enhanced Testing and Privacy</title>
      <link>https://blog.langchain.com/empowering-development-with-flowtestai/</link>
      <description>Editor's note: we're excited to highlight this blog from FlowTestAI. FlowTestAI is an exciting startup building on top of LangChain. Specifically, they try to enable easy accessing of APIs through LLMs. Interacting with APIs via LLMs is a huge use case of LangChain, and so we're excited to showcase what this looks like in a production application.

Independent APIs when connected together are very powerful. Virtually every online interaction, whether it involves external customers, internal use,</description>
      <guid isPermaLink="false">https://blog.langchain.com/empowering-development-with-flowtestai/</guid>
      <pubDate>Mon, 22 Apr 2024 08:48:58 -0700</pubDate>
    </item>
    <item>
      <title>Tool Calling with LangChain</title>
      <link>https://blog.langchain.com/tool-calling-with-langchain/</link>
      <description>TLDR: We are introducing a new tool_calls attribute on AIMessage. More and more LLM providers are exposing API’s for reliable tool calling. The goal with the new attribute is to provide a standard interface for interacting with tool invocations. This is fully backwards compatible and is supported on all models that have native tool-calling support. In order to access these latest features you will need to upgrade your langchain_core and partner package versions.

YouTube Walkthrough

Python:

 *</description>
      <guid isPermaLink="false">https://blog.langchain.com/tool-calling-with-langchain/</guid>
      <pubDate>Thu, 11 Apr 2024 09:46:57 -0700</pubDate>
    </item>
    <item>
      <title>Rethinking Our Documentation</title>
      <link>https://blog.langchain.com/langchain-documentation-refresh/</link>
      <description>LangChain has seen some incredible growth in the last year and half. The Python open-source library is now downloaded over 7 million times per month, and has had more than 20,000 pull requests and 2,500 contributors!

The community is truly what makes LangChain incredible, and we're beyond thankful to everyone who has pitched in. But this exponential growth has also exponentially increased the surface area our documentation has had to cover. This has led to some issues with organization and disc</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-documentation-refresh/</guid>
      <pubDate>Fri, 05 Apr 2024 08:18:25 -0700</pubDate>
    </item>
    <item>
      <title>LangSmith: Production Monitoring &amp; Automations</title>
      <link>https://blog.langchain.com/langsmith-production-logging-automations/</link>
      <description>Key Links:

 * YouTube Walkthrough
 * Sign up for LangSmith here

If 2023 was a breakthrough year for LLMs, then 2024 is shaping up to be the year that a significant amount of LLM-powered applications make their way into production. From the Elastic AI Assistant to CommandBar's Copilot User Assistant - more and more complex applications are shipping to production and providing real business value. Many of these applications use LangSmith to test and debug their applications, and today we're anno</description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-production-logging-automations/</guid>
      <pubDate>Tue, 02 Apr 2024 08:41:23 -0700</pubDate>
    </item>
    <item>
      <title>LangFriend: a Journal with Long-Term Memory</title>
      <link>https://blog.langchain.com/langfriend/</link>
      <description>One of the concepts we are most interested in at LangChain is memory. Whenever we are interested in a concept, we like to build an example app showing off that concept. For memory, we decided to build a journaling app! We're hosting a version of it that anyone can try out. We're also starting to work with a few alpha users on a developer facing API. If you are interested in this, please sign up below.

Key Links:

 * YouTube
 * Journal App
 * Developer API Access

💡We are also doing a memory re</description>
      <guid isPermaLink="false">https://blog.langchain.com/langfriend/</guid>
      <pubDate>Thu, 28 Mar 2024 09:03:00 -0700</pubDate>
    </item>
    <item>
      <title>Open Source Extraction Service</title>
      <link>https://blog.langchain.com/open-source-extraction-service/</link>
      <description>Earlier this month we announced our most recent OSS use-case accelerant: a service for extracting structured data from unstructured sources, such as text and PDF documents. Today we are exposing a hosted version of the service with a simple front end. The application is free to use, but is not intended for production workloads or sensitive data. The intent is to showcase what is possible in this category in 2024, and to help developers get a running start with their own applications.

Key Links:</description>
      <guid isPermaLink="false">https://blog.langchain.com/open-source-extraction-service/</guid>
      <pubDate>Tue, 26 Mar 2024 08:15:35 -0700</pubDate>
    </item>
    <item>
      <title>Using Feedback to Improve Your Application: Self Learning GPTs</title>
      <link>https://blog.langchain.com/self-learning-gpts/</link>
      <description>We built and hosted a simple demo app to show how applications can learn and improve from feedback over time. The app is called "Self Learning GPTs" and it uses LangSmith to gather feedback and then automatically use that feedback to improve over time. It does this by creating few-shot examples from that feedback and incorporating those into the prompt.

Key Links:

 * You can access a hosted version of this app here.
 * You can see a deep dive on how this works in this YouTube video.
 * We are </description>
      <guid isPermaLink="false">https://blog.langchain.com/self-learning-gpts/</guid>
      <pubDate>Wed, 20 Mar 2024 09:38:28 -0700</pubDate>
    </item>
    <item>
      <title>LangChain Integrates NVIDIA NIM for GPU-optimized LLM Inference in RAG</title>
      <link>https://blog.langchain.com/nvidia-nim/</link>
      <description>Roughly a year and a half ago, OpenAI launched ChatGPT and the generative AI era really kicked off. Since then we’ve seen rapid growth and widespread adoption by all types of industries and all types of enterprises. As enterprises turn their attention from prototyping LLM applications to productionizing them, they often want to turn from third-party model services to self-hosted solutions. We’ve seen many folks struggle with this, and that’s why LangChain is so excited to integrate the new NVIDI</description>
      <guid isPermaLink="false">https://blog.langchain.com/nvidia-nim/</guid>
      <pubDate>Mon, 18 Mar 2024 15:00:45 -0700</pubDate>
    </item>
    <item>
      <title>Enhancing RAG-based application accuracy by constructing and leveraging knowledge graphs</title>
      <link>https://blog.langchain.com/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/</link>
      <description>A practical guide to constructing and retrieving information from knowledge graphs in RAG applications with Neo4j and LangChain

Editor's Note: the following is a guest blog post from Tomaz Bratanic, who focuses on Graph ML and GenAI research at Neo4j. Neo4j is a graph database and analytics company which helps organizations find hidden relationships and patterns across billions of data connections deeply, easily, and quickly.

Graph retrieval augmented generation (Graph RAG) is gaining momentum</description>
      <guid isPermaLink="false">https://blog.langchain.com/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/</guid>
      <pubDate>Fri, 15 Mar 2024 11:01:37 -0700</pubDate>
    </item>
    <item>
      <title>Benchmarking Query Analysis in High Cardinality Situations</title>
      <link>https://blog.langchain.com/high-cardinality/</link>
      <description>Several key use cases for LLMs involve returning data in a structured format. Extraction is one such use case - we recently highlighted this with updated documentation and a dedicated repo. Query analysis is another - we’ve also updated our documentation around this recently. When returning information in a structured format the fields can be a myriad of types: string, boolean, integers. One of the hardest types to correctly handle is high-cardinality categorical values (or enums).

What does “h</description>
      <guid isPermaLink="false">https://blog.langchain.com/high-cardinality/</guid>
      <pubDate>Fri, 15 Mar 2024 08:15:19 -0700</pubDate>
    </item>
    <item>
      <title>Multi Needle in a Haystack</title>
      <link>https://blog.langchain.com/multi-needle-in-a-haystack/</link>
      <description>Key Links

 * Video
 * Code


Overview

Interest in long context LLMs is surging as context windows expand to 1M tokens. One of the most popular and cited benchmarks for long context LLM retrieval is Greg Kamradt's Needle in A Haystack: a fact (needle) is injected into a (haystack) of context (e.g., Paul Graham essays) and the LLM is asked a question related to this fact. This explores retrieval across context length and document placement.

But, this isn't fully reflective of many retrieval aug</description>
      <guid isPermaLink="false">https://blog.langchain.com/multi-needle-in-a-haystack/</guid>
      <pubDate>Wed, 13 Mar 2024 09:02:08 -0700</pubDate>
    </item>
    <item>
      <title>Iterating Towards LLM Reliability with Evaluation Driven Development</title>
      <link>https://blog.langchain.com/iterating-towards-llm-reliability-with-evaluation-driven-development/</link>
      <description>Editor's Note: the following is a guest blog post from the Devin Stein, CEO of Dosu. Dosu is an engineering teammate that helps you develop, maintain, and support software.

It’s well known at this point that building production-grade LLM products is hard. Reliability is critical for any product to succeed, but when your product is underpinned by a series of probabilistic functions, ensuring reliability is far from straightforward.

At Dosu, we are continuously iterating on our product. For ever</description>
      <guid isPermaLink="false">https://blog.langchain.com/iterating-towards-llm-reliability-with-evaluation-driven-development/</guid>
      <pubDate>Mon, 11 Mar 2024 08:11:53 -0700</pubDate>
    </item>
    <item>
      <title>Use Case Accelerant: Extraction Service</title>
      <link>https://blog.langchain.com/use-case-accelerant-extraction-service/</link>
      <description>Today we’re excited to announce our newest OSS use-case accelerant: an extraction service. LLMs are a powerful tool for extracting structured data from unstructured sources. We've improved our support for data extraction in the open source LangChain library over the past few releases, and now we’re taking that a step further with a starter repository to help you build your own extraction application.

The starter repository includes a bare-bones web application that can be extended to build a se</description>
      <guid isPermaLink="false">https://blog.langchain.com/use-case-accelerant-extraction-service/</guid>
      <pubDate>Wed, 06 Mar 2024 10:00:35 -0800</pubDate>
    </item>
    <item>
      <title>LangGraph for Code Generation</title>
      <link>https://blog.langchain.com/code-execution-with-langgraph/</link>
      <description>Key Links

 * LangGraph cookbook
 * Video


Motivation

Code generation and analysis are two of most important applications of LLMs, as shown by the ubiquity of products like GitHub co-pilot and popularity of projects like GPT-engineer. The recent AlphaCodium work showed that code generation can be improved by using a flow paradigm rather than a naive prompt:answer paradigm: answers can be iteratively constructed by (1) testing answers and (2) reflecting on the results of these tests in order to</description>
      <guid isPermaLink="false">https://blog.langchain.com/code-execution-with-langgraph/</guid>
      <pubDate>Tue, 27 Feb 2024 08:10:00 -0800</pubDate>
    </item>
    <item>
      <title>Reflection Agents</title>
      <link>https://blog.langchain.com/reflection-agents/</link>
      <description>Reflection is a prompting strategy used to improve the quality and success rate of agents and similar AI systems. This post outlines how to build 3 reflection techniques using LangGraph, including implementations of Reflexion and Language Agent Tree Search.</description>
      <guid isPermaLink="false">https://blog.langchain.com/reflection-agents/</guid>
      <pubDate>Wed, 21 Feb 2024 01:29:10 -0800</pubDate>
    </item>
    <item>
      <title>JSON agents with Ollama &amp; LangChain</title>
      <link>https://blog.langchain.com/json-based-agents-with-ollama-and-langchain/</link>
      <description>Learn to implement an open-source Mixtral agent that interacts with a graph database Neo4j through a semantic layer

Editor's note: This post is written by Tomaz Bratanic from Neo4j

By now, we all have probably recognized that we can significantly enhance the capabilities of LLMs by providing them with additional tools. For example, even ChatGPT can use Bing Search and Python interpreter out of the box in the paid version. OpenAI is a step ahead and provides fine-tuned LLM models for tool usage</description>
      <guid isPermaLink="false">https://blog.langchain.com/json-based-agents-with-ollama-and-langchain/</guid>
      <pubDate>Tue, 20 Feb 2024 09:24:29 -0800</pubDate>
    </item>
    <item>
      <title>Supercharging If-Statements With Prompt Classification Using Ollama and LangChain</title>
      <link>https://blog.langchain.com/supercharging-if-statements-with-prompt-classification-using-ollama-and-langchain/</link>
      <description>Editor's Note: Andrew Nguonly has been building one of the more impressive projects we've seen recently - an LLM co-pilot for browsing the web, powered by local LLMs. There are a lot of small architectural decisions made that contain a ton of nuance, and so we're super excited to post this blog by him going over one of them in detail.


Reintroducing Lumos! 🪄

I’ve written extensively about Lumos in the past so I’ll keep the reintroduction short and sweet. Lumos is an LLM co-pilot for browsing </description>
      <guid isPermaLink="false">https://blog.langchain.com/supercharging-if-statements-with-prompt-classification-using-ollama-and-langchain/</guid>
      <pubDate>Mon, 19 Feb 2024 09:16:07 -0800</pubDate>
    </item>
    <item>
      <title>Winning in AI means mastering the new stack</title>
      <link>https://blog.langchain.com/winning-in-ai-means-mastering-the-new-stack/</link>
      <description>Authors: Edo Liberty, Guillermo Rauch, Ori Goshen, Robert Nishihara, Harrison Chase


AI in 2030

AI is rapidly changing. Too rapidly for most. Ten years ago it was all about big data and ML. Deep Learning was a “buzzy” term that was just picking up steam. The term “AI” was still reserved for the futuristic dream of human level intelligence. The technology was used mostly by hyperscalers for advertising optimizations, search, feed ranking in online media, product recommendation in shopping, abus</description>
      <guid isPermaLink="false">https://blog.langchain.com/winning-in-ai-means-mastering-the-new-stack/</guid>
      <pubDate>Fri, 16 Feb 2024 12:02:46 -0800</pubDate>
    </item>
    <item>
      <title>Announcing the General Availability of LangSmith and Our Series A Led By Sequoia Capital</title>
      <link>https://blog.langchain.com/langsmith-ga/</link>
      <description>Today, we’re thrilled to announce the general availability of LangSmith — our solution for LLM application development, monitoring, and testing. We initially launched LangSmith in closed beta in July 2023. Since then, we’ve received invaluable feedback from our early users and customers, and made significant improvements to the platform based on their input. We’ve also made heavy investments in our infrastructure to ensure that the platform is able to seamlessly scale to accommodate our rapidly </description>
      <guid isPermaLink="false">https://blog.langchain.com/langsmith-ga/</guid>
      <pubDate>Thu, 15 Feb 2024 08:00:38 -0800</pubDate>
    </item>
    <item>
      <title>Rakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients and employees</title>
      <link>https://blog.langchain.com/customers-rakuten/</link>
      <description>Rakuten Group is well known for operating one of the largest online shopping malls in Japan. The company has 70+ businesses in fields such as e-commerce, travel, digital content, fintech, communications and more.

Adopting new technologies to push the frontiers of what’s possible is in the DNA of the company, and Rakuten Group has invested in delivering AI applications to better service their end users, clients and employees with a unified product suite.

Rakuten AI for Business is a comprehensi</description>
      <guid isPermaLink="false">https://blog.langchain.com/customers-rakuten/</guid>
      <pubDate>Wed, 14 Feb 2024 12:20:31 -0800</pubDate>
    </item>
    <item>
      <title>How Dataherald Makes Natural Language to SQL Easy</title>
      <link>https://blog.langchain.com/dataherald/</link>
      <description>Editor's Note: we're excited to feature this guest post from the Dataherald team. Text-to-SQL is a HUGE use case, and Dataherald is the open-source leader in the space. This is a great look behind the curtains to see what makes it tick.

When ChatGPT came out in late 2022, everyone went over to see if AI could do their day to day work. Marketers wanted their blog posts written, college students their essays, and developers their helper functions. For those working with relational data, the test </description>
      <guid isPermaLink="false">https://blog.langchain.com/dataherald/</guid>
      <pubDate>Wed, 14 Feb 2024 09:09:09 -0800</pubDate>
    </item>
    <item>
      <title>Plan-and-Execute Agents</title>
      <link>https://blog.langchain.com/planning-agents/</link>
      <description>Plan and execute agents promise faster, cheaper, and more performant task execution over previous agent designs. Learn how to build 3 types of planning agents in LangGraph in this post.</description>
      <guid isPermaLink="false">https://blog.langchain.com/planning-agents/</guid>
      <pubDate>Tue, 13 Feb 2024 08:35:24 -0800</pubDate>
    </item>
    <item>
      <title>BCG X Releases AgentKit, a Full-Stack Starter Kit for Building Constrained Agents</title>
      <link>https://blog.langchain.com/bcg-x-releases-agentkit-a-full-stack-starter-kit-for-building-constrained-agents/</link>
      <description>Editor's Note: We're very excited to share this work by BCG. We've worked closely with the BCG over the past year to help support companies bring GenAI initiatives into production. We were intrigued to hear about their AgentKit platform, and once we got a closer look we were even more excited. We hope you all are as well!


Introduction 

BCG X is excited to announce today's release of AgentKit, a LangChain-based starter kit to build constrained agent applications. We frequently use LangChain in</description>
      <guid isPermaLink="false">https://blog.langchain.com/bcg-x-releases-agentkit-a-full-stack-starter-kit-for-building-constrained-agents/</guid>
      <pubDate>Mon, 12 Feb 2024 08:38:19 -0800</pubDate>
    </item>
    <item>
      <title>LangChain Partners with CommandBar on their Copilot User Assistant</title>
      <link>https://blog.langchain.com/langchain-partners-with-commandbar-on-their-copilot-user-assistant/</link>
      <description>CommandBar is a user assistance platform that helps software companies make their products easy to use by capturing and predicting user intent, and then delivering personalized in-product help. CommandBar’s Copilot widget, which companies embed into their applications, goes beyond a typical chatbot. It can answer user questions, trigger personalized product tours, even fulfill a user’s intent directly by carrying out actions on their behalf.

CommandBar’s customers have slightly different needs </description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-partners-with-commandbar-on-their-copilot-user-assistant/</guid>
      <pubDate>Thu, 08 Feb 2024 13:10:49 -0800</pubDate>
    </item>
    <item>
      <title>Human-in-the-loop with OpenGPTs and LangGraph</title>
      <link>https://blog.langchain.com/human-in-the-loop-with-opengpts-and-langgraph/</link>
      <description>TLDR; Today we’re launching two “human in the loop” features in OpenGPTs, Interrupt and Authorize, both powered by LangGraph.

We've recently launched LangGraph, a library to help developers build multi-actor, multi-step, stateful LLM applications. That's a lot words packed into a short sentence, let's take it one at a time


Multi-actor

A team of specialists can build something together that none of them could build alone. The same is true of LLM applications: an LLM (great at answer generatio</description>
      <guid isPermaLink="false">https://blog.langchain.com/human-in-the-loop-with-opengpts-and-langgraph/</guid>
      <pubDate>Thu, 08 Feb 2024 08:56:41 -0800</pubDate>
    </item>
    <item>
      <title>Self-Reflective RAG with LangGraph</title>
      <link>https://blog.langchain.com/agentic-rag-with-langgraph/</link>
      <description>Key Links

 * Cookbooks for Self-RAG and CRAG
 * Video


Motivation

Because most LLMs are only periodically trained on a large corpus of public data, they lack recent information and / or private data that is inaccessible for training. Retrieval augmented generation (RAG) is a central paradigm in LLM application development to address this by connecting LLMs to external data sources (see our video series and blog post). The basic RAG pipeline involves embedding a user query, retrieving relevant</description>
      <guid isPermaLink="false">https://blog.langchain.com/agentic-rag-with-langgraph/</guid>
      <pubDate>Wed, 07 Feb 2024 08:47:25 -0800</pubDate>
    </item>
    <item>
      <title>Meet Connery: An Open-Source Plugin Infrastructure for OpenGPTs and LLM apps</title>
      <link>https://blog.langchain.com/meet-connery-an-open-source-plugin-infrastructure-for-opengpts-and-llm-apps/</link>
      <description>Editor's Note: this blog was written by Michael Liebmann and Volodymyr Machula, co-founders of Connery. Connery is an open-source framework for creating integrations as plugins usable across many platforms, including as tools for LLM-powered agents!

Over the past decade, Volodymyr and I have created all sorts of integrations. This includes everything from traditional system integrations and customizations to creating plugins for LLM applications, CI/CD workflows, Slack, and no-code tools.

It’s</description>
      <guid isPermaLink="false">https://blog.langchain.com/meet-connery-an-open-source-plugin-infrastructure-for-opengpts-and-llm-apps/</guid>
      <pubDate>Wed, 07 Feb 2024 08:41:33 -0800</pubDate>
    </item>
    <item>
      <title>Generating Usable Text with AI</title>
      <link>https://blog.langchain.com/generating-usable-text-with-ai/</link>
      <description>Editor's Note: This post was written by Mutt Data through LangChain's Partner Program.


Introduction


Overview

In our previous discussions, we not only delved into the challenges of implementing Generative AI applications in general but also explored effective mitigation strategies for image generation problems. Now, it's time to shift our focus to the unique set of challenges that arise when generating text.

In this blog post, we provide a concise overview of these challenges while sharing </description>
      <guid isPermaLink="false">https://blog.langchain.com/generating-usable-text-with-ai/</guid>
      <pubDate>Mon, 05 Feb 2024 11:47:37 -0800</pubDate>
    </item>
    <item>
      <title>OpenGPTs</title>
      <link>https://blog.langchain.com/opengpts/</link>
      <description>Key Links:

 * OpenGPTs GitHub Repo
 * OpenGPTs Walkthrough on YouTube
 * LangGraph: Python, JS

A little over two months ago, on the heels of OpenAI dev day, we launched OpenGPTs: a take on what an open-source GPT store may look like. It was powered by an early version of LangGraph - an extension of LangChain aimed at building agents as graphs. At the time, we did not highlight this new package much, as we had not publicly launched it and were still figuring out the interface. We finally got ar</description>
      <guid isPermaLink="false">https://blog.langchain.com/opengpts/</guid>
      <pubDate>Wed, 31 Jan 2024 08:47:26 -0800</pubDate>
    </item>
    <item>
      <title>LangSmith's Latest Feature: Grouped Monitoring Charts</title>
      <link>https://blog.langchain.com/grouped-monitoring-charts/</link>
      <description>Tag and Metadata Grouping

LangSmith has long supported monitoring charts to showcase important performance and feedback metrics overtime for your LLM applications (see the Monitoring section in any project details page). However, until now, it wasn't possible to compare metrics of logged traces containing different tags or metadata. In LLM applications, there can often be many knobs at your disposal (model params, prompt, chunking strategy, look-back window), each having a potentially huge impa</description>
      <guid isPermaLink="false">https://blog.langchain.com/grouped-monitoring-charts/</guid>
      <pubDate>Tue, 30 Jan 2024 09:55:48 -0800</pubDate>
    </item>
    <item>
      <title>LangChain partners with Elastic to launch the Elastic AI Assistant</title>
      <link>https://blog.langchain.com/langchain-partners-with-elastic-to-launch-the-elastic-ai-assistant/</link>
      <description>Elastic, a leading search analytics company, serving over 20k customers worldwide, enables organizations to securely harness search-powered AI so anyone can find the answers they need in real-time using all their data, at scale. By integrating AI with search technology, the company  facilitates the discovery of actionable insights from large volumes of both structured and unstructured data, addressing the need for real-time, scalable data processing. They have cloud-based solutions for search, s</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-partners-with-elastic-to-launch-the-elastic-ai-assistant/</guid>
      <pubDate>Tue, 30 Jan 2024 09:52:47 -0800</pubDate>
    </item>
    <item>
      <title>Mental Health Therapy as an LLM State Machine</title>
      <link>https://blog.langchain.com/mental-health-therapy-as-an-llm-state-machine/</link>
      <description>Editor's Note: this blog post was written by Chris from Sonia Health. We're particularly excited to highlight this for a few reasons. First, this is a use case with a really positive societal benefit. Second, the implementation mirrors how we are thinking about more complex workflows internally - as state machines! Check out LangGraph (which we just released) as an easy way to build these types of applications.


Mental Health Crisis

20% of Americans suffer with their mental health each year. W</description>
      <guid isPermaLink="false">https://blog.langchain.com/mental-health-therapy-as-an-llm-state-machine/</guid>
      <pubDate>Fri, 26 Jan 2024 08:55:34 -0800</pubDate>
    </item>
    <item>
      <title>How Mendable leverages LangSmith to debug Tools &amp; Actions</title>
      <link>https://blog.langchain.com/how-mendable-leverages-langsmith-to-debug-tools-actions/</link>
      <description>Editor's Note: this blog is from Nicolas Camara, CTO @ Mendable. Mendable.ai is a platform helping enterprise teams answer technical questions with AI. We're incredibly excited to highlight how they are using LangChain Agents and LangSmith on their newest feature: Tools &amp; Actions.

It is no secret that 2024 will be the year we start seeing more LLMs baked into our workflows. This means that the way we interact with LLM models will be less just Question and Answer and more action-based. 

At Mend</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-mendable-leverages-langsmith-to-debug-tools-actions/</guid>
      <pubDate>Thu, 25 Jan 2024 09:38:20 -0800</pubDate>
    </item>
    <item>
      <title>LangGraph: Multi-Agent Workflows</title>
      <link>https://blog.langchain.com/langgraph-multi-agent-workflows/</link>
      <description>Links

 * Python Examples
 * JS Examples
 * YouTube

Last week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.

Today, we're excited to highlight a sec</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph-multi-agent-workflows/</guid>
      <pubDate>Tue, 23 Jan 2024 09:32:37 -0800</pubDate>
    </item>
    <item>
      <title>LangGraph</title>
      <link>https://blog.langchain.com/langgraph/</link>
      <description>TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes.

 * Python Repo
 * Python YouTube Playlist
 * JS Repo


Introduction

One of the things we highlighted in our LangChain v0.1 announcement was the introduction of a new library: LangGraph. LangGraph is built on top of LangChain and completely interoperable with the LangChain ecosystem. It adds new value primarily through the introduction of an easy way to create cycl</description>
      <guid isPermaLink="false">https://blog.langchain.com/langgraph/</guid>
      <pubDate>Wed, 17 Jan 2024 09:46:54 -0800</pubDate>
    </item>
    <item>
      <title>Build and deploy a RAG app with Pinecone Serverless</title>
      <link>https://blog.langchain.com/pinecone-serverless/</link>
      <description>Key Links

 * Repo: https://github.com/langchain-ai/pinecone-serverless
 * Video: https://youtu.be/EhlPDL4QrWY


Context

LLMs are unlocking a new era of generative AI applications, becoming the kernel process of a new kind of operating system. Just as modern computers have RAM and file access, LLMs have a context window that can be loaded with information retrieved from external data sources, such as databases or vectorstores.

Retrieved information can be loaded into the context window and use</description>
      <guid isPermaLink="false">https://blog.langchain.com/pinecone-serverless/</guid>
      <pubDate>Tue, 16 Jan 2024 06:16:07 -0800</pubDate>
    </item>
    <item>
      <title>Ally Financial Collaborates with LangChain to Deliver Critical Coding Module to Mask Personal Identifying Information in a Compliant and Safe Manner</title>
      <link>https://blog.langchain.com/ally-financial-collaborates-with-langchain-to-deliver-critical-coding-module-to-mask-personal-identifying-information-in-a-compliant-and-safe-manner/</link>
      <description>Ally Financial, the largest digital-only bank in the US and a leading auto lender, has recently collaborated with LangChain to release the first initial coding module that addresses a significant challenge for AI developers working with personal identifiable information (PII) in highly regulated, consumer-focused industries. The PII Masking module - available here - provides a starting point for organizations that frequently handle customer PII during the normal course of business – including th</description>
      <guid isPermaLink="false">https://blog.langchain.com/ally-financial-collaborates-with-langchain-to-deliver-critical-coding-module-to-mask-personal-identifying-information-in-a-compliant-and-safe-manner/</guid>
      <pubDate>Thu, 11 Jan 2024 08:33:43 -0800</pubDate>
    </item>
    <item>
      <title>LangChain v0.1.0</title>
      <link>https://blog.langchain.com/langchain-v0-1-0/</link>
      <description>Today we’re excited to announce the release of langchain 0.1.0, our first stable version. It is fully backwards compatible, comes in both Python and JavaScript, and comes with improved focus through both functionality and documentation. A stable version of LangChain helps us earn developer trust and gives us the ability to evolve the library systematically and safely.

 * Python GitHub Discussion
 * Python v0.1.0 Guides
 * JS v0.1.0 Guides
 * YouTube Walkthrough


Introduction

LangChain has bee</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-v0-1-0/</guid>
      <pubDate>Mon, 08 Jan 2024 08:39:54 -0800</pubDate>
    </item>
    <item>
      <title>LangChain State of AI 2023</title>
      <link>https://blog.langchain.com/langchain-state-of-ai-2023/</link>
      <description>In 2023 we saw an explosion of interest in Generative AI upon the heels of ChatGPT. All companies - from startups to enterprises - were (and still are) trying to figure out their GenAI strategy.

"How can we incorporate GenAI into our product? What reference architectures should we be following? What models are best for our use case? What is the technology stack we should be using? How can we test our LLM applications?"

These are all questions that companies are asking themselves. In a time of </description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-state-of-ai-2023/</guid>
      <pubDate>Thu, 21 Dec 2023 08:20:36 -0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Agent Tool Use</title>
      <link>https://blog.langchain.com/benchmarking-agent-tool-use/</link>
      <description>Agents may be the “killer” LLM app, but building and evaluating agents is hard. Function calling is a key skill for effective tool use, but there aren’t many good benchmarks for measuring function calling performance. Today, we are excited to release four new test environments for benchmarking LLMs’ ability to effectively use tools to accomplish tasks. We hope this makes it easier for everyone to test different LLM and prompting strategies to show what enables the best agentic behavior.

We desi</description>
      <guid isPermaLink="false">https://blog.langchain.com/benchmarking-agent-tool-use/</guid>
      <pubDate>Tue, 19 Dec 2023 22:28:18 -0800</pubDate>
    </item>
    <item>
      <title>How Rubric Labs and Graphite leveraged LLMs to create personalized videos at scale</title>
      <link>https://blog.langchain.com/rubric-labs-graphite-personalized-video-at-scale/</link>
      <description>How Rubric Labs and Graphite generated personalized, unique GitHub Wrapped 2023 videos for each user.</description>
      <guid isPermaLink="false">https://blog.langchain.com/rubric-labs-graphite-personalized-video-at-scale/</guid>
      <pubDate>Tue, 19 Dec 2023 10:27:38 -0800</pubDate>
    </item>
    <item>
      <title>Benchmarking RAG on tables</title>
      <link>https://blog.langchain.com/benchmarking-rag-on-tables/</link>
      <description>Key links

LangChain public benchmark evaluation notebooks:

 * Long context LLMs here
 * Chunk size tuning here
 * Multi vector with ensemble here


Motivation

Retrieval augmented generation (RAG) is one of the most important concepts in LLM app development. Documents of many types can be passed into the context window of an LLM, enabling interactive chat or Q+A assistants. Reasoning over information in tables is an important application of RAG since tables are common in documents such as whit</description>
      <guid isPermaLink="false">https://blog.langchain.com/benchmarking-rag-on-tables/</guid>
      <pubDate>Wed, 13 Dec 2023 08:21:48 -0800</pubDate>
    </item>
    <item>
      <title>Towards LangChain 0.1: LangChain-Core and LangChain-Community</title>
      <link>https://blog.langchain.com/the-new-langchain-architecture-langchain-core-v0-1-langchain-community-and-a-path-to-langchain-v0-1/</link>
      <description>The goal of LangChain has always been to make it as easy as possible to develop context-aware reasoning applications with LLMs. LangChain started as a side project, and purely as a Python package. Over the past year it has grown tremendously. This growth has been a forcing function to rethink the architecture of the package. We’ve been listening to the community and are announcing a re-architecture of the package into multiple packages (done in a completely backwards compatible way), a path towa</description>
      <guid isPermaLink="false">https://blog.langchain.com/the-new-langchain-architecture-langchain-core-v0-1-langchain-community-and-a-path-to-langchain-v0-1/</guid>
      <pubDate>Tue, 12 Dec 2023 10:16:34 -0800</pubDate>
    </item>
    <item>
      <title>Multi-modal RAG on slide decks</title>
      <link>https://blog.langchain.com/multi-modal-rag-template/</link>
      <description>Key Links

 * LangChain public benchmark evaluation notebooks
 * LangChain template for multi-modal RAG on presentations


Motivation

Retrieval augmented generation (RAG) is one of the most important concepts in LLM app development. Documents of many types can be passed into the context window of an LLM, enabling interactive chat or Q+A assistants. While many of the RAG apps to date have focused on text, a great deal of information is conveyed as visual content. As an example, slide decks are c</description>
      <guid isPermaLink="false">https://blog.langchain.com/multi-modal-rag-template/</guid>
      <pubDate>Wed, 06 Dec 2023 08:30:07 -0800</pubDate>
    </item>
    <item>
      <title>Transforming Mortgage Ops with LangChain &amp; LangSmith</title>
      <link>https://blog.langchain.com/transforming-mortgage-ops-with-langchain-langsmith/</link>
      <description>Editor's Note: This post was written by Sasha Aptlin at Aptford through LangChain's Partner Program.

Meet Maya, a loan officer at InstaMortgage, whose professional life was once consumed by the flood of loan applications and constant demands for accuracy and precision. Imagine her desk, buried under piles of paperwork, her inbox constantly filled with client requests, her days a never-ending cycle of entering data manually and conducting thorough reviews.

At InstaMortgage, Maya is not just a l</description>
      <guid isPermaLink="false">https://blog.langchain.com/transforming-mortgage-ops-with-langchain-langsmith/</guid>
      <pubDate>Tue, 05 Dec 2023 15:37:48 -0800</pubDate>
    </item>
    <item>
      <title>Extraction Benchmarking</title>
      <link>https://blog.langchain.com/extraction-benchmarking/</link>
      <description>








Test
confidence_level_similarity
json_edit_distance
json_schema
off_topic_similarity
programming_language_similarity
question_category
sentiment_similarity
toxicity_similarity




claude-2-xsd-to-xml-5689
0.97
0.39
0.52
0.00
0.52
0.37
0.91
1.0


claude-2-json-schema-to-xml-5689
0.97
0.37
0.78
0.00
0.44
0.48
0.93
1.0


gpt-4-1106-preview-5689
0.94
0.28
1.00
0.89
0.59
0.56
1.00
0.0













Test
confidence_level_similarity
json_edit_distance
json_schema
off_topic_similarity
programmin</description>
      <guid isPermaLink="false">https://blog.langchain.com/extraction-benchmarking/</guid>
      <pubDate>Tue, 05 Dec 2023 10:16:55 -0800</pubDate>
    </item>
    <item>
      <title>Deconstructing RAG</title>
      <link>https://blog.langchain.com/deconstructing-rag/</link>
      <description>Context

In a recent overview on the state of large language models (LLMs), Karpathy described LLMs as the kernel process of a new kind of operating system. Just as modern computers have RAM and access to files, LLMs have a context window that can be loaded with information retrieved from numerous data sources.

This retrieved information is loaded into the context window and used in LLM output generation, a process typically called retrieval augmented generation (RAG). RAG is one of the most im</description>
      <guid isPermaLink="false">https://blog.langchain.com/deconstructing-rag/</guid>
      <pubDate>Thu, 30 Nov 2023 08:07:12 -0800</pubDate>
    </item>
    <item>
      <title>Adding Long Term Memory to OpenGPTs</title>
      <link>https://blog.langchain.com/adding-long-term-memory-to-opengpts/</link>
      <description>Three weeks ago we launched OpenGPTs, an implementation of OpenAI GPTs and Assistant API but in an open source manner. OpenGPTs allows for implementation of conversational agents - a flexible and futuristic cognitive architecture. One large part of agents is memory. In their current implementation, GPTs, OpenGPTs, and the Assistants API only really support basic conversational memory. Longer term memory is an underexplored area. In this blog post we will talk a little bit about how we think abou</description>
      <guid isPermaLink="false">https://blog.langchain.com/adding-long-term-memory-to-opengpts/</guid>
      <pubDate>Wed, 29 Nov 2023 13:49:12 -0800</pubDate>
    </item>
    <item>
      <title>OpenAI's Bet on a Cognitive Architecture</title>
      <link>https://blog.langchain.com/openais-bet-on-a-cognitive-architecture/</link>
      <description>Three weeks ago OpenAI held a highly anticipated developer day. They released a myriad of new features. The two most interesting to me were the Assistants API and GPTs. To me, these represent the same bet – on a particular, agent-like, closed “cognitive architecture”. They appeal to different end users, but both speak to OpenAI’s ambitions to drive applications towards this particular cognitive architecture. At LangChain, we believe in a world where LLMs power agent-like systems that are truly t</description>
      <guid isPermaLink="false">https://blog.langchain.com/openais-bet-on-a-cognitive-architecture/</guid>
      <pubDate>Tue, 28 Nov 2023 08:55:44 -0800</pubDate>
    </item>
    <item>
      <title>LLMs accelerate Adyen's support team through smart-ticket routing and support agent copilot</title>
      <link>https://blog.langchain.com/llms-accelerate-adyens-support-team-through-smart-ticket-routing-and-support-agent-copilot/</link>
      <description>Challenge

As global commerce accelerates, Adyen, a publicly-traded financial technology platform, is helping large companies like Meta, Uber, H&amp;M, and Microsoft achieve their ambitions faster by providing end-to-end payments capabilities, data-driven insights, and financial products in a single global solution. 

With more merchants signing on and with increased transaction volume comes increased pressure on support teams and a team at Adyen that immediately sought out leveraged solutions. "We </description>
      <guid isPermaLink="false">https://blog.langchain.com/llms-accelerate-adyens-support-team-through-smart-ticket-routing-and-support-agent-copilot/</guid>
      <pubDate>Tue, 28 Nov 2023 08:19:49 -0800</pubDate>
    </item>
    <item>
      <title>Sharing LangSmith Benchmarks</title>
      <link>https://blog.langchain.com/public-langsmith-benchmarks/</link>
      <description>The single biggest pain point we hear from developers taking their apps into production is around testing and evaluation. This difficulty is felt more acutely due to the constant onslaught of new models, new retrieval techniques, new agent types, and new cognitive architectures.

Over the past months, we've made LangSmith the best place to go for LLM architecture evaluation (test comparison view, dataset curation). Today we're making it possible to share evaluation datasets and results, to more </description>
      <guid isPermaLink="false">https://blog.langchain.com/public-langsmith-benchmarks/</guid>
      <pubDate>Wed, 22 Nov 2023 09:04:34 -0800</pubDate>
    </item>
    <item>
      <title>Introducing Dream – an AI no-code tool to build fully functional web apps and components with natural language</title>
      <link>https://blog.langchain.com/introducing-dream/</link>
      <description>I’m Calix, and I’m currently a sophomore at USC Iovine &amp; Young Academy. For my hacker residency at LangChain, I continued working on my project, Dream.

Dream is an AI no-code tool to build fully functional web apps and components with natural language. Whether it’s an AI app, a game, or an internal tool, Dream is a way for any technical or non-technical person to build and deploy functional websites. Users on Dream can create website projects, they can create pages within each project, and with</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-dream/</guid>
      <pubDate>Tue, 21 Nov 2023 09:15:50 -0800</pubDate>
    </item>
    <item>
      <title>Introducing Tuna - A Tool for Rapidly Generating Synthetic Fine-Tuning Datasets</title>
      <link>https://blog.langchain.com/introducing-tuna-a-tool-for-rapidly-generating-synthetic-fine-tuning-datasets/</link>
      <description>Editor's Note: This post was written by Andrew Kean Gao through LangChain's Student Hacker in Residence Program.


Brief Overview

Tuna is a no-code tool for quickly generating LLM fine-tuning datasets from scratch. This enables anyone to create high-quality training data for fine-tuning large language models like the LLaMas. There is both a web interface (Streamlit) and a Python script (Repl.it, recommended for speed). 

You provide an input CSV file of text data that will be individually sent </description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-tuna-a-tool-for-rapidly-generating-synthetic-fine-tuning-datasets/</guid>
      <pubDate>Tue, 21 Nov 2023 09:14:13 -0800</pubDate>
    </item>
    <item>
      <title>Applying OpenAI's RAG Strategies</title>
      <link>https://blog.langchain.com/applying-openai-rag/</link>
      <description>Context

At their demo day, Open AI reported a series of RAG experiments for a customer that they worked with. While evaluation metics will depend on your specific application, it’s interesting to see what worked and what didn't for them. Below, we expand on each method mention and show how you can implement each one for yourself. The ability to understand and these methods on your application is critical: from talking to many partners and users, there is no "one-size-fits-all" solution because </description>
      <guid isPermaLink="false">https://blog.langchain.com/applying-openai-rag/</guid>
      <pubDate>Fri, 17 Nov 2023 08:57:04 -0800</pubDate>
    </item>
    <item>
      <title>"Research Assistant": Exploring UXs Besides Chat</title>
      <link>https://blog.langchain.com/exploring-uxs-besides-chat-with-research-assistant/</link>
      <description>TLDR: We’re excited to announce a new LangChain template for helping with research, heavily inspired by and in collaboration with the GPT Researcher team. We are excited about this because it is one of the best performing, long-running, general, non-chat “cognitive architectures” that we’ve seen.

Key Links:

 * Access the “research assistant” template here
 * Watch us code the "research assistant" from scratch here


The Downside of Chat

Most LLM applications so far have been chat based. This </description>
      <guid isPermaLink="false">https://blog.langchain.com/exploring-uxs-besides-chat-with-research-assistant/</guid>
      <pubDate>Thu, 16 Nov 2023 07:32:54 -0800</pubDate>
    </item>
    <item>
      <title>LangChain Expands Collaboration with Microsoft</title>
      <link>https://blog.langchain.com/langchain-expands-collaboration-with-microsoft/</link>
      <description>Today, we’re thrilled to announce a collaboration between LangChain and Microsoft.

LangChain helps developers build context-aware reasoning applications and powers some of the most exciting products in AI. And Microsoft has repeatedly pushed the frontier of innovation and safety in technology broadly. 

By collaborating more closely with Microsoft, we’re thrilled to offer our joint customers deeper product integrations that live up to our company’s commitment to AI with the enterprise assurance</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-expands-collaboration-with-microsoft/</guid>
      <pubDate>Wed, 15 Nov 2023 11:33:47 -0800</pubDate>
    </item>
    <item>
      <title>Query Construction</title>
      <link>https://blog.langchain.com/query-construction/</link>
      <description>Key Links

 * Text-to-metadata: Updated self-query docs and template
 * Text-to-SQL+semantic: Cookbook and template

There's great interest in seamlessly connecting natural language with diverse types of data (structured, unstructured, and semi-structured). But, this emerging "LUI" (language user interface) has specific challenges/considerations for each data type:

 * Structured Data: Predominantly housed within SQL or Graph databases, structured data is characterized by predefined schemas and </description>
      <guid isPermaLink="false">https://blog.langchain.com/query-construction/</guid>
      <pubDate>Tue, 14 Nov 2023 08:07:16 -0800</pubDate>
    </item>
    <item>
      <title>Morningstar Intelligence Engine puts personalized investment insights at analysts' fingertips</title>
      <link>https://blog.langchain.com/morningstar-intelligence-engine-puts-personalized-investment-insights-at-analysts-fingertips/</link>
      <description>Challenge

Financial services is one of the most data-driven industries and financial professionals are always hungry for more data and better tools to drive value for their clients. Morningstar–a publicly-traded investment research firm–has been compiling and analyzing fund, stock, and general market data for finance professionals since its founding in 1984. 

Getting the most out of Morningstar and its products has historically required a deep familiarity with the financial landscape, an abili</description>
      <guid isPermaLink="false">https://blog.langchain.com/morningstar-intelligence-engine-puts-personalized-investment-insights-at-analysts-fingertips/</guid>
      <pubDate>Tue, 14 Nov 2023 04:26:32 -0800</pubDate>
    </item>
    <item>
      <title>Parallel Function Calling for Structured Data Extraction</title>
      <link>https://blog.langchain.com/parallel-function-calling-extraction/</link>
      <description>Important Links:

 * Cookbook for extraction using parallel function calling

One of the biggest use cases for language models that we see is in extraction. This is where the language model is used to extract multiple pieces of structured information from unstructured documents. The biggest challenge developers faced here was in getting the language model to correctly output valid JSON.

OpenAI helped immensely with that when they introduced function calling in early 2023. At a high level, funct</description>
      <guid isPermaLink="false">https://blog.langchain.com/parallel-function-calling-extraction/</guid>
      <pubDate>Thu, 09 Nov 2023 08:10:14 -0800</pubDate>
    </item>
    <item>
      <title>♠️ SPADE: Automatically Digging up Evals based on Prompt Refinements</title>
      <link>https://blog.langchain.com/spade-automatically-digging-up-evals-based-on-prompt-refinements/</link>
      <description>Written by Shreya Shankar (UC Berkeley) in collaboration with Haotian Li (HKUST), Will Fu-Hinthorn (LangChain), Harrison Chase (LangChain), J.D. Zamfirescu-Pereira (UC Berkeley), Yiming Lin (UC Berkeley), Sam Noyes (LangChain), Eugene Wu (Columbia University), Aditya Parameswaran (UC Berkeley)

💡Key Links:
- Use SPADE to discover evaluation suggestions for your prompts.
- Complete the interest form to connect with the Berkeley researchers.
- Try out LangSmith and Hub to build and version contro</description>
      <guid isPermaLink="false">https://blog.langchain.com/spade-automatically-digging-up-evals-based-on-prompt-refinements/</guid>
      <pubDate>Wed, 08 Nov 2023 08:33:08 -0800</pubDate>
    </item>
    <item>
      <title>Implementing advanced RAG strategies with Neo4j</title>
      <link>https://blog.langchain.com/implementing-advanced-retrieval-rag-strategies-with-neo4j/</link>
      <description>Editor's note: We're excited to share this blogpost as it covers several of the advanced retrieval strategies we introduced in the past month, specifically a lot of the ones that rely on changing the ingestion step. A lot of these advanced retrieval strategies can be summarized as changing how indexing of documents is done to retain some concept of hierarchy. Neo4j is an exciting database to use for these tasks since it can represent these hierarchies as part of the graph. This also allows you t</description>
      <guid isPermaLink="false">https://blog.langchain.com/implementing-advanced-retrieval-rag-strategies-with-neo4j/</guid>
      <pubDate>Tue, 07 Nov 2023 10:32:09 -0800</pubDate>
    </item>
    <item>
      <title>Embeddings Drive the Quality of RAG: Voyage AI in Chat LangChain</title>
      <link>https://blog.langchain.com/voyage-embeddings-in-langchain-and-chat-langchain/</link>
      <description>Editor's Note: This post was written by the Voyage AI team.

This post demonstrates that the choice of embedding models significantly impacts the overall quality of a chatbot based on Retrieval-Augmented Generation (RAG). We focus on the case of Chat LangChain, the LangChain chatbot for answering questions about LangChain documentation, which currently uses fine-tuned Voyage embeddings in production. We finish by showing how to access general Voyage embedding models via LangChain.


Brief backgr</description>
      <guid isPermaLink="false">https://blog.langchain.com/voyage-embeddings-in-langchain-and-chat-langchain/</guid>
      <pubDate>Thu, 02 Nov 2023 09:51:18 -0700</pubDate>
    </item>
    <item>
      <title>LangChain Templates</title>
      <link>https://blog.langchain.com/langchain-templates/</link>
      <description>Today we're excited to announce the release of LangChain Templates. LangChain Templates offers a collection of easily deployable reference architectures that anyone can use. We've worked with some of our partners to create a set of easy-to-use templates to help developers get to production more quickly. We will continue to add to this over time. This is a new way to create, share, maintain, download, and customize chains and agents. They are all in a standard format with allows them to easily be</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-templates/</guid>
      <pubDate>Tue, 31 Oct 2023 08:18:26 -0700</pubDate>
    </item>
    <item>
      <title>Announcing Data Annotation Queues</title>
      <link>https://blog.langchain.com/announcing-data-annotation-queue/</link>
      <description>💡Data Annotation Queues are a new feature in LangSmith, our developer platform aimed at helping bring LLM applications from prototype to production. Sign up for the beta here.

LangSmith was launched with the goal of making it easier to take an LLM application from prototype to production. One of the main blockers here is improving the performance of your application and making it more reliable than just a Twitter.

There are several ways to do that. At the most basic, it's useful to look caref</description>
      <guid isPermaLink="false">https://blog.langchain.com/announcing-data-annotation-queue/</guid>
      <pubDate>Thu, 26 Oct 2023 08:39:02 -0700</pubDate>
    </item>
    <item>
      <title>Query Transformations</title>
      <link>https://blog.langchain.com/query-transformations/</link>
      <description>Naive RAG typically splits documents into chunks, embeds them, and retrieves chunks with high semantic similarity to a user question. But, this present a few problems: (1) document chunks may contain irrelevant content that degrades retrieval, (2) user questions may be poorly worded for retrieval, and (3) structured queries may need to be generated from the user question (e.g., for querying a vectorstore with metadata filtering or a SQL db).

LangChain has many advanced retrieval methods to help</description>
      <guid isPermaLink="false">https://blog.langchain.com/query-transformations/</guid>
      <pubDate>Tue, 24 Oct 2023 09:50:11 -0700</pubDate>
    </item>
    <item>
      <title>LangChain's First Birthday</title>
      <link>https://blog.langchain.com/langchains-first-birthday/</link>
      <description>It’s LangChain’s first birthday! It’s been a really exciting year!

We worked with thousands of developers building LLM applications and tooling. We shipped and learned a lot. We grew our team. And best of all, we met so many people from all over the world exploring the possibilities of Generative AI.

Today, we’re feeling especially grateful for our community. Here are some reflections and highlights from our first year building together.

Thank you.


In numbers

 * Over 2,000 developers contr</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchains-first-birthday/</guid>
      <pubDate>Tue, 24 Oct 2023 07:51:17 -0700</pubDate>
    </item>
    <item>
      <title>Beyond Text: Making GenAI Applications Accessible to All</title>
      <link>https://blog.langchain.com/beyond-text-making-genai-applications-accessible-to-all/</link>
      <description>Editor's Note: This post was written by Andres Torres and Dylan Brock from Norwegian Cruise Line. Building UI/UX for AI applications is hard and there's lot of subtleties. This is a fantastic deep dive into the issues and concerns they are thinking about.

Everyone loves having some vacation and time to enjoy with their loved ones. At Norwegian Cruise Line, our team mission is to provide exceptional vacation experiences through a commitment to world-class hospitality and innovation. This experie</description>
      <guid isPermaLink="false">https://blog.langchain.com/beyond-text-making-genai-applications-accessible-to-all/</guid>
      <pubDate>Mon, 23 Oct 2023 07:25:18 -0700</pubDate>
    </item>
    <item>
      <title>Robocorp’s code generation assistant makes building Python automation easy for developers</title>
      <link>https://blog.langchain.com/robocorps-code-gen-assistant-makes-building-python-automation-easy-for-developers/</link>
      <description>Challenge

Robocorp was founded in 2019 out of frustration that the promise of developers being able to automate monotonous work hadn’t been realized. Right out of the gate, their Python-based platform helped teams of all shapes and sizes build and operate automations more efficiently. But, they knew they could deliver even more value for their customers through Generative AI by helping the automation developers write better code, faster.


Solution

The Robocorp team conceived an AI-powered dev</description>
      <guid isPermaLink="false">https://blog.langchain.com/robocorps-code-gen-assistant-makes-building-python-automation-easy-for-developers/</guid>
      <pubDate>Sun, 22 Oct 2023 10:46:54 -0700</pubDate>
    </item>
    <item>
      <title>Multi-Vector Retriever for RAG on tables, text, and images</title>
      <link>https://blog.langchain.com/semi-structured-multi-modal-rag/</link>
      <description>Summary

Seamless question-answering across diverse data types (images, text, tables) is one of the holy grails of RAG. We’re releasing three new cookbooks that showcase the multi-vector retriever for RAG on documents that contain a mixture of content types. These cookbooks as also present a few ideas for pairing multimodal LLMs with the multi-vector retriever to unlock RAG on images.

 * Cookbook for semi-structured (tables + text) RAG
 * Cookbook for multi-modal (text + tables + images) RAG
 *</description>
      <guid isPermaLink="false">https://blog.langchain.com/semi-structured-multi-modal-rag/</guid>
      <pubDate>Fri, 20 Oct 2023 08:27:19 -0700</pubDate>
    </item>
    <item>
      <title>LangServe Playground and Configurability</title>
      <link>https://blog.langchain.com/langserve-playground-and-configurability/</link>
      <description>Last week we launched LangServe, a way to easily deploy chains and agents in a production-ready manner. Specifically, it takes a chain and easily spins up a FastAPI server with streaming and batch endpoints, as well as providing a way to stream intermediate steps.

This week, we're making some additions – a playground and configurability. Both are centered around the same ideas: common architectures, experimentation, and collaboration.


Playground

Now when you use LangServe to deploy your chai</description>
      <guid isPermaLink="false">https://blog.langchain.com/langserve-playground-and-configurability/</guid>
      <pubDate>Thu, 19 Oct 2023 10:36:11 -0700</pubDate>
    </item>
    <item>
      <title>Constructing knowledge graphs from text using OpenAI functions: Leveraging knowledge graphs to power LangChain Applications</title>
      <link>https://blog.langchain.com/constructing-knowledge-graphs-from-text-using-openai-functions/</link>
      <description>Editor's Note: This post was written by Tomaz Bratanic from the Neo4j team.

Extracting structured information from unstructured data like text has been around for some time and is nothing new. However, LLMs brought a significant shift to the field of information extraction. If before you needed a team of machine learning experts to curate datasets and train custom models, you only need access to an LLM nowadays. The barrier to entry has dropped significantly, making what was just a couple of ye</description>
      <guid isPermaLink="false">https://blog.langchain.com/constructing-knowledge-graphs-from-text-using-openai-functions/</guid>
      <pubDate>Thu, 19 Oct 2023 08:05:25 -0700</pubDate>
    </item>
    <item>
      <title>A Chunk by Any Other Name: Structured Text Splitting and Metadata-enhanced RAG</title>
      <link>https://blog.langchain.com/a-chunk-by-any-other-name/</link>
      <description>





















There's something of a structural irony in the fact that building context-aware LLM applications typically begins with a systematic process of decontextualization, wherein


 1. source text is divided into more or less arbitrarily-sized pieces before
 2. each piece undergoes a vector embedding process designed to comprehend context, to capture information inherent in relations between pieces of text.


Not altogether unlike the way human readers interact with natural langua</description>
      <guid isPermaLink="false">https://blog.langchain.com/a-chunk-by-any-other-name/</guid>
      <pubDate>Wed, 18 Oct 2023 14:57:05 -0700</pubDate>
    </item>
    <item>
      <title>You.com x LangChain</title>
      <link>https://blog.langchain.com/you-com-x-langchain/</link>
      <description>Editor's Note: the following is a guest blog post from our friends at You.com. We've seen a lot of interesting use cases around interacting with the internet, and we're always looking for new tools to highlight to our community that can help do that. So when You.com mentioned they would releasing an API access to their search engine - the same one they use to power their AI assistant - we jumped at the opportunity to help them highlight this.

This blog post walks through some results highlighti</description>
      <guid isPermaLink="false">https://blog.langchain.com/you-com-x-langchain/</guid>
      <pubDate>Wed, 18 Oct 2023 10:27:49 -0700</pubDate>
    </item>
    <item>
      <title>The Prompt Landscape</title>
      <link>https://blog.langchain.com/the-prompt-landscape/</link>
      <description>Context

Prompt Engineering can steer LLM behavior without updating the model weights. A variety of prompts for different uses-cases have emerged (e.g., see @dair_ai’s prompt engineering guide and this excellent review from Lilian Weng). As the number of LLMs and different use-cases expand, there is increasing need for prompt management to support discoverability, sharing, workshopping, and debugging prompts. We launched the LangChain Hub over a month ago to support these needs, serving as a hom</description>
      <guid isPermaLink="false">https://blog.langchain.com/the-prompt-landscape/</guid>
      <pubDate>Wed, 18 Oct 2023 09:00:10 -0700</pubDate>
    </item>
    <item>
      <title>Test Run Comparisons</title>
      <link>https://blog.langchain.com/test-run-comparisons/</link>
      <description>One pattern I noticed is that great AI researchers are willing to manually inspect lots of data. And more than that, they build infrastructure that allows them to manually inspect data quickly. Though not glamorous, manually examining data gives valuable intuitions about the problem.

- Jason Wei, OpenAI

Evaluations continue to be one of the hardest parts of building LLM applications. It's really tough to evaluate in a quantitative way the effect of changes to your prompt, chain, or agent. We'r</description>
      <guid isPermaLink="false">https://blog.langchain.com/test-run-comparisons/</guid>
      <pubDate>Tue, 17 Oct 2023 08:37:33 -0700</pubDate>
    </item>
    <item>
      <title>Testing Fine Tuned Open Source Models in LangSmith</title>
      <link>https://blog.langchain.com/testing-fine-tuned-open-source-models-in-langsmith/</link>
      <description>Editor's Note. This blog post was written by Ryan Brandt, the CTO and Cofounder of ChatOpenSource, a business specializing in enterprise AI chat that runs entirely within an orgs network, no third party needed. He covers how he uses LangSmith, LangChain's platform for getting LLM applications to production. Sign up for access here.

Open source models are increasingly capable for use in applications. The trend is only accelerating with recent releases like Mistral 7b and the Llama2 family. The f</description>
      <guid isPermaLink="false">https://blog.langchain.com/testing-fine-tuned-open-source-models-in-langsmith/</guid>
      <pubDate>Mon, 16 Oct 2023 07:41:27 -0700</pubDate>
    </item>
    <item>
      <title>How to design an Agent for Production</title>
      <link>https://blog.langchain.com/how-to-design-an-agent-for-production/</link>
      <description>Editor's Note: This post is written by Dexter Storey, Sarim Malik, and Ted Spare from the Rubric Labs team.


Important Links

 * GitHub repository
 * OpenAI Functions Agent by LangChain
 * Install Cal.ai


Goal

The purpose of this guide is to explain the underlying tech and logic used to deploy a scheduling agent, Cal.ai, in production using LangChain.


Context

Recently, our team at Rubric Labs had the opportunity to build Cal.com's AI-driven email assistant. For context, we’re a team of bui</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-to-design-an-agent-for-production/</guid>
      <pubDate>Sun, 15 Oct 2023 12:25:59 -0700</pubDate>
    </item>
    <item>
      <title>Building LLM-Powered Web Apps with Client-Side Technology</title>
      <link>https://blog.langchain.com/building-llm-powered-web-apps-with-client-side-technology/</link>
      <description>The initial version of this blog post was a talk for Google’s internal WebML Summit 2023, which you can check out here.

It’s no secret that for a long time machine learning has been mostly a Python game, but the recent surge in popularity of ChatGPT has brought many new developers into the field. With JavaScript being the most widely-used programming language, it’s no surprise that this has included many web developers, who have naturally tried to build web apps.

There’s been a ton of ink spil</description>
      <guid isPermaLink="false">https://blog.langchain.com/building-llm-powered-web-apps-with-client-side-technology/</guid>
      <pubDate>Fri, 13 Oct 2023 10:12:46 -0700</pubDate>
    </item>
    <item>
      <title>Introducing LangServe, the best way to deploy your LangChains</title>
      <link>https://blog.langchain.com/introducing-langserve/</link>
      <description>We think the LangChain Expression Language (LCEL) is the quickest way to prototype the brains of your LLM application. The next exciting step is to ship it to your users and get some feedback! Today we're making that a lot easier, launching LangServe. LangServe is the easiest and best way to deploy any any LangChain chain/agent/runnable.

Important Links:

 * LangServe Github Repo
 * Example repo (deploy on GCP)
 * Replit Template


Why it exists

Whether you’re building a customer-facing chatbo</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-langserve/</guid>
      <pubDate>Thu, 12 Oct 2023 10:14:04 -0700</pubDate>
    </item>
    <item>
      <title>Fine-tuning ChatGPT: Surpassing GPT-4 Summarization Performance–A 63% Cost Reduction and 11x Speed Enhancement using Synthetic Data and LangSmith</title>
      <link>https://blog.langchain.com/fine-tuning-chatgpt-surpassing-gpt-4-summarization/</link>
      <description>Editor's Note: This post was written by Charlie George, machine learning engineer at Elicit.


Summary

 * Fine-tuned ChatGPT beats GPT-4 for news article summarization using only synthetic data.
 * We quantify this improvement using human-level automated evaluation using the ScoreStringEvalChain and improved PairwiseStringEvalChain.


Context

GPT-4 is widely regarded as the world’s best language model, often capable of outperforming the average human in tasks that can be described in under 100</description>
      <guid isPermaLink="false">https://blog.langchain.com/fine-tuning-chatgpt-surpassing-gpt-4-summarization/</guid>
      <pubDate>Tue, 10 Oct 2023 14:27:48 -0700</pubDate>
    </item>
    <item>
      <title>Using a Knowledge Graph to implement a DevOps RAG application</title>
      <link>https://blog.langchain.com/using-a-knowledge-graph-to-implement-a-devops-rag-application/</link>
      <description>Editor's Note: This post was written in collaboration with the Neo4J team.

RAG applications are all the rage at the moment. Everyone is building their company documentation chatbot or similar. Mostly, they all have in common that their source of knowledge is unstructured text, which gets chunked and embedded in one way or another. However, not all information arrives as unstructured text.

Say, for example, you wanted to create a chatbot that could answer questions about your microservice archi</description>
      <guid isPermaLink="false">https://blog.langchain.com/using-a-knowledge-graph-to-implement-a-devops-rag-application/</guid>
      <pubDate>Wed, 04 Oct 2023 09:18:44 -0700</pubDate>
    </item>
    <item>
      <title>Building (and Breaking) WebLangChain</title>
      <link>https://blog.langchain.com/weblangchain/</link>
      <description>Important Links:

 * Hosted WebLangChain
 * Open-source code for WebLangChain


Introduction

One of the big shortcomings of LLMs is that they can only answer questions about data they were trained on. That is, unless you can connect them to external sources of knowledge or computation - exactly what LangChain was built to help enable. One of the most popular sources of knowledge to hook LLMs up to is the internet - from You.com to Perplexity to ChatGPT Browsing. In this blog post, we show how b</description>
      <guid isPermaLink="false">https://blog.langchain.com/weblangchain/</guid>
      <pubDate>Wed, 04 Oct 2023 08:33:51 -0700</pubDate>
    </item>
    <item>
      <title>Handling PII data in LangChain</title>
      <link>https://blog.langchain.com/handling-pii-data-in-langchain/</link>
      <description>This blog post was written by Francisco, a founder at Pampa Labs, who assists companies in developing LLM applications that are accurate and cost efficient.


Introduction

PII stands for “personally identifiable information” and it refers to personal data that can be used to uncover an individual’s identity. Lately, regulations such as GDPR make it so that companies find it increasingly important to find solutions that consider handling PII data effectively.

Managing PII data with LLMs can be </description>
      <guid isPermaLink="false">https://blog.langchain.com/handling-pii-data-in-langchain/</guid>
      <pubDate>Tue, 03 Oct 2023 08:06:31 -0700</pubDate>
    </item>
    <item>
      <title>Kay x Cybersyn x LangChain: Embedding SEC Filings for RAG</title>
      <link>https://blog.langchain.com/kay-x-cybersyn-x-langchain/</link>
      <description>Editor's Note: This post was written by the Kay team, in collaboration with Cybersyn. Financial data processing is hard. SEC Retriever on LangChain– Powered by Kay and Cybersyn–makes it easy for developers to retrieve context from SEC Filings for their generative and conversational agents.

Financial documents carry a wealth of nuanced information that is frequently used in high-stakes scenarios, from investing to corporate strategy. SEC Filings are a common source of such financial knowledge fo</description>
      <guid isPermaLink="false">https://blog.langchain.com/kay-x-cybersyn-x-langchain/</guid>
      <pubDate>Tue, 03 Oct 2023 07:13:40 -0700</pubDate>
    </item>
    <item>
      <title>Bringing Free OSS Models to the Playground with Fireworks AI</title>
      <link>https://blog.langchain.com/bringing-free-oss-models-to-the-playground-with-fireworks-ai/</link>
      <description>A year ago, the only real LLM people were using was OpenAI's GPT-3. Fast forward to now, and there are a multitude of models to choose from - including a wide variety of open source models. These open source models have seen large performance gains over the past six months in particular. As these models get better, we've seen more and more people wanting to try them out. We've teamed up with Fireworks AI to bring these models to the LangSmith playground - completely free of cost (for now, we'll </description>
      <guid isPermaLink="false">https://blog.langchain.com/bringing-free-oss-models-to-the-playground-with-fireworks-ai/</guid>
      <pubDate>Mon, 02 Oct 2023 09:37:01 -0700</pubDate>
    </item>
    <item>
      <title>How "Correct" are LLM Evaluators?</title>
      <link>https://blog.langchain.com/how-correct-are-llm-evaluators/</link>
      <description>Summary:

 * We tested LangChain's LLM-assisted evaluators on common tasks to provide guidelines on how to best use them in your practice.
 * GPT-4 excels in accuracy across various tasks, while GPT-3.5 and Claude-2 lag for tasks requiring complex "reasoning" (when used in a zero-shot setting).


Context

Evaluating language model applications is a challenge. Evaluating by hand can be costly and time-consuming, and classic automated metrics like ROUGE or BLEU can often miss the point of what mak</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-correct-are-llm-evaluators/</guid>
      <pubDate>Thu, 28 Sep 2023 09:31:19 -0700</pubDate>
    </item>
    <item>
      <title>Building Chat LangChain</title>
      <link>https://blog.langchain.com/building-chat-langchain-2/</link>
      <description>Hosted: https://chat.langchain.com

Repo: https://github.com/langchain-ai/chat-langchain


Intro

LangChain packs the power of large language models and an entire ecosystem of tooling around them into a single package. This consolidation ultimately simplifies building LLM applications, but it does mean that there are a lot of features to learn about.

To help folks navigate LangChain, we decided to use LangChain to explain LangChain.

In this post, we'll build a chatbot that answers questions ab</description>
      <guid isPermaLink="false">https://blog.langchain.com/building-chat-langchain-2/</guid>
      <pubDate>Wed, 27 Sep 2023 09:02:56 -0700</pubDate>
    </item>
    <item>
      <title>Fine-tune your LLMs with LangSmith and Lilac</title>
      <link>https://blog.langchain.com/fine-tune-your-llms-with-langsmith-and-lilac/</link>
      <description>In taking your LLM from prototype into production, many have turned to fine-tuning models to get more consistent and high-quality behavior in their applications. Services like OpenAI and HuggingFace make it easy to fine-tune a model on your application-specific data. All it takes is a JSON file!

The tricky part is deciding what to include in that data. Once your LLM is deployed, it could be prompted given any input - how do you make sure it will respond appropriately for the user or machine it </description>
      <guid isPermaLink="false">https://blog.langchain.com/fine-tune-your-llms-with-langsmith-and-lilac/</guid>
      <pubDate>Tue, 26 Sep 2023 10:21:28 -0700</pubDate>
    </item>
    <item>
      <title>Timescale Vector x LangChain: Making PostgreSQL A Better Vector Database for AI Applications</title>
      <link>https://blog.langchain.com/timescale-vector-x-langchain-making-postgresql-a-better-vector-database-for-ai-applications/</link>
      <description>Editor's Note: This post was written in collaboration with the Timescale Vector team. Their integration with LangChain supports PostgreSQL as your vector database for faster similarity search, time-based context retrieval for RAG, and self-querying capabilities. And they're offering a free 90 day trial!

Introducing the Timescale Vector integration for LangChain. Timescale Vector enables LangChain developers to build better AI applications with PostgreSQL as their vector database: with faster ve</description>
      <guid isPermaLink="false">https://blog.langchain.com/timescale-vector-x-langchain-making-postgresql-a-better-vector-database-for-ai-applications/</guid>
      <pubDate>Sun, 24 Sep 2023 10:35:44 -0700</pubDate>
    </item>
    <item>
      <title>LangChain and Scrimba Partner to help Web Devs become AI Engineers</title>
      <link>https://blog.langchain.com/langchain-and-scrimba-partner-to-help-web-devs-become-ai-engineers/</link>
      <description>We’re excited to announce that we are partnering with Scrimba, a code-learning platform with over a million users. Through their interactive video format known as scrims, they enable developers to grow their skills in a more fun and immersive way than regular video courses.

By combing the LangChain JS library with interactive scrims, we will provide web developers with a fast-lane into the exciting world of AI engineering. The collaboration involves two parts:

 1. Creating a free LangChain JS </description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-and-scrimba-partner-to-help-web-devs-become-ai-engineers/</guid>
      <pubDate>Thu, 21 Sep 2023 12:34:25 -0700</pubDate>
    </item>
    <item>
      <title>Eden AI x LangChain: Harnessing LLMs, Embeddings, and AI</title>
      <link>https://blog.langchain.com/eden-ai-x-langchain/</link>
      <description>Editor's Note: This post was written in collaboration with the Eden AI team. We're really excited about Eden's approach to simplifying AI implementation so that we can get more applications into production! It grants access to a diverse range of AI capabilities, spanning text and image generation, OCR, speech-to-text, and image analysis, all with the convenience of a single API key and minimal code. And their integration with LangChain provides effortless access to lots of LLMs and Embeddings.

</description>
      <guid isPermaLink="false">https://blog.langchain.com/eden-ai-x-langchain/</guid>
      <pubDate>Thu, 21 Sep 2023 09:59:52 -0700</pubDate>
    </item>
    <item>
      <title>Peering Into the Soul of AI Decision-Making with LangSmith</title>
      <link>https://blog.langchain.com/peering-into-the-soul-of-ai-decision-making-with-langsmith/</link>
      <description>Editor's Note: This post was written by Paul Thomson from Commandbar. They've been awesome partners as they brought their application into production with LangSmith, and we're excited to share their story getting there.

Do you ever wonder why you’re getting unhinged responses from ChatGPT sometimes? Or why the heck Midjourney is giving your creations 7 weird fingers? As intelligent as AI is supposed to be, it does produce some pretty unintelligent responses sometimes.

Now, if you’re using GPT </description>
      <guid isPermaLink="false">https://blog.langchain.com/peering-into-the-soul-of-ai-decision-making-with-langsmith/</guid>
      <pubDate>Wed, 20 Sep 2023 12:55:16 -0700</pubDate>
    </item>
    <item>
      <title>LangChain + Docugami Webinar: Lessons from Deploying LLMs with LangSmith</title>
      <link>https://blog.langchain.com/langchain-docugami-webinar-lessons-from-deploying-llms-with-langsmith/</link>
      <description>Editor's Note: This post was written in collaboration with the Docugami team. We recently did a webinar with them and Rechat to talk about what it actually requires to get an LLM application into production. You can find the recording of the webinar here–and this post provides a helpful overview of what they discussed and dives even deeper on their learnings.

At Docugami we have been using, training or fine-tuning language models for multiple years in our mission to transform documents to data.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-docugami-webinar-lessons-from-deploying-llms-with-langsmith/</guid>
      <pubDate>Wed, 20 Sep 2023 12:32:24 -0700</pubDate>
    </item>
    <item>
      <title>TED AI Hackathon Kickoff (and projects we’d love to see)</title>
      <link>https://blog.langchain.com/ted-ai-hackathon-kickoff/</link>
      <description>The TED AI Hackathon kicks off October 14 and we’re excited to be their partner in bringing it to life! TED has a long history of inspiring and educating great thinkers and builders and we can’t wait to see what everyone builds.

You can register here and here's a video walkthrough of the event.

We’re anticipating (and hoping!) there are many of you who might be building with LLMs for the first time. So, we thought we’d share some resources to help you get started and ideas for apps that we’d l</description>
      <guid isPermaLink="false">https://blog.langchain.com/ted-ai-hackathon-kickoff/</guid>
      <pubDate>Mon, 18 Sep 2023 17:23:36 -0700</pubDate>
    </item>
    <item>
      <title>How to Safely Query Enterprise Data with LangChain Agents + SQL + OpenAI + Gretel</title>
      <link>https://blog.langchain.com/how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel/</link>
      <description>Editor's Note: This post was written in collaboration with the Gretel team. We're really excited by their approach to combining agent-based methods, LLMs, and synthetic data to enable natural language queries for databases and data warehouses, sans SQL. The post has a really helpful walkthrough (with code!) to bring the ideas to life.

Agent-based approaches coupled with large language models (LLMs) are quickly transforming how we interact with databases and data warehouses. Combined, these tech</description>
      <guid isPermaLink="false">https://blog.langchain.com/how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel/</guid>
      <pubDate>Tue, 12 Sep 2023 13:14:19 -0700</pubDate>
    </item>
    <item>
      <title>OpaquePrompts x LangChain: Enhance the privacy of your LangChain application with just one code change</title>
      <link>https://blog.langchain.com/opaqueprompts-x-langchain-enhance-the-privacy-of-your-langchain-application-with-just-one-code-change/</link>
      <description>Editor's Note: This blog post was written in collaboration with the Opaque team. As more apps get into production, we've been hearing more teams talk about solutions for data privacy. Opaque's seamless integration with LangChain ensures personal information in your users’ prompts will be hidden from the LLM provider with just a few lines of code.

We’ve been hearing growing feedback from our users that they want to keep their data private from LLM providers, whether it be OpenAI, Anthropic, Cohe</description>
      <guid isPermaLink="false">https://blog.langchain.com/opaqueprompts-x-langchain-enhance-the-privacy-of-your-langchain-application-with-just-one-code-change/</guid>
      <pubDate>Tue, 12 Sep 2023 07:17:15 -0700</pubDate>
    </item>
    <item>
      <title>Neo4j x LangChain: Deep dive into the new Vector index implementation</title>
      <link>https://blog.langchain.com/neo4j-x-langchain-new-vector-index/</link>
      <description>Learn how to customize LangChain’s wrapper of Neo4j vector index

Editor's Note: This post was written in collaboration with the Neo4j team. We've been working closely with them on their new vector index and we're really impressed with its ability to efficiently perform semantic search over unstructured text or other embedded data modalities, unlocking support for RAG applications and more customization.

Neo4j was and is an excellent fit for handling structured information, but it struggled a b</description>
      <guid isPermaLink="false">https://blog.langchain.com/neo4j-x-langchain-new-vector-index/</guid>
      <pubDate>Thu, 07 Sep 2023 07:16:58 -0700</pubDate>
    </item>
    <item>
      <title>Syncing data sources to vector stores</title>
      <link>https://blog.langchain.com/syncing-data-sources-to-vector-stores/</link>
      <description>Most complex and knowledge-intensive LLM applications require runtime data retrieval for Retrieval Augmented Generation (RAG). A core component of the typical RAG stack is a vector store, which is used to power document retrieval.

Using a vector store requires setting up an indexing pipeline to load data from sources (a website, a file, etc.), transform the data into documents, embed those documents, and insert the embeddings and documents into the vector store.

If your data sources or process</description>
      <guid isPermaLink="false">https://blog.langchain.com/syncing-data-sources-to-vector-stores/</guid>
      <pubDate>Wed, 06 Sep 2023 07:57:41 -0700</pubDate>
    </item>
    <item>
      <title>Announcing our Student Hacker in Residence Program, Fall '23 Semester</title>
      <link>https://blog.langchain.com/student-hacker-in-residence-fall-23/</link>
      <description>Today, we're opening up applications for our inaugural student hacker in residence program.

We're looking for 3-5 students to work alongside the LangChain team this semester to build LLM applications that are creative, useful, thought-proving, and probably a little weird.


How it works

 * Mostly just build. We'll work together to pick the right project. From there, your work will be largely self-guided.
 * Build with the LangChain team. We'll will be available to unblock and collaborate as yo</description>
      <guid isPermaLink="false">https://blog.langchain.com/student-hacker-in-residence-fall-23/</guid>
      <pubDate>Wed, 06 Sep 2023 07:28:49 -0700</pubDate>
    </item>
    <item>
      <title>Streamlit LLM Hackathon Kickoff (and projects we’d love to see)</title>
      <link>https://blog.langchain.com/streamlit-llm-hackathon-kickoff-and-projects-wed-love-to-see-2/</link>
      <description>Streamlit’s LLM Hackathon kicks off today and we’re thrilled to be partnering with them to bring it to life. We’ve been building with the Streamlit team since LangChain’s inception because it’s the easiest place to get started building LLM apps and we can’t wait to see what everyone builds this week.

As you prepare to get going, we thought we’d share some resources and ideas for apps that we’d love to see (and share out with the broader community!).


Getting Started with LangChain and Streamli</description>
      <guid isPermaLink="false">https://blog.langchain.com/streamlit-llm-hackathon-kickoff-and-projects-wed-love-to-see-2/</guid>
      <pubDate>Tue, 05 Sep 2023 10:10:18 -0700</pubDate>
    </item>
    <item>
      <title>Announcing LangChain Hub</title>
      <link>https://blog.langchain.com/langchain-prompt-hub/</link>
      <description>Today, we're excited to launch LangChain Hub–a home for uploading, browsing, pulling, and managing your prompts. (Soon, we'll be adding other artifacts like chains and agents).

💡Explore the Hub here

LangChain Hub is built into LangSmith (more on that below) so there are 2 ways to start exploring LangChain Hub.

 * With LangSmith access: Full read and write permissions. You can explore all existing prompts and upload your own by logging in and navigate to the Hub from your admin panel.
 * With</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-prompt-hub/</guid>
      <pubDate>Tue, 05 Sep 2023 09:18:08 -0700</pubDate>
    </item>
    <item>
      <title>Incorporating domain specific knowledge in SQL-LLM solutions</title>
      <link>https://blog.langchain.com/incorporating-domain-specific-knowledge-in-sql-llm-solutions/</link>
      <description>Editor's Note: This post was written in collaboration with Manuel and Francisco from the Pampa Labs team. We're always excited to see new best practices emerge for more customizing/personalizing apps more thoroughly, and this post about extending the capabilities of the standard SQL toolkit by applying innovative RAG techniques is an awesome example.

The LangChain library provides different tools to interact with SQL databases which can be used to build and run queries based on natural language</description>
      <guid isPermaLink="false">https://blog.langchain.com/incorporating-domain-specific-knowledge-in-sql-llm-solutions/</guid>
      <pubDate>Tue, 05 Sep 2023 05:23:18 -0700</pubDate>
    </item>
    <item>
      <title>TitanTakeoff x LangChain: Supercharged Local Inference for LLMs</title>
      <link>https://blog.langchain.com/titantakeoff-x-langchain-supercharged-local-inference-for-llms-2/</link>
      <description>Editor's Note: This post was written in collaboration with the TitanML team. The integration between their NLP development platform + LangChain makes inference LLMs super easy!


Challenges

With the release of many open source large language models over the past year, developers are increasingly keen to jump on the bandwagon and deploy their own LLMs. However, without specialised knowledge, developers who are experimenting with deploying LLMs on their own hardware may face unexpected technical </description>
      <guid isPermaLink="false">https://blog.langchain.com/titantakeoff-x-langchain-supercharged-local-inference-for-llms-2/</guid>
      <pubDate>Wed, 30 Aug 2023 11:32:28 -0700</pubDate>
    </item>
    <item>
      <title>Boost Your Bottom Line and Performance: OpenAI’s 3.5T Fine-Tuning with LangSmith</title>
      <link>https://blog.langchain.com/chatopensource-x-langchain-the-future-is-fine-tuning-2/</link>
      <description>Editor's Note: This post was written in collaboration with Author Ryan Brandt from the ChatOpenSource.com team. It's a detailed look at how fine-tuning can meaningfully improve model performance. And how LangSmith + LangChain can help you experiment with different models and measure and compare results.

Unable to use gpt-3.5-turbo for your most critical AI workflows? Then it’s time to think about fine-tuning. Today, we’ll dive into the perks, prep steps, and cost-cutting advantages, all while p</description>
      <guid isPermaLink="false">https://blog.langchain.com/chatopensource-x-langchain-the-future-is-fine-tuning-2/</guid>
      <pubDate>Tue, 29 Aug 2023 11:19:34 -0700</pubDate>
    </item>
    <item>
      <title>Xata x LangChain: new vector store and memory store integrations</title>
      <link>https://blog.langchain.com/xata-x-langchain-new-vector-store-and-memory-store-integrations/</link>
      <description>Editor's Note: This post was written in collaboration with the Xata team. We're excited about their new integrations and really enjoyed their deepdive on implementation a Q&amp;A chat bot with them.  

Over the past few weeks, we’ve merged four Xata integrations to the LangChain repositories, and today we’re happy to unveil them as part of Xata’s launch week! In this blog post, we’ll take a brief look at what Xata is and why it is a good data companion for AI applications. We’ll also show a code exa</description>
      <guid isPermaLink="false">https://blog.langchain.com/xata-x-langchain-new-vector-store-and-memory-store-integrations/</guid>
      <pubDate>Tue, 29 Aug 2023 07:46:07 -0700</pubDate>
    </item>
    <item>
      <title>Chat Loaders: Fine-tune a ChatModel in your Voice</title>
      <link>https://blog.langchain.com/chat-loaders-finetune-a-chatmodel-in-your-voice/</link>
      <description>Summary

We are adding a new integration type, ChatLoaders, to make it easier to fine-tune models on your own unique writing style. These utilities help convert data from popular messaging platforms to chat messages compatible with fine-tuning formats like that supported by OpenAI.

Thank you to Greg Kamradt for Misbah Syed for their thought leadership on this.

Important Links:

 * Chat Loaders
 * Twitter Finetune Example
 * Code for Twitter Finetune Example
 * Webinar on this topic next week

</description>
      <guid isPermaLink="false">https://blog.langchain.com/chat-loaders-finetune-a-chatmodel-in-your-voice/</guid>
      <pubDate>Fri, 25 Aug 2023 07:34:06 -0700</pubDate>
    </item>
    <item>
      <title>Summarizing and Querying Data from Excel Spreadsheets Using eparse and a Large Language Model</title>
      <link>https://blog.langchain.com/summarizing-and-querying-data-from-excel-spreadsheets-using-eparse-and-a-large-language-model/</link>
      <description>Editor's Note: This post was written by Chris Pappalardo, a Senior Director at Alvarez &amp; Marsal, a leading global professional services firm. The standard processes for building with LLM work well for documents that contain mostly text, but do not work as well for documents that contain tabular data (like spreadsheets). We wrote about our latest thinking on Q&amp;A over csvs on the blog a couple weeks ago, and we loved reading Chris's exploration of working with csvs and LangChain using agents, chai</description>
      <guid isPermaLink="false">https://blog.langchain.com/summarizing-and-querying-data-from-excel-spreadsheets-using-eparse-and-a-large-language-model/</guid>
      <pubDate>Thu, 24 Aug 2023 07:48:38 -0700</pubDate>
    </item>
    <item>
      <title>Evaluating RAG pipelines with Ragas + LangSmith</title>
      <link>https://blog.langchain.com/evaluating-rag-pipelines-with-ragas-langsmith/</link>
      <description>Editor's Note: This post was written in collaboration with the Ragas team. One of the things we think and talk about a lot at LangChain is how the industry will evolve to identify new monitoring and evaluation metrics that evolve beyond traditional ML ops metrics. Ragas is an exciting new framework that helps developers evaluate QA pipelines in new ways. This post shows how LangSmith and Ragas can be a powerful combination for teams that want to build reliable LLM apps.

How important evals are </description>
      <guid isPermaLink="false">https://blog.langchain.com/evaluating-rag-pipelines-with-ragas-langsmith/</guid>
      <pubDate>Wed, 23 Aug 2023 19:24:53 -0700</pubDate>
    </item>
    <item>
      <title>Cube x LangChain: Building AI experiences with LLMs and the semantic layer</title>
      <link>https://blog.langchain.com/cube-x-langchain-building-ai-experiences-with-llms-and-the-semantic-layer/</link>
      <description>Editor's Note: This post was written in collaboration with the Cube team. The semantic layer plays a key role in ensuring correctness and predictability when building text-to-sql LLM-based applications. Their integration with LangChain makes it really easy to get started with building AI applications on top of the Cube semantic layer.

For many years already, we live in the data-driven world where accessing the data and deriving insights from it efficiently is paramount. This year, we experience</description>
      <guid isPermaLink="false">https://blog.langchain.com/cube-x-langchain-building-ai-experiences-with-llms-and-the-semantic-layer/</guid>
      <pubDate>Wed, 23 Aug 2023 11:46:02 -0700</pubDate>
    </item>
    <item>
      <title>Epsilla x LangChain: Retrieval Augmented Generation (RAG) in LLM-Powered Question-Answering Pipelines</title>
      <link>https://blog.langchain.com/espilla-x-langchain-retrieval-augmented-generation-rag-in-llm-powered-question-answering-pipelines/</link>
      <description>Editor's Note: This post was written in collaboration with the Epsilla team. As more apps rely on Retrieval Augmented Generation (RAG) for building personalized applications on top of proprietary data, vector databases are becoming even more important. We're really excited about what Epsilla is doing here to help builders quickly and accurately fetch the most relevant documents and data points.

By leveraging the strengths of both LLMs and vector databases, this integration promises richer, more</description>
      <guid isPermaLink="false">https://blog.langchain.com/espilla-x-langchain-retrieval-augmented-generation-rag-in-llm-powered-question-answering-pipelines/</guid>
      <pubDate>Wed, 23 Aug 2023 11:21:00 -0700</pubDate>
    </item>
    <item>
      <title>Tavrn x LangChain: Integrating Noah: ChatGPT with Google Drive and Notion data</title>
      <link>https://blog.langchain.com/integrating-chatgpt-with-google-drive-and-notion-data/</link>
      <description>Editor's Note: This post was written in collaboration with the Tavrn team. They were able to build a new personal assistant app, Noah, that's highly personalized and highly context-aware using LangChain (with some interesting retrieval tactics) and LangSmith (for fine-tuning chains and prompts).

ChatGPT is already an indispensable tool for many in the workplace. Its impressive general purpose performance makes it extremely versatile to assist in workflows ranging from creative brainstorming to </description>
      <guid isPermaLink="false">https://blog.langchain.com/integrating-chatgpt-with-google-drive-and-notion-data/</guid>
      <pubDate>Wed, 23 Aug 2023 09:47:53 -0700</pubDate>
    </item>
    <item>
      <title>Using LangSmith to Support Fine-tuning</title>
      <link>https://blog.langchain.com/using-langsmith-to-support-fine-tuning-of-open-source-llms/</link>
      <description>Summary

We created a guide for fine-tuning and evaluating LLMs using LangSmith for dataset management and evaluation. We did this both with an open source LLM on CoLab and HuggingFace for model training, as well as OpenAI's new finetuning service. As a test case, we fine-tuned LLaMA2-7b-chat and gpt-3.5-turbo for an extraction task (knowledge graph triple extraction) using training data exported from LangSmith and also evaluated the results using LangSmith. The CoLab guide is here.


Context

I</description>
      <guid isPermaLink="false">https://blog.langchain.com/using-langsmith-to-support-fine-tuning-of-open-source-llms/</guid>
      <pubDate>Wed, 23 Aug 2023 08:46:25 -0700</pubDate>
    </item>
    <item>
      <title>Introducing Airbyte sources within LangChain</title>
      <link>https://blog.langchain.com/introducing-airbyte-sources-within-langchain/</link>
      <description>Editor's Note: This post was written in collaboration with the Airbyte team. They've made it really easy to connect even more data sources to LangChain as document loaders.

It’s now possible to utilize the Airbyte sources for Gong, Hubspot, Salesforce, Shopify, Stripe, Typeform and Zendesk Support directly within your LangChain-based application, implemented as document loaders.

For example, to load the Stripe invoices for a user, you can use the AirbyteStripeLoader. Installing it is super sim</description>
      <guid isPermaLink="false">https://blog.langchain.com/introducing-airbyte-sources-within-langchain/</guid>
      <pubDate>Tue, 22 Aug 2023 08:05:56 -0700</pubDate>
    </item>
    <item>
      <title>LangChain 🤝 DemoGPT: New Era for Gen-AI Applications</title>
      <link>https://blog.langchain.com/langchain-demogpt-new-era-for-gen-ai-applications/</link>
      <description>Editor's Note: This post was written in collaboration with the DemoGPT team. We're excited about what they're doing to make it easier to not only build LLM applications, but also get them in the hands of users and build community in the process. We also thought way they built the platform on top of LangChain and Streamlit is really neat–their under-the-hood walkthrough offers some cool ideas for anyone using a language model to generate an app.

Today we’re happy to announce the collaboration of</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-demogpt-new-era-for-gen-ai-applications/</guid>
      <pubDate>Mon, 21 Aug 2023 09:56:09 -0700</pubDate>
    </item>
    <item>
      <title>Zep x LangSmith: Foundations of LLM app development with LangChain.js and Zep</title>
      <link>https://blog.langchain.com/zep-x-langsmith-foundations-of-llm-app-development-with-langchain-js-and-zep/</link>
      <description>Learn how to build three foundational LLM apps using TypeScript, LangChain.js, and Zep.

Editor's Note: This post was written in collaboration with the Zep team. The post walks, step-by-step, through the process of building three foundational LLM apps using TypeScript, LangChain.js, and Zep. We think it's a really compelling exploration of RAG and agents accessing to tools, combined with LangSmith for visibility into model behavior. And, we think–and hope–more developers will try these same appr</description>
      <guid isPermaLink="false">https://blog.langchain.com/zep-x-langsmith-foundations-of-llm-app-development-with-langchain-js-and-zep/</guid>
      <pubDate>Thu, 17 Aug 2023 11:10:52 -0700</pubDate>
    </item>
    <item>
      <title>Langchain x Predibase: The easiest way to fine-tune and productionize OSS LLMs</title>
      <link>https://blog.langchain.com/langchain-predibase-the-easiest-way-to-fine-tune-and-productionize-oss-llms/</link>
      <description>Editor's Note: This post was written in collaboration with the Predibase team. We're really excited about the way their integration with LangChain helps bring production-grade standards and workflows to open-source to open-source models.

Today, we’re announcing a Langchain Integration for Predibase. This integration allows Langchain developers to seamlessly integrate hosted OSS models on Predibase into their workflows.


What is Predibase?

Predibase is a Developer platform for OSS LLMs. Predib</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-predibase-the-easiest-way-to-fine-tune-and-productionize-oss-llms/</guid>
      <pubDate>Thu, 17 Aug 2023 09:00:00 -0700</pubDate>
    </item>
    <item>
      <title>Qdrant x LangChain: Endgame Performance</title>
      <link>https://blog.langchain.com/qdrant-x-langchain-endgame-performance/</link>
      <description>Editor's Note: This post was written by the Qdrant team and cross-posted from their blog. As more LLM applications move into production, speed, stability and costs are going to become even more important features of the LLM tech stack. And, as more LLM applications take advantage of RAG (and longterm memory), this becomes even more of a challenge. We're really excited about what Qdrant is doing to help with that–their async support is particularly helpful!


LangChain currently supports 40+ vect</description>
      <guid isPermaLink="false">https://blog.langchain.com/qdrant-x-langchain-endgame-performance/</guid>
      <pubDate>Wed, 16 Aug 2023 08:49:00 -0700</pubDate>
    </item>
    <item>
      <title>MultiOn x LangChain: Powering Next-Gen Web Automation &amp; Navigation with AI</title>
      <link>https://blog.langchain.com/multion-x-langchain-powering-next-gen-web-automation-navigation-with-ai/</link>
      <description>Editor's Note: This post was written in collaboration with MultiOn. We're really excited about the way they're using Agents to automate and streamline online interactions. They are one of the first real world, production agent applications that we know of. Their integration with LangChain as a Toolkit makes it quick and easy to personalize and automate everyday web tasks.


MultiOn: Your Personal AI Agent Now on LangChain

Whether it's searching for information, filling out forms, or navigating </description>
      <guid isPermaLink="false">https://blog.langchain.com/multion-x-langchain-powering-next-gen-web-automation-navigation-with-ai/</guid>
      <pubDate>Tue, 15 Aug 2023 11:49:00 -0700</pubDate>
    </item>
    <item>
      <title>Benchmarking Question/Answering Over CSV Data</title>
      <link>https://blog.langchain.com/benchmarking-question-answering-over-csv-data/</link>
      <description>This is a bit of a longer post. It's a deep dive on question-answering over tabular data. We discuss (and use) CSV data in this post, but a lot of the same ideas apply to SQL data. It covers:

 * Background Motivation: why this is an interesting task
 * Initial Application: how we set up a simple Streamlit app in order to gather a good distribution of real questions
 * Initial Solution: our initial solution and some conceptual considerations
 * Debugging with LangSmith: what we saw people asking</description>
      <guid isPermaLink="false">https://blog.langchain.com/benchmarking-question-answering-over-csv-data/</guid>
      <pubDate>Mon, 14 Aug 2023 22:16:00 -0700</pubDate>
    </item>
    <item>
      <title>Label Studio x LangChain: From Foundation Models to Fine-Tuned Applications Using Label Studio</title>
      <link>https://blog.langchain.com/from-foundation-models-to-fine-tuned-applications-using-label-studio/</link>
      <description>Editor's Note: This post was written by Jimmy Whitaker, Data Scientist in Residence at HumanSignal. Label Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback, a critical part of ongoing evaluation and maintenance of expert systems.


Introduction

Quality is a</description>
      <guid isPermaLink="false">https://blog.langchain.com/from-foundation-models-to-fine-tuned-applications-using-label-studio/</guid>
      <pubDate>Mon, 14 Aug 2023 11:22:00 -0700</pubDate>
    </item>
    <item>
      <title>GPT Researcher x LangChain</title>
      <link>https://blog.langchain.com/gpt-researcher-x-langchain/</link>
      <description>Here at LangChain we think that web research is fantastic use case for LLMs. So much so that we wrote a blog on it about a month ago. In that blog we mentioned the leading open-source implementation of a research assistant - gpt-researcher. Today we're excited to announce that GPT Researcher is integrated with LangChain. Specifically, it is integrated with our OpenAI adapter, which allows (1) easy usage of other LLM models under the hood, (2) easy logging with LangSmith.

What is GPT Researcher?</description>
      <guid isPermaLink="false">https://blog.langchain.com/gpt-researcher-x-langchain/</guid>
      <pubDate>Sun, 13 Aug 2023 13:46:00 -0700</pubDate>
    </item>
    <item>
      <title>Villagers x LangSmith: Simulating multi-agent social networks with LangSmith</title>
      <link>https://blog.langchain.com/villagers-x-langsmith-simulating-multi-agent-social-networks/</link>
      <description>Editor's Note: This post was written in collaboration with Kevin Hu, Tae Hyoung Jo, John Kim, and Tejal Patwardhan from the Villagers team. Villagers came in second at a recent Anthropic hackathon. We really LOVED this project as it shows off complex prompt engineering with their multi-agent social network simulation that runs many agents in parallel. We were really excited to see how LangSmith could help the team automate traces, quickly iterate on prompts, and efficiently debug for this comple</description>
      <guid isPermaLink="false">https://blog.langchain.com/villagers-x-langsmith-simulating-multi-agent-social-networks/</guid>
      <pubDate>Thu, 10 Aug 2023 07:34:00 -0700</pubDate>
    </item>
    <item>
      <title>NeumAI x LangChain: Efficiently maintaining context in sync for AI applications</title>
      <link>https://blog.langchain.com/neum-x-langchain/</link>
      <description>Editors Note: This post was written by the NeumAI team and cross-posted from their blog. Keeping source data relevant and up-to-date efficiently is a challenge many builders are facing. It's especially painful for teams that are building on top of datasources constantly changing like team documentation (a use-case we see a lot of). Following up on our blog yesterday about making ingestion pipelines more production ready, we're really excited to highlight this because it continues in that vein. I</description>
      <guid isPermaLink="false">https://blog.langchain.com/neum-x-langchain/</guid>
      <pubDate>Wed, 09 Aug 2023 08:30:12 -0700</pubDate>
    </item>
    <item>
      <title>Making Data Ingestion Production Ready: a LangChain-Powered Airbyte Destination</title>
      <link>https://blog.langchain.com/making-data-ingestion-production-ready-a-langchain-powered-airbyte-destination/</link>
      <description>A big focus of ours over the past few months has been enabling teams to go from prototype to production. To take apps they developed in an hour and get them into a place where they can actually be reliably used. Arguably the biggest category of applications LangChain helps enable is retrieval based applications (where you connect LLMs to your own data). There are a few things that are needed to take retrieval based applications from prototype to production.

One component of that is everything r</description>
      <guid isPermaLink="false">https://blog.langchain.com/making-data-ingestion-production-ready-a-langchain-powered-airbyte-destination/</guid>
      <pubDate>Tue, 08 Aug 2023 10:35:54 -0700</pubDate>
    </item>
    <item>
      <title>Chat with your data using OpenAI, Pinecone, Airbyte and Langchain</title>
      <link>https://blog.langchain.com/chat-with-your-data-using-openai-pinecone-airbyte-langchain/</link>
      <description>Editor’s Note: This blog post was written in collaboration with Airbyte. Their new vector database destination makes it really easy for data to retrieve relevant context for question answering use cases via LangChain. We're seeing more and more teams seek ways to integrate diverse data sources–and keep them up-to-date automatically–and this is a fantastic way to do it!

Aside from the specific use case highlighted here, we're also very excited about this integration in general. It combines the h</description>
      <guid isPermaLink="false">https://blog.langchain.com/chat-with-your-data-using-openai-pinecone-airbyte-langchain/</guid>
      <pubDate>Tue, 08 Aug 2023 07:21:40 -0700</pubDate>
    </item>
    <item>
      <title>Yeager.ai x LangChain: Exploring GenWorlds a Framework for Coordinating AI Agents</title>
      <link>https://blog.langchain.com/exploring-genworlds/</link>
      <description>Editor's Note: This is another edition of our series of guest posts highlighting the powerful applications of LangChain. We have been working with the Yeager.ai team for several months now, and they have built some really impressive applications of LangChain agents. We're excited to highlight this guest blog on their GenWorlds framework for multi-agent systems. We are especially excited to see their plan for making it seamless for the LangChain/GenWorlds community to monetize their projects.

🧬</description>
      <guid isPermaLink="false">https://blog.langchain.com/exploring-genworlds/</guid>
      <pubDate>Fri, 04 Aug 2023 06:47:43 -0700</pubDate>
    </item>
    <item>
      <title>Conversational Retrieval Agents</title>
      <link>https://blog.langchain.com/conversational-retrieval-agents/</link>
      <description>TL;DR: There have been several emerging trends in LLM applications over the past few months: RAG, chat interfaces, agents. Our newest functionality - conversational retrieval agents - combines them all. This isn't just a case of combining a lot of buzzwords - it provides real benefits and superior user experience.

Key Links:

 * Python Documentation
 * JavaScript Documentation
 * End-to-end example

As LLM applications are starting to make their way into more and more production use cases, a fe</description>
      <guid isPermaLink="false">https://blog.langchain.com/conversational-retrieval-agents/</guid>
      <pubDate>Thu, 03 Aug 2023 08:31:37 -0700</pubDate>
    </item>
    <item>
      <title>Unifying AI endpoints with Genoss, powered by LangChain</title>
      <link>https://blog.langchain.com/unifying-ai-endpoints-with-genoss/</link>
      <description>Editor’s Note: This blog post was written by Matt Carey, one of the builders of Genoss. We're sharing it on our blog too because we hear from a lot of people that don't want to get locked in to a single model. We think tools like Genoss that provide clean interfaces for interoperability will help more builders get robust apps into production fast. We're also incredibly excited about the integration it has with LangSmith to enable easy debugging, logging, monitoring, and observability!



Introdu</description>
      <guid isPermaLink="false">https://blog.langchain.com/unifying-ai-endpoints-with-genoss/</guid>
      <pubDate>Wed, 02 Aug 2023 07:06:44 -0700</pubDate>
    </item>
    <item>
      <title>LangChain Expression Language</title>
      <link>https://blog.langchain.com/langchain-expression-language/</link>
      <description>TL;DR:

 * We’re excited to announce a new syntax to create chains with composition. This comes along with a new interface that supports batch, async, and streaming out of the box. We’re calling this syntax LangChain Expression Language (LCEL)
 * We've created a "LangChain Teacher" to help teach you LCEL (assumes LangChain familiarity)
 * We'll be doing a webinar on 8/2 about this and how to use it
 * This is aimed at making it easier to construct complex chains, and pairs nicely with LangSmith </description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-expression-language/</guid>
      <pubDate>Tue, 01 Aug 2023 09:38:29 -0700</pubDate>
    </item>
    <item>
      <title>Goodbye CVEs, Hello `langchain_experimental`</title>
      <link>https://blog.langchain.com/goodbye-cves-hello-langchain_experimental/</link>
      <description>One of the things that LangChain seeks to enable is connecting language models to external sources of data and computation. This allows language models to act as the reasoning engine and outsource knowledge and execution to other systems. Some examples of this include:

 * Retrieval augmented generation: Hooking a language model up to a retrieval system and using that influence the generation. This allows language models to answer questions about information other than what they were trained on.</description>
      <guid isPermaLink="false">https://blog.langchain.com/goodbye-cves-hello-langchain_experimental/</guid>
      <pubDate>Mon, 31 Jul 2023 08:32:21 -0700</pubDate>
    </item>
    <item>
      <title>Zep x LangChain: Diagnosing and Fixing Slow Chatbots</title>
      <link>https://blog.langchain.com/zep-x-langchain-slow-chatbots/</link>
      <description>Editor’s Note: This blog post was written in collaboration with Zep, an early LangSmith BETA user. We've fielded a lot of questions about the latency of LangChain applications - where it comes from, how to improve. This is a FANTASTIC walkthrough of how LangSmith allows you to easily diagnose the causes of latency in your app, and how different components of the LangChain ecosystem (in this case, Zep) can be used to improve it.


Summary

Poor chatbot response times can result in frustrated user</description>
      <guid isPermaLink="false">https://blog.langchain.com/zep-x-langchain-slow-chatbots/</guid>
      <pubDate>Wed, 26 Jul 2023 08:59:21 -0700</pubDate>
    </item>
    <item>
      <title>Automating Web Research</title>
      <link>https://blog.langchain.com/automating-web-research/</link>
      <description>Key Links

 * Web Researcher Repo
 * New LangChain Retriever and Documentation
 * Hosted Streamlit App


Motivation

Web research is one of the killer LLM applications: Greg Kamradt highlighted it as one of his top desired AI tools and OSS repos like gpt-researcher are growing in popularity. We decided to take a stab at it, initially setting out like many others to build a web research agent. But, we landed somewhere different: a fairly simple retriever proved to be effective and easily configur</description>
      <guid isPermaLink="false">https://blog.langchain.com/automating-web-research/</guid>
      <pubDate>Wed, 26 Jul 2023 07:47:31 -0700</pubDate>
    </item>
    <item>
      <title>RealChar x LangSmith: Using Open Source tools to create an AI companion</title>
      <link>https://blog.langchain.com/realchar-x-langsmith-ai-companions/</link>
      <description>Editor’s Note: This blog post was written in collaboration with RealChar, an early LangSmith BETA user. They moved fast and created something really, really sophisticated and really, really fun to use–all with open source tools.

We're also very excited about AI characters and companions internally, which is part of the reason we're excited to highlight RealChar. As seen by the meteoric rise of platforms like CharacterAI, allowing people to converse with different personas can be really fun.

Re</description>
      <guid isPermaLink="false">https://blog.langchain.com/realchar-x-langsmith-ai-companions/</guid>
      <pubDate>Mon, 24 Jul 2023 09:33:44 -0700</pubDate>
    </item>
    <item>
      <title>Lepton x LangChain: Earning Sage, How to Transform AI into a Savvy CFO</title>
      <link>https://blog.langchain.com/lepton-x-langchain-earning-sage/</link>
      <description>Editor’s Note: This blog post was written in collaboration LeptonAI Team, an early LangSmith BETA user. Lots of folks are talking about how best to finetune an open-source model for their specific use case, and LeptonAI has actually done that. We're excited to share their journey and hope it can inform others.


Introduction

Have you ever thought about joining an earning call and asking questions to these CFOs? That used to be the privilege held by the investors from high-end investment banks s</description>
      <guid isPermaLink="false">https://blog.langchain.com/lepton-x-langchain-earning-sage/</guid>
      <pubDate>Mon, 24 Jul 2023 07:40:00 -0700</pubDate>
    </item>
    <item>
      <title>Announcing LangSmith, a unified platform for debugging, testing, evaluating, and monitoring your LLM applications</title>
      <link>https://blog.langchain.com/announcing-langsmith/</link>
      <description>LangChain exists to make it as easy as possible to develop LLM-powered applications.

We started with an open-source Python package when the main blocker for building LLM-powered applications was getting a simple prototype working. We remember seeing Nat Friedman tweet in late 2022 that there was “not enough tinkering happening.” The LangChain open-source packages are aimed at addressing this and we see lots of tinkering happening now (Nat agrees)–people are building everything from chatbots ove</description>
      <guid isPermaLink="false">https://blog.langchain.com/announcing-langsmith/</guid>
      <pubDate>Tue, 18 Jul 2023 08:59:40 -0700</pubDate>
    </item>
    <item>
      <title>Code Interpreter API</title>
      <link>https://blog.langchain.com/code-interpreter-api/</link>
      <description>Editor's Note: This is another installation of our guest blog posts highlighting interesting and novel use cases. This blog is written by Shroominic who built an open source implementation of the ChatGPT Code Interpreter.

Important Links:

 * GitHub Repo

In the world of open-source software, there are always exciting developments. Today, I am thrilled to announce a new project that I have been working on - Code Interpreter API. It's an implementation of the ChatGPT Code Interpreter using LangC</description>
      <guid isPermaLink="false">https://blog.langchain.com/code-interpreter-api/</guid>
      <pubDate>Sun, 16 Jul 2023 09:37:52 -0700</pubDate>
    </item>
    <item>
      <title>Analyzing User Interactions with LLMs to Improve our Documentation</title>
      <link>https://blog.langchain.com/llms-to-improve-documentation/</link>
      <description>Introduction

We're strongly committed to consistently enhancing our documentation and its navigability. Using Mendable, a AI-enabled chat application, users can search our documentation using keywords or questions. Over time, Mendable has collected a large dataset of questions that highlights areas for documentation improvement.


Challenge

Distilling common themes from tens of thousands of questions per month is a significant challenge. Manual labeling can be effective, but is slow and labori</description>
      <guid isPermaLink="false">https://blog.langchain.com/llms-to-improve-documentation/</guid>
      <pubDate>Thu, 13 Jul 2023 08:52:59 -0700</pubDate>
    </item>
    <item>
      <title>LangChain x Context: Building Better Chat Products With User Analytics</title>
      <link>https://blog.langchain.com/langchain-x-context-building-better-chat-products-with-user-analytics/</link>
      <description>Today we’re announcing a Langchain integration for Context. This integration allows builders of Langchain chat products to receive user analytics with a one line plugin.

Building compelling chat products is hard. Developers need a deep understanding of user behaviour and user goals to iteratively improve their products. Common questions that builders ask include: how are people using my product? How well is my product meeting user needs? And where does my product need improvement?

Today, answe</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-x-context-building-better-chat-products-with-user-analytics/</guid>
      <pubDate>Wed, 12 Jul 2023 22:34:59 -0700</pubDate>
    </item>
    <item>
      <title>Neon x LangChain: HNSW in Postgres with pg_embedding</title>
      <link>https://blog.langchain.com/neon-x-langchainhnsw-in-postgres-with-pg_embedding/</link>
      <description>Editor’s Note: This blog post was written in collaboration with the Neon team (Raouf Chebri in particular). The vectorstore space is on fire, and we’re excited to highlight new implementations and options. We’re also really excited by the detailed analysis done here, bringing some solid stats and insights to a novel space.

We’re very excited to announce Neon’s collaboration with LangChain to release the pg_embedding extension and PGEmbedding integration in LangChain for vector similarity search</description>
      <guid isPermaLink="false">https://blog.langchain.com/neon-x-langchainhnsw-in-postgres-with-pg_embedding/</guid>
      <pubDate>Wed, 12 Jul 2023 07:27:30 -0700</pubDate>
    </item>
    <item>
      <title>LangChain 🤝 Streamlit</title>
      <link>https://blog.langchain.com/langchain-streamlit/</link>
      <description>The initial integration of Streamlit with LangChain and our future plans.</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-streamlit/</guid>
      <pubDate>Tue, 11 Jul 2023 08:59:02 -0700</pubDate>
    </item>
    <item>
      <title>🎉 Prem Challenge🎉</title>
      <link>https://blog.langchain.com/prem-challenge-with-langchain/</link>
      <description>We're excited to announce a challenge hosted by Prem in collaboration with LangChain.

At LangChain we try to make it easy as possible to experiment with as many different models as possible. That includes the incredible number of emerging open source models. We've made efforts to make our framework as suitable as possible for experimentation with open source models. This has already enabled several amazing projects to be built on top of LangChain and open-source models.

We want to see more of </description>
      <guid isPermaLink="false">https://blog.langchain.com/prem-challenge-with-langchain/</guid>
      <pubDate>Mon, 26 Jun 2023 13:39:59 -0700</pubDate>
    </item>
    <item>
      <title>LangChain &lt;&gt; MongoDB Atlas</title>
      <link>https://blog.langchain.com/langchain-x-mongodb-atlas/</link>
      <description>Today we’re announcing LangChain’s integration with MongoDB Atlas, adding support for one of the most popular developer data platforms in the world. This is an integration so anticipated that a few developers added the integration before we were ready to announce it :)


Overview

One of the key components of AI powered applications is semantic search powered by embeddings and vector stores. Semantic Search is a capability that allows you to query your data based on its meaning rather than the d</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-x-mongodb-atlas/</guid>
      <pubDate>Thu, 22 Jun 2023 11:23:16 -0700</pubDate>
    </item>
    <item>
      <title>Data-Driven Characters</title>
      <link>https://blog.langchain.com/data-driven-characters/</link>
      <description>Data-driven-characters is a repo for creating, debugging, and interacting your own chatbots conditioned on your own story corpora.</description>
      <guid isPermaLink="false">https://blog.langchain.com/data-driven-characters/</guid>
      <pubDate>Mon, 19 Jun 2023 05:15:44 -0700</pubDate>
    </item>
    <item>
      <title>LangChain + Vectara: better together</title>
      <link>https://blog.langchain.com/langchain-vectara-better-together/</link>
      <description>Introduction

One of the main use cases of LangChain is connecting LLMs to user data, allowing users to build personalized LLM applications. A key part of this is retrieval - fetching relevant documents based on user queries.

Today we’re happy to announce the integration of Vectara into LangChain to help make retrieval easier. In this blog post, we’ll dig deeper into why retrieval is so important and how to use Vectara’s LangChain integration to build scalable LLM-powered applications.


What i</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-vectara-better-together/</guid>
      <pubDate>Tue, 06 Jun 2023 07:07:16 -0700</pubDate>
    </item>
    <item>
      <title>GPTeam: A multi-agent simulation</title>
      <link>https://blog.langchain.com/gpteam-a-multi-agent-simulation/</link>
      <description>Editor's Note: This is another edition in our series of guest posts highlighting novel applications of LangChain. After the Generative Agents paper was released, there was a flurry of open source projects rushing to incorporate some of the key ideas. GPTeam was one of the most impressive ones we saw, so we're incredibly excited to highlight this guest blog from @itstimconnors and the rest of the team  (@alecvxyz @joshsny, and @haniasnyder).

On May 16th, we released GPTeam, a completely customiz</description>
      <guid isPermaLink="false">https://blog.langchain.com/gpteam-a-multi-agent-simulation/</guid>
      <pubDate>Mon, 05 Jun 2023 07:23:13 -0700</pubDate>
    </item>
    <item>
      <title>Going Beyond Chatbots: How to Make GPT-4 Output Structured Data Using LangChain</title>
      <link>https://blog.langchain.com/going-beyond-chatbots-how-to-make-gpt-4-output-structured-data-using-langchain/</link>
      <description>By Jacob Lee

Over the past few months, I had the opportunity to do some cool exploratory work for a client that integrated LLMs like GPT-4 and Claude into their internal workflow, rather than exposing them through a chat interface. The general idea was to take some input data, analyze it using an LLM, enrich the LLM's output using existing data sources, and then sanity check it using both traditional tools and LLMs. This process could repeat several times until finally storing a final result in</description>
      <guid isPermaLink="false">https://blog.langchain.com/going-beyond-chatbots-how-to-make-gpt-4-output-structured-data-using-langchain/</guid>
      <pubDate>Sun, 21 May 2023 20:22:53 -0700</pubDate>
    </item>
    <item>
      <title>Auto-Evaluation of Anthropic 100k Context Window</title>
      <link>https://blog.langchain.com/auto-evaluation-of-anthropic-100k-context-window/</link>
      <description>Lance Martin


Retrieval Architectures

LLM question answering (Q+A) typically involves retrieval of documents relevant to the question followed by synthesis of the retrieved chunks into an answer by an LLM.  In practice, the retrieval step is necessary because the LLM context window is limited relative to the size of most text corpus of interest (e.g., LLM context windows range from ~2k-4k tokens for many models and up 8k-32k for GPT4). Anthropic recently released a Claude model with a 100k tok</description>
      <guid isPermaLink="false">https://blog.langchain.com/auto-evaluation-of-anthropic-100k-context-window/</guid>
      <pubDate>Tue, 16 May 2023 08:33:09 -0700</pubDate>
    </item>
    <item>
      <title>Rebuff: Detecting Prompt Injection Attacks</title>
      <link>https://blog.langchain.com/rebuff/</link>
      <description>[Editor's Note]: we're excited to highlight a guest blog by Willem Pienaar. As more and more LangChains make their way into production, we're getting an increased amount of questions about the security and privacy of these systems. We did a webinar on this topic a few weeks ago, and the main action item that emerged was the best thing at the moment is more awareness of this topic is needed. That is why we are so excited for this post!

Important Links:

 * Rebuff playground
 * LangChain x Rebuff</description>
      <guid isPermaLink="false">https://blog.langchain.com/rebuff/</guid>
      <pubDate>Sun, 14 May 2023 17:50:26 -0700</pubDate>
    </item>
    <item>
      <title>Plan-and-Execute Agents</title>
      <link>https://blog.langchain.com/plan-and-execute-agents/</link>
      <description>TL;DR: We’re introducing a new type of agent executor, which we’re calling “Plan-and-Execute”. This is to contrast against the previous types of agent we supported, which we’re calling “Action” agents. Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper. We think Plan-and-Execute is great for more complex long term planning, at the cost of more calls to the language model. We're putting the initial version of this in the experimental module as we expect ra</description>
      <guid isPermaLink="false">https://blog.langchain.com/plan-and-execute-agents/</guid>
      <pubDate>Wed, 10 May 2023 08:47:15 -0700</pubDate>
    </item>
    <item>
      <title>Feature Stores and LLMs</title>
      <link>https://blog.langchain.com/feature-stores-and-llms/</link>
      <description>Editor's note: big thank you to Willem Pienaar (Feast), Mike Del Balso (Tecton), and Simba Khadder (FeatureForm) for their comments and help on this post.

LLMs represent a new paradigm of AI. There is a big open question of how many of the tools and services that were useful for traditional machine learning are still relevant here. On one hand, there are very real new use cases and requirements for this new paradigm. On the other hand, existing tools and services have years of experience, devel</description>
      <guid isPermaLink="false">https://blog.langchain.com/feature-stores-and-llms/</guid>
      <pubDate>Tue, 09 May 2023 09:07:36 -0700</pubDate>
    </item>
    <item>
      <title>Structured Tools</title>
      <link>https://blog.langchain.com/structured-tools/</link>
      <description>TL;DR: we're introducing a new abstraction to allow for usage of more complex tools. While previous tools took in a single string input, new tools can take in an arbitrary number of inputs of arbitrary types. We are also introducing a new agent class that works well with these new types of tools.

Important Links:

 * Tools list
 * New agent

Way back in November 2022 when we first launched LangChain, agent and tool utilization played a central role in our design. We built one of the first chain</description>
      <guid isPermaLink="false">https://blog.langchain.com/structured-tools/</guid>
      <pubDate>Tue, 02 May 2023 22:00:45 -0700</pubDate>
    </item>
    <item>
      <title>Auto-Evaluator Opportunities</title>
      <link>https://blog.langchain.com/auto-evaluator-opportunities/</link>
      <description>Editor's Note: this is a guest blog post by Lance Martin.


TL;DR

We recently open-sourced an auto-evaluator tool for grading LLM question-answer chains. We are now releasing an open source, free to use hosted app and API to expand usability. Below we discuss a few opportunities to further improve this.


Context

Document Question-Answering is a popular LLM use-case. LangChain makes it easy to assemble LLM components (e.g., models and retrievers) into chains that support question-answering: in</description>
      <guid isPermaLink="false">https://blog.langchain.com/auto-evaluator-opportunities/</guid>
      <pubDate>Mon, 01 May 2023 09:11:15 -0700</pubDate>
    </item>
    <item>
      <title>Callbacks Improvements</title>
      <link>https://blog.langchain.com/callbacks/</link>
      <description>TL;DR: We're announcing improvements to our callbacks system, which powers logging, tracing, streaming output, and some awesome third-party integrations. This will better support concurrent runs with independent callbacks, tracing of deeply nested trees of LangChain components, and callback handlers scoped to a single request (which is super useful for deploying LangChain on a server).

 * Python docs
 * JS docs


Context

Originally we designed the callbacks mechanism in LangChain to be used in</description>
      <guid isPermaLink="false">https://blog.langchain.com/callbacks/</guid>
      <pubDate>Mon, 01 May 2023 07:54:17 -0700</pubDate>
    </item>
    <item>
      <title>Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees</title>
      <link>https://blog.langchain.com/unleashing-the-power-of-ai-collaboration-with-parallelized-llm-agent-actor-trees/</link>
      <description>Editor's note: the following is a guest blog post from Cyrus at Shaman AI. We use guest blog posts to highlight interesting and novel applciations, and this is certainly that. There's been a lot of talk about agents recently, but most have been discussions around a single agent. If multiple agents have been involved, they've been invoked sequentially. This work is novel in that it pushes the boundaries of that and explores multiple agents acting in parallel.

Important Links:

 * GitHub


Introd</description>
      <guid isPermaLink="false">https://blog.langchain.com/unleashing-the-power-of-ai-collaboration-with-parallelized-llm-agent-actor-trees/</guid>
      <pubDate>Fri, 28 Apr 2023 00:12:35 -0700</pubDate>
    </item>
    <item>
      <title>Gradio &amp; LLM Agents</title>
      <link>https://blog.langchain.com/gradio-llm-agents/</link>
      <description>Editor's note: this is a guest blog post from Freddy Boulton, a software engineer at Gradio. We're excited to share this post because it brings a large number of exciting new tools into the ecosystem. Agents are largely defined by the tools they have, so to be able to equip them with all these gradio_tools is very exciting to us!

Important Links:

 * Gradio Tools Library
 * LangChain Integration
 * Accompanying Gradio Blog Post

Large Language Models (LLMs) are very impressive but they can be m</description>
      <guid isPermaLink="false">https://blog.langchain.com/gradio-llm-agents/</guid>
      <pubDate>Sun, 23 Apr 2023 18:54:35 -0700</pubDate>
    </item>
    <item>
      <title>RecAlign - The smart content filter for social media feed</title>
      <link>https://blog.langchain.com/recalign-the-smart-content-filter-for-social-media-feed/</link>
      <description>[Editor's Note] This is a guest post by Tian Jin. We are highlighting this application as we think it is a novel use case. Specifically, we think recommendation systems are incredibly impactful in our everyday lives and there has not been a ton of discourse on how LLMs will impact these systems.

We've all experienced the pains of using recommender systems: you signed up for Twitter to keep up with latest AI research, but a click on a funny meme will flood your timeline with similar distractions</description>
      <guid isPermaLink="false">https://blog.langchain.com/recalign-the-smart-content-filter-for-social-media-feed/</guid>
      <pubDate>Sat, 22 Apr 2023 07:35:24 -0700</pubDate>
    </item>
    <item>
      <title>Improving Document Retrieval with Contextual Compression</title>
      <link>https://blog.langchain.com/improving-document-retrieval-with-contextual-compression/</link>
      <description>Note: This post assumes some familiarity with LangChain and is moderately technical.

💡 TL;DR: We’ve introduced a new abstraction and a new document Retriever to facilitate the post-processing of retrieved documents. Specifically, the new abstraction makes it easy to take a set of retrieved documents and extract from them only the information relevant to the given query.


Introduction

Many LLM-powered applications require some queryable document storage that allows for the retrieval of applic</description>
      <guid isPermaLink="false">https://blog.langchain.com/improving-document-retrieval-with-contextual-compression/</guid>
      <pubDate>Thu, 20 Apr 2023 22:23:33 -0700</pubDate>
    </item>
    <item>
      <title>Autonomous Agents &amp; Agent Simulations</title>
      <link>https://blog.langchain.com/agents-round/</link>
      <description>Over the past two weeks, there has been a massive increase in using LLMs in an agentic manner. Specifically, projects like AutoGPT, BabyAGI, CAMEL, and Generative Agents have popped up. The LangChain community has now implemented some parts of all of those projects in the LangChain framework. While researching and implementing these projects, we’ve tried to best understand what the differences between them are and what the novel features of each are. This blog is an explanation of what we’ve lea</description>
      <guid isPermaLink="false">https://blog.langchain.com/agents-round/</guid>
      <pubDate>Tue, 18 Apr 2023 23:15:05 -0700</pubDate>
    </item>
    <item>
      <title>AI-Powered Medical Knowledge: Revolutionizing Care for Rare Conditions</title>
      <link>https://blog.langchain.com/ai-powered-medical-knowledge/</link>
      <description>[Editor's Note]: This is a guest post by Jack Simon, who recently participated in a hackathon at Williams College. He built a LangChain-powered chatbot focused on appendiceal cancer, aiming to make specialized knowledge more accessible to those in need. If you are interested in building a chatbot for another rare condition, please reach out to jms9@williams.edu.

The reason we are highlighting this is that we think it is a fantastic and under-appreciated use case for question-answering systems. </description>
      <guid isPermaLink="false">https://blog.langchain.com/ai-powered-medical-knowledge/</guid>
      <pubDate>Mon, 17 Apr 2023 12:27:06 -0700</pubDate>
    </item>
    <item>
      <title>Auto-Eval of Question-Answering Tasks</title>
      <link>https://blog.langchain.com/auto-eval-of-question-answering-tasks/</link>
      <description>By Lance Martin

Context

LLM ops platforms, such as LangChain, make it easy to assemble LLM components (e.g., models, document retrievers, data loaders) into chains. Question-Answering is one of the most popular applications of these chains. But it is often not always obvious to determine what parameters (e.g., chunk size) or components (e.g., model choice, VectorDB) yield the best QA performance.

Here, we introduce a simple tool for evaluating QA chains (see the code here) called auto-evaluat</description>
      <guid isPermaLink="false">https://blog.langchain.com/auto-eval-of-question-answering-tasks/</guid>
      <pubDate>Sat, 15 Apr 2023 20:54:17 -0700</pubDate>
    </item>
    <item>
      <title>Announcing LangChainJS Support for Multiple JS Environments</title>
      <link>https://blog.langchain.com/js-envs/</link>
      <description>TLDR: We're announcing support for running LangChain.js in browsers, Cloudflare Workers, Vercel/Next.js, Deno, Supabase Edge Functions, alongside existing support for Node.js ESM and CJS. See install/upgrade docs and breaking changes list.


Context

Originally we designed LangChain.js to run in Node.js, which is the longstanding serverside JavaScript runtime. Back in February (time flies!) we started to collect feedback from the community on what other JS runtimes we should support, and have si</description>
      <guid isPermaLink="false">https://blog.langchain.com/js-envs/</guid>
      <pubDate>Tue, 11 Apr 2023 09:25:51 -0700</pubDate>
    </item>
    <item>
      <title>LangChain x Supabase</title>
      <link>https://blog.langchain.com/langchain-x-supabase/</link>
      <description>Supabase is holding an AI Hackathon this week. Here at LangChain we are big fans of both Supabase and hackathons, so we thought this would be a perfect time to highlight the multiple ways you can use LangChain and Supabase together.

The reason we like Supabase so much is that it useful in multiple different ways. A big part of building interesting AI applications is connecting models like GPT-3 with your personal data. So in that way, the different types of databases that Supabase supports are </description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-x-supabase/</guid>
      <pubDate>Sat, 08 Apr 2023 13:04:19 -0700</pubDate>
    </item>
    <item>
      <title>Announcing our $10M seed round led by Benchmark</title>
      <link>https://blog.langchain.com/announcing-our-10m-seed-round-led-by-benchmark/</link>
      <description>It was only six months ago that we released the first version of LangChain, but it seems like several years. When we launched, generative AI was starting to go mainstream: stable diffusion had just been released and was captivating people’s imagination and fueling an explosion in developer activity, Jasper announced a funding round, and investors released the first Gen AI market maps.

Alongside this boon in content creation, people started to realize that the true power of this technology was n</description>
      <guid isPermaLink="false">https://blog.langchain.com/announcing-our-10m-seed-round-led-by-benchmark/</guid>
      <pubDate>Tue, 04 Apr 2023 09:35:29 -0700</pubDate>
    </item>
    <item>
      <title>Custom Agents</title>
      <link>https://blog.langchain.com/custom-agents/</link>
      <description>One of the most common requests we've heard is better functionality and documentation for creating custom agents. This has always been a bit tricky - because in our mind it's actually still very unclear what an "agent" actually is, and therefor what the "right" abstractions for them may be. Recently, we've felt some of the abstractions starting to come together, so we did a big push across both our Python and TypeScript modules to better enforce and document these abstractions. Please see below </description>
      <guid isPermaLink="false">https://blog.langchain.com/custom-agents/</guid>
      <pubDate>Mon, 03 Apr 2023 09:05:55 -0700</pubDate>
    </item>
    <item>
      <title>Retrieval</title>
      <link>https://blog.langchain.com/retrieval/</link>
      <description>TL;DR: We are adjusting our abstractions to make it easy for other retrieval methods besides the LangChain VectorDB object to be used in LangChain. This is done with the goals of (1) allowing retrievers constructed elsewhere to be used more easily in LangChain, (2) encouraging more experimentation with alternative retrieval methods (like hybrid search). This is backwards compatible, so all existing chains should continue to work as before. However, we recommend updating from VectorDB chains to t</description>
      <guid isPermaLink="false">https://blog.langchain.com/retrieval/</guid>
      <pubDate>Thu, 23 Mar 2023 21:33:49 -0700</pubDate>
    </item>
    <item>
      <title>LangChain + Zapier Natural Language Actions (NLA)</title>
      <link>https://blog.langchain.com/langchain-zapier-nla/</link>
      <description>We are super excited to team up with Zapier and integrate their new Zapier NLA API into LangChain, which you can now use with your agents and chains. With this integration, you have access to the 5k+ apps and 20k+ actions on Zapier's platform through a natural language API interface. This is extremely powerful and gives your LangChain agents seemingly limitless possibilities. Big shoutout to Mike Knoop and the rest of the Zapier team for helping with this integration. You can request access in t</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-zapier-nla/</guid>
      <pubDate>Thu, 16 Mar 2023 07:48:06 -0700</pubDate>
    </item>
    <item>
      <title>LLMs and SQL</title>
      <link>https://blog.langchain.com/llms-and-sql/</link>
      <description>Francisco Ingham and Jon Luo are two of the community members leading the change on the SQL integrations. We’re really excited to write this blog post with them going over all the tips and tricks they’ve learned doing so. We’re even more excited to announce that we’ll be doing an hour long webinar with them to discuss these learnings and field other related questions. This webinar will be on March 22nd - sign up at the below link:

 * Webinar Link

The LangChain library has multiple SQL chains a</description>
      <guid isPermaLink="false">https://blog.langchain.com/llms-and-sql/</guid>
      <pubDate>Mon, 13 Mar 2023 08:18:02 -0700</pubDate>
    </item>
    <item>
      <title>Origin Web Browser</title>
      <link>https://blog.langchain.com/origin-web-browser/</link>
      <description>[Editor's Note]: This is the second of hopefully many guest posts. We intend to highlight novel applications building on top of LangChain. If you are interested in working with us on such a post, please reach out to harrison@langchain.dev.

Authors: Parth Asawa (pgasawa@), Ayushi Batwara (ayushi.batwara@), Jason Ding (jasonding@), Arvind Rajaraman (arvind.rajaraman@) [@berkeley.edu]

Link to original blogpost


The Problem

Has your browser ever looked like this?

There’s probably been a time wh</description>
      <guid isPermaLink="false">https://blog.langchain.com/origin-web-browser/</guid>
      <pubDate>Wed, 08 Mar 2023 10:54:13 -0800</pubDate>
    </item>
    <item>
      <title>Prompt Selectors</title>
      <link>https://blog.langchain.com/prompt-selectors/</link>
      <description>One common complaint we've heard is that the default prompt templates do not work equally well for all models. This became especially pronounced this past week when OpenAI released a ChatGPT API. This new API had a completely new interface (which required new abstractions) and as a result many users noticed issues with old prompts no longer working. Although we quickly added support for this model, many users noticed that prompt templates that worked well for GPT-3 did not work well in the chat </description>
      <guid isPermaLink="false">https://blog.langchain.com/prompt-selectors/</guid>
      <pubDate>Wed, 08 Mar 2023 09:45:44 -0800</pubDate>
    </item>
    <item>
      <title>Chat Models</title>
      <link>https://blog.langchain.com/chat-models/</link>
      <description>Last week OpenAI released a ChatGPT endpoint. It came marketed with several big improvements, most notably being 10x cheaper and a lot faster. But it also came with a completely new API endpoint. We were able to quickly write a wrapper for this endpoint to let users use it like any normal LLM in LangChain, but this did not fully take advantage of the new message-based API. In this blog post we go over the new API schema and how we are adapting LangChain to accommodate not only ChatGPT but also a</description>
      <guid isPermaLink="false">https://blog.langchain.com/chat-models/</guid>
      <pubDate>Mon, 06 Mar 2023 10:03:34 -0800</pubDate>
    </item>
    <item>
      <title>Using the ChatGPT API to evaluate the ChatGPT API</title>
      <link>https://blog.langchain.com/using-chatgpt-api-to-evaluate-chatgpt/</link>
      <description>OpenAI released a new ChatGPT API yesterday. Lots of people were excited to try it. But how does it actually compare to the existing API? It will take some time before there is a definitive answer, but here are some initial thoughts. Because I'm lazy, I also enrolled the help of the ChatGPT API itself to help do this evaluation. Confused? Don't be. Let's dive in.

Relevant links:

 * Evaluation Notebook
 * ChatGPT PR
 * ChatGPT PR Discussion


What task are we evaluating?

In this article we wil</description>
      <guid isPermaLink="false">https://blog.langchain.com/using-chatgpt-api-to-evaluate-chatgpt/</guid>
      <pubDate>Thu, 02 Mar 2023 07:54:38 -0800</pubDate>
    </item>
    <item>
      <title>Agent Toolkits</title>
      <link>https://blog.langchain.com/agent-toolkits/</link>
      <description>Today, we're announcing agent toolkits, a new abstraction that allows developers to create agents designed for a particular use-case (for example, interacting with a relational database or interacting with an OpenAPI spec). We hope to continue developing different toolkits that can enable agents to do amazing feats. Toolkits are supported in both Python and TypeScript.


Agents

Quick refresher: what do we mean by agents? And why use them?

By agents we mean a system that uses an LLM to decide w</description>
      <guid isPermaLink="false">https://blog.langchain.com/agent-toolkits/</guid>
      <pubDate>Wed, 01 Mar 2023 07:52:18 -0800</pubDate>
    </item>
    <item>
      <title>TypeScript Support</title>
      <link>https://blog.langchain.com/typescript-support/</link>
      <description>It's finally here... TypeScript support for LangChain.

What does this mean? It means that all your favorite prompts, chains, and agents are all recreatable in TypeScript natively. Both the Python version and TypeScript version utilize the same serializable format, meaning that artifacts can seamlessly be shared between languages. As an example of using this, we've also recreated ChatLangChain with TypeScript.

A huge thank you to the community for helping with this.

Important Links:

 * GitHub</description>
      <guid isPermaLink="false">https://blog.langchain.com/typescript-support/</guid>
      <pubDate>Fri, 17 Feb 2023 08:12:40 -0800</pubDate>
    </item>
    <item>
      <title>Streaming Support in LangChain</title>
      <link>https://blog.langchain.com/streaming-support-in-langchain/</link>
      <description>We’re excited to announce streaming support in LangChain. There's been a lot of talk about the best UX for LLM applications, and we believe streaming is at its core. We’ve also updated the chat-langchain repo to include streaming and async execution. We hope that this repo can serve as a template for developers building best-in-class chat and question/answering applications.


Motivation

One of the biggest pain-points developers discuss when trying to build useful LLM applications is latency; t</description>
      <guid isPermaLink="false">https://blog.langchain.com/streaming-support-in-langchain/</guid>
      <pubDate>Tue, 14 Feb 2023 23:03:16 -0800</pubDate>
    </item>
    <item>
      <title>LangChain + Chroma</title>
      <link>https://blog.langchain.com/langchain-chroma/</link>
      <description>Today we’re announcing LangChain's integration with Chroma, the first step on the path to the Modern A.I Stack.


LangChain - The A.I-native developer toolkit

We started LangChain with the intent to build a modular and flexible framework for developing A.I-native applications. Some of the use cases which immediately jumped to mind are chat bots, question answering services, and agents. Thousands of developers are now hacking, tinkering, and building all kinds of LLM-powered applications using L</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-chroma/</guid>
      <pubDate>Mon, 13 Feb 2023 10:27:54 -0800</pubDate>
    </item>
    <item>
      <title>Chat-Your-Data Submissions</title>
      <link>https://blog.langchain.com/chat-your-data-submissions/</link>
      <description>Last week, we kicked off a week long competition to create a chatbot over your own data. The goal was to inspire (1) lots of document loaders for loading various types of data, (2) lots of end-to-end examples.

We succeeded on both fronts! On the document loader side, we added 25+ document loaders ranging from s3 to EveryNote to the College Confidential website.

One the end-to-end examples side, we're excited to highlight some of the projects below. As a reminder, the winner of the competition </description>
      <guid isPermaLink="false">https://blog.langchain.com/chat-your-data-submissions/</guid>
      <pubDate>Mon, 13 Feb 2023 07:21:42 -0800</pubDate>
    </item>
    <item>
      <title>Async Support in LangChain</title>
      <link>https://blog.langchain.com/async-api/</link>
      <description>We’re excited to roll out initial asynchronous support in LangChain by leveraging the asyncio library. Asyncio uses uses coroutines and an event loop to perform non-blocking I/O operations; these coroutines are able to “pause” (await) while waiting on their ultimate result and let other routines run in the meantime. To learn more about asyncio and how it compares to multithreading and multiprocessing, check out this awesome tutorial.


Motivation

Since LangChain applications tend to be fairly I</description>
      <guid isPermaLink="false">https://blog.langchain.com/async-api/</guid>
      <pubDate>Wed, 08 Feb 2023 00:24:23 -0800</pubDate>
    </item>
    <item>
      <title>Chat-Your-Data Challenge</title>
      <link>https://blog.langchain.com/chat-your-data-challenge/</link>
      <description>ChatGPT has taken the world by storm. Millions are using it. But while it’s great for general purpose knowledge, it only knows information about what it has been trained on, which is pre-2021 generally available internet data. It doesn’t know about your private data, it doesn’t know about recent sources of data.

Wouldn’t it be useful if it did? This is where LangChain comes in.

The goal of LangChain is to make it easier for everyone to develop language model applications. We recently published</description>
      <guid isPermaLink="false">https://blog.langchain.com/chat-your-data-challenge/</guid>
      <pubDate>Mon, 06 Feb 2023 00:19:43 -0800</pubDate>
    </item>
    <item>
      <title>Tutorial: ChatGPT Over Your Data</title>
      <link>https://blog.langchain.com/tutorial-chatgpt-over-your-data/</link>
      <description>Note: See the accompanying GitHub repo for this blogpost here.

ChatGPT has taken the world by storm. Millions are using it. But while it’s great for general purpose knowledge, it only knows information about what it has been trained on, which is pre-2021 generally available internet data. It doesn’t know about your private data, it doesn’t know about recent sources of data.

Wouldn’t it be useful if it did?

This blog post is a tutorial on how to set up your own version of ChatGPT over a specif</description>
      <guid isPermaLink="false">https://blog.langchain.com/tutorial-chatgpt-over-your-data/</guid>
      <pubDate>Sun, 05 Feb 2023 23:54:19 -0800</pubDate>
    </item>
    <item>
      <title>LangChain &lt;&gt; Unstructured</title>
      <link>https://blog.langchain.com/langchain-unstructured/</link>
      <description>One of the core value props of LangChain is the ability to combine Large Language Models with your own text data. There are multiple (four!) different methods of doing so, and many different applications this can power.

A step that sits upstream of using text data is the ability to get your data into a text form. This can be rather tricky due to the multitude of different formats that exist out there.

Enter... unstructured.io.

Unstructured is a company with a mission of transforming natural l</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-unstructured/</guid>
      <pubDate>Sun, 05 Feb 2023 23:32:46 -0800</pubDate>
    </item>
    <item>
      <title>GPTwitter</title>
      <link>https://blog.langchain.com/gptwitter/</link>
      <description>[Editor's Note]: This is the first of hopefully many guest posts. We intend to highlight novel applications building on top of LangChain. If you are interested in working with us on such a post, please reach out to harrison@langchain.dev.

This post by Akash Samant highlights an application that we believe achieves user-level personalization in a novel, reproducible, and under-explored way.

GPTwitter: The first personalized AI generated Social Media Platform. Access it here: https://gptwitter-n</description>
      <guid isPermaLink="false">https://blog.langchain.com/gptwitter/</guid>
      <pubDate>Wed, 01 Feb 2023 08:34:39 -0800</pubDate>
    </item>
    <item>
      <title>Tracing</title>
      <link>https://blog.langchain.com/tracing/</link>
      <description>We’re excited to announce native tracing support in LangChain! By enabling tracing in your LangChain runs, you’ll be able to more effectively visualize, step through, and debug your chains and agents.


Motivation

Reasoning about your chain and agent executions is important for troubleshooting and debugging. However, it can be difficult for complex chains and agents, for a number of reasons:

 1. There could be a high number of steps, making it hard to keep track of all of them
 2. The sequence</description>
      <guid isPermaLink="false">https://blog.langchain.com/tracing/</guid>
      <pubDate>Sun, 29 Jan 2023 20:48:04 -0800</pubDate>
    </item>
    <item>
      <title>LangChainHub</title>
      <link>https://blog.langchain.com/langchainhub/</link>
      <description>We are excited to announce the launch of the LangChainHub, a place where you can find and submit commonly used prompts, chains, agents, and more!

This obviously draws a lot of inspiration from Hugging Face's Hub, which we believe has done an incredible job of fostering an amazing community.


Motivation

Over the past few months, we’ve seen the LangChain community build a staggering number of applications using the framework. These applications use LangChain components such as prompts, LLMs, ch</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchainhub/</guid>
      <pubDate>Mon, 23 Jan 2023 23:44:41 -0800</pubDate>
    </item>
    <item>
      <title>LangChain Chat</title>
      <link>https://blog.langchain.com/langchain-chat/</link>
      <description>Today we’re excited to announce and showcase an open source chatbot specifically geared toward answering questions about LangChain’s documentation.

Key Links

 * Deployed Chatbot: chat.langchain.dev
 * Deployed Chatbot on HuggingFace spaces: huggingface.co/spaces/hwchase17/chat-langchain
 * Open source repo: github.com/hwchase17/chat-langchain
 * Next.js frontend: github.com/zahidkhawaja/langchain-chat-nextjs

Huge shoutout to Zahid Khawaja for collaborating with us on this. If you want this ty</description>
      <guid isPermaLink="false">https://blog.langchain.com/langchain-chat/</guid>
      <pubDate>Mon, 16 Jan 2023 00:00:00 -0800</pubDate>
    </item>
  </channel>
</rss>
